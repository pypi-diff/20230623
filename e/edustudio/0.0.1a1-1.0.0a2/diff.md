# Comparing `tmp/edustudio-0.0.1a1-py3-none-any.whl.zip` & `tmp/edustudio-1.0.0a2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,11 +1,48 @@
-Zip file size: 173887 bytes, number of entries: 124
--rw-rw-r--  2.0 unx      140 b- defN 23-Jun-18 09:30 edustudio/__init__.py
+Zip file size: 254308 bytes, number of entries: 198
+-rw-rw-r--  2.0 unx      139 b- defN 23-Jun-23 13:24 edustudio/__init__.py
 -rw-rw-r--  2.0 unx      738 b- defN 23-Jun-18 09:30 edustudio/settings.py
--rw-rw-r--  2.0 unx      985 b- defN 23-Jun-18 09:30 edustudio/assets/datasets.yaml
+-rw-rw-r--  2.0 unx      523 b- defN 23-Jun-23 13:09 edustudio/assets/datasets.yaml
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-23 13:09 edustudio/atom_op/__init__.py
+-rw-rw-r--  2.0 unx      629 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/CD/__init__.py
+-rw-rw-r--  2.0 unx     2993 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/CD/data_split4cd.py
+-rw-rw-r--  2.0 unx     1550 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/CD/filter_records4cd.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/KT/__init__.py
+-rw-rw-r--  2.0 unx     9455 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/KT/build_seq_inter_feats.py
+-rw-rw-r--  2.0 unx     3621 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/KT/cpt_as_exer.py
+-rw-rw-r--  2.0 unx      850 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/KT/gen_cpt_seq.py
+-rw-rw-r--  2.0 unx     2635 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/KT/gen_unfold_cpt_seq.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/__init__.py
+-rw-rw-r--  2.0 unx      820 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/base_mid2cache.py
+-rw-rw-r--  2.0 unx      207 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/build_cpt_relation.py
+-rw-rw-r--  2.0 unx      967 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/gen_q_mat.py
+-rw-rw-r--  2.0 unx      531 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/label2int.py
+-rw-rw-r--  2.0 unx     1362 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/merge_divided_splits.py
+-rw-rw-r--  2.0 unx     3022 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/common/remapid.py
+-rw-rw-r--  2.0 unx     2463 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/single/M2C_DIMKT_OP.py
+-rw-rw-r--  2.0 unx     6599 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/single/M2C_DKTDSC_OP.py
+-rw-rw-r--  2.0 unx     4510 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/single/M2C_DKTForget_OP.py
+-rw-rw-r--  2.0 unx     2622 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/single/M2C_EERNN_OP.py
+-rw-rw-r--  2.0 unx     5263 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/single/M2C_LPKT_OP.py
+-rw-rw-r--  2.0 unx      203 b- defN 23-Jun-23 13:09 edustudio/atom_op/mid2cache/single/__init__.py
+-rw-rw-r--  2.0 unx     1295 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/__init__.py
+-rw-rw-r--  2.0 unx     5081 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/aaai_2023.py
+-rw-rw-r--  2.0 unx     7324 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/algebra2005.py
+-rw-rw-r--  2.0 unx     7366 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/assist_0910.py
+-rw-rw-r--  2.0 unx     3584 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/assist_1213.py
+-rw-rw-r--  2.0 unx     1967 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/assist_1516.py
+-rw-rw-r--  2.0 unx     7386 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/bridge2006.py
+-rw-rw-r--  2.0 unx     3304 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/ednet_kt1.py
+-rw-rw-r--  2.0 unx     2741 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/frcsub.py
+-rw-rw-r--  2.0 unx     5775 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/junyi_area_topic_as_cpt.py
+-rw-rw-r--  2.0 unx     6091 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/junyi_exer_as_cpt.py
+-rw-rw-r--  2.0 unx     2323 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/math1.py
+-rw-rw-r--  2.0 unx     2645 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/math2.py
+-rw-rw-r--  2.0 unx      995 b- defN 23-Jun-23 13:09 edustudio/atom_op/raw2mid/raw2mid.py
 -rw-rw-r--  2.0 unx       92 b- defN 23-Jun-18 09:30 edustudio/datafmt/__init__.py
 -rw-rw-r--  2.0 unx     7075 b- defN 23-Jun-18 09:30 edustudio/datafmt/base_datafmt.py
 -rw-rw-r--  2.0 unx      416 b- defN 23-Jun-18 09:30 edustudio/datafmt/CD/__init__.py
 -rw-rw-r--  2.0 unx     6463 b- defN 23-Jun-18 09:30 edustudio/datafmt/CD/cdgk_datafmt.py
 -rw-rw-r--  2.0 unx     2044 b- defN 23-Jun-18 09:30 edustudio/datafmt/CD/cncd_f_datafmt.py
 -rw-rw-r--  2.0 unx     3356 b- defN 23-Jun-18 09:30 edustudio/datafmt/CD/cncd_q_datafmt.py
 -rw-rw-r--  2.0 unx     3941 b- defN 23-Jun-18 09:30 edustudio/datafmt/CD/ecd_datafmt.py
@@ -30,97 +67,134 @@
 -rw-rw-r--  2.0 unx     5958 b- defN 23-Jun-18 09:30 edustudio/datafmt/KT/lpkt_datafmt.py
 -rw-rw-r--  2.0 unx     1509 b- defN 23-Jun-18 09:30 edustudio/datafmt/KT/qdkt_datafmt.py
 -rw-rw-r--  2.0 unx     2253 b- defN 23-Jun-18 09:30 edustudio/datafmt/KT/rkt_datafmt.py
 -rw-rw-r--  2.0 unx      133 b- defN 23-Jun-18 09:30 edustudio/datafmt/utils/__init__.py
 -rw-rw-r--  2.0 unx     1170 b- defN 23-Jun-18 09:30 edustudio/datafmt/utils/common.py
 -rw-rw-r--  2.0 unx     5132 b- defN 23-Jun-18 09:30 edustudio/datafmt/utils/pad_seq_util.py
 -rw-rw-r--  2.0 unx     4046 b- defN 23-Jun-18 09:30 edustudio/datafmt/utils/spliter_util.py
+-rw-rw-r--  2.0 unx       59 b- defN 23-Jun-23 13:09 edustudio/datatpl/__init__.py
+-rw-rw-r--  2.0 unx      214 b- defN 23-Jun-23 13:09 edustudio/datatpl/CD/CDInterDataTPL.py
+-rw-rw-r--  2.0 unx      228 b- defN 23-Jun-23 13:09 edustudio/datatpl/CD/CDInterExtendsQDataTPL.py
+-rw-rw-r--  2.0 unx     5971 b- defN 23-Jun-23 13:09 edustudio/datatpl/CD/IRRDataTPL.py
+-rw-rw-r--  2.0 unx       91 b- defN 23-Jun-23 13:09 edustudio/datatpl/CD/MGCDDataTPL.py
+-rw-rw-r--  2.0 unx      137 b- defN 23-Jun-23 13:09 edustudio/datatpl/CD/__init__.py
+-rw-rw-r--  2.0 unx     1168 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/DIMKTDataTPL.py
+-rw-rw-r--  2.0 unx     1370 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/DKTDSCDataTPL.py
+-rw-rw-r--  2.0 unx      582 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/DKTForgetDataTPL.py
+-rw-rw-r--  2.0 unx     1420 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/EERNNDataTPL.py
+-rw-rw-r--  2.0 unx      208 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/KTInterCptAsExerDataTPL.py
+-rw-rw-r--  2.0 unx      358 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/KTInterCptUnfoldDataTPL.py
+-rw-rw-r--  2.0 unx      190 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/KTInterDataTPL.py
+-rw-rw-r--  2.0 unx      583 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/KTInterExtendsQDataTPL.py
+-rw-rw-r--  2.0 unx      592 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/LPKTDataTPL.py
+-rw-rw-r--  2.0 unx      427 b- defN 23-Jun-23 13:09 edustudio/datatpl/KT/__init__.py
+-rw-rw-r--  2.0 unx      162 b- defN 23-Jun-23 13:09 edustudio/datatpl/common/__init__.py
+-rw-rw-r--  2.0 unx     3342 b- defN 23-Jun-23 13:09 edustudio/datatpl/common/base_datatpl.py
+-rw-rw-r--  2.0 unx     3313 b- defN 23-Jun-23 13:09 edustudio/datatpl/common/edu_datatpl.py
+-rw-rw-r--  2.0 unx    18430 b- defN 23-Jun-23 13:09 edustudio/datatpl/common/general_datatpl.py
+-rw-rw-r--  2.0 unx     2212 b- defN 23-Jun-23 13:09 edustudio/datatpl/common/proxy_datatpl.py
+-rw-rw-r--  2.0 unx      133 b- defN 23-Jun-23 13:09 edustudio/datatpl/utils/__init__.py
+-rw-rw-r--  2.0 unx     1170 b- defN 23-Jun-23 13:09 edustudio/datatpl/utils/common.py
+-rw-rw-r--  2.0 unx     5132 b- defN 23-Jun-23 13:09 edustudio/datatpl/utils/pad_seq_util.py
+-rw-rw-r--  2.0 unx     4886 b- defN 23-Jun-23 13:09 edustudio/datatpl/utils/spliter_util.py
 -rw-rw-r--  2.0 unx      140 b- defN 23-Jun-18 09:30 edustudio/evalfmt/__init__.py
 -rw-rw-r--  2.0 unx     1373 b- defN 23-Jun-18 09:30 edustudio/evalfmt/base_evalfmt.py
 -rw-rw-r--  2.0 unx     1940 b- defN 23-Jun-18 09:30 edustudio/evalfmt/bc_evalfmt.py
 -rw-rw-r--  2.0 unx     8338 b- defN 23-Jun-18 09:30 edustudio/evalfmt/cd_evalfmt.py
+-rw-rw-r--  2.0 unx      141 b- defN 23-Jun-23 13:09 edustudio/evaltpl/__init__.py
+-rw-rw-r--  2.0 unx     1405 b- defN 23-Jun-23 13:09 edustudio/evaltpl/base_evaltpl.py
+-rw-rw-r--  2.0 unx     1941 b- defN 23-Jun-23 13:09 edustudio/evaltpl/bc_evaltpl.py
+-rw-rw-r--  2.0 unx     8454 b- defN 23-Jun-23 13:09 edustudio/evaltpl/cd_evaltpl.py
 -rw-rw-r--  2.0 unx      193 b- defN 23-Jun-18 09:30 edustudio/model/__init__.py
--rw-rw-r--  2.0 unx     4601 b- defN 23-Jun-18 09:30 edustudio/model/basemodel.py
--rw-rw-r--  2.0 unx     1776 b- defN 23-Jun-18 09:30 edustudio/model/gd_basemodel.py
+-rw-rw-r--  2.0 unx     4748 b- defN 23-Jun-23 13:09 edustudio/model/basemodel.py
+-rw-rw-r--  2.0 unx     1797 b- defN 23-Jun-23 13:09 edustudio/model/gd_basemodel.py
 -rw-rw-r--  2.0 unx      383 b- defN 23-Jun-18 09:30 edustudio/model/CD/__init__.py
--rw-rw-r--  2.0 unx     4903 b- defN 23-Jun-18 09:30 edustudio/model/CD/cdgk.py
--rw-rw-r--  2.0 unx     3399 b- defN 23-Jun-18 09:30 edustudio/model/CD/cdmfkc.py
--rw-rw-r--  2.0 unx     6549 b- defN 23-Jun-18 09:30 edustudio/model/CD/cncd_f.py
--rw-rw-r--  2.0 unx     4181 b- defN 23-Jun-18 09:30 edustudio/model/CD/cncd_q.py
--rw-rw-r--  2.0 unx     4344 b- defN 23-Jun-18 09:30 edustudio/model/CD/dina.py
--rw-rw-r--  2.0 unx    12290 b- defN 23-Jun-18 09:30 edustudio/model/CD/ecd.py
--rw-rw-r--  2.0 unx     8903 b- defN 23-Jun-18 09:30 edustudio/model/CD/hier_cdf.py
--rw-rw-r--  2.0 unx     1343 b- defN 23-Jun-18 09:30 edustudio/model/CD/irr.py
--rw-rw-r--  2.0 unx     2878 b- defN 23-Jun-18 09:30 edustudio/model/CD/irt.py
--rw-rw-r--  2.0 unx     6384 b- defN 23-Jun-18 09:30 edustudio/model/CD/kancd.py
--rw-rw-r--  2.0 unx     5119 b- defN 23-Jun-18 09:30 edustudio/model/CD/kscd.py
--rw-rw-r--  2.0 unx     7162 b- defN 23-Jun-18 09:30 edustudio/model/CD/mgcd.py
--rw-rw-r--  2.0 unx     2391 b- defN 23-Jun-18 09:30 edustudio/model/CD/mirt.py
--rw-rw-r--  2.0 unx     2408 b- defN 23-Jun-18 09:30 edustudio/model/CD/ncdm.py
--rw-rw-r--  2.0 unx     9510 b- defN 23-Jun-18 09:30 edustudio/model/CD/rcd.py
--rw-rw-r--  2.0 unx      764 b- defN 23-Jun-18 09:30 edustudio/model/KT/__init__.py
--rw-rw-r--  2.0 unx    12449 b- defN 23-Jun-18 09:30 edustudio/model/KT/akt.py
--rw-rw-r--  2.0 unx     3867 b- defN 23-Jun-18 09:30 edustudio/model/KT/atkt.py
--rw-rw-r--  2.0 unx     7214 b- defN 23-Jun-18 09:30 edustudio/model/KT/ckt.py
--rw-rw-r--  2.0 unx    20281 b- defN 23-Jun-18 09:30 edustudio/model/KT/cl4kt.py
--rw-rw-r--  2.0 unx     8600 b- defN 23-Jun-18 09:30 edustudio/model/KT/ct_ncm.py
--rw-rw-r--  2.0 unx     3797 b- defN 23-Jun-18 09:30 edustudio/model/KT/deep_irt.py
--rw-rw-r--  2.0 unx     5980 b- defN 23-Jun-18 09:30 edustudio/model/KT/dimkt.py
--rw-rw-r--  2.0 unx     2685 b- defN 23-Jun-18 09:30 edustudio/model/KT/dkt.py
--rw-rw-r--  2.0 unx     3335 b- defN 23-Jun-18 09:30 edustudio/model/KT/dkt_dsc.py
--rw-rw-r--  2.0 unx     5595 b- defN 23-Jun-18 09:30 edustudio/model/KT/dkt_forget.py
--rw-rw-r--  2.0 unx     1510 b- defN 23-Jun-18 09:30 edustudio/model/KT/dkt_plus.py
--rw-rw-r--  2.0 unx     3447 b- defN 23-Jun-18 09:30 edustudio/model/KT/dkvmn.py
--rw-rw-r--  2.0 unx    15104 b- defN 23-Jun-18 09:30 edustudio/model/KT/dtransformer.py
--rw-rw-r--  2.0 unx     4435 b- defN 23-Jun-18 09:30 edustudio/model/KT/eernn.py
--rw-rw-r--  2.0 unx     1798 b- defN 23-Jun-18 09:30 edustudio/model/KT/ekt.py
--rw-rw-r--  2.0 unx     4732 b- defN 23-Jun-18 09:30 edustudio/model/KT/hawkeskt.py
--rw-rw-r--  2.0 unx    13687 b- defN 23-Jun-18 09:30 edustudio/model/KT/iekt.py
--rw-rw-r--  2.0 unx     4824 b- defN 23-Jun-18 09:30 edustudio/model/KT/kqn.py
--rw-rw-r--  2.0 unx     5252 b- defN 23-Jun-18 09:30 edustudio/model/KT/lpkt.py
--rw-rw-r--  2.0 unx     6285 b- defN 23-Jun-18 09:30 edustudio/model/KT/lpkt_s.py
--rw-rw-r--  2.0 unx     4482 b- defN 23-Jun-18 09:30 edustudio/model/KT/qdkt.py
--rw-rw-r--  2.0 unx     9760 b- defN 23-Jun-18 09:30 edustudio/model/KT/qikt.py
--rw-rw-r--  2.0 unx     9617 b- defN 23-Jun-18 09:30 edustudio/model/KT/rkt.py
--rw-rw-r--  2.0 unx    10381 b- defN 23-Jun-18 09:30 edustudio/model/KT/saint.py
--rw-rw-r--  2.0 unx    11007 b- defN 23-Jun-18 09:30 edustudio/model/KT/saint_plus.py
--rw-rw-r--  2.0 unx     3418 b- defN 23-Jun-18 09:30 edustudio/model/KT/sakt.py
--rw-rw-r--  2.0 unx    14386 b- defN 23-Jun-18 09:30 edustudio/model/KT/simplekt.py
--rw-rw-r--  2.0 unx    14704 b- defN 23-Jun-18 09:30 edustudio/model/KT/skvmn.py
+-rw-rw-r--  2.0 unx     4903 b- defN 23-Jun-23 13:09 edustudio/model/CD/cdgk.py
+-rw-rw-r--  2.0 unx     3868 b- defN 23-Jun-23 13:09 edustudio/model/CD/cdmfkc.py
+-rw-rw-r--  2.0 unx     7270 b- defN 23-Jun-23 13:09 edustudio/model/CD/cncd_f.py
+-rw-rw-r--  2.0 unx     4807 b- defN 23-Jun-23 13:09 edustudio/model/CD/cncd_q.py
+-rw-rw-r--  2.0 unx     4550 b- defN 23-Jun-23 13:09 edustudio/model/CD/dina.py
+-rw-rw-r--  2.0 unx    12876 b- defN 23-Jun-23 13:09 edustudio/model/CD/ecd.py
+-rw-rw-r--  2.0 unx     9157 b- defN 23-Jun-23 13:09 edustudio/model/CD/hier_cdf.py
+-rw-rw-r--  2.0 unx     1576 b- defN 23-Jun-23 13:09 edustudio/model/CD/irr.py
+-rw-rw-r--  2.0 unx     2808 b- defN 23-Jun-23 13:09 edustudio/model/CD/irt.py
+-rw-rw-r--  2.0 unx     6682 b- defN 23-Jun-23 13:09 edustudio/model/CD/kancd.py
+-rw-rw-r--  2.0 unx     5462 b- defN 23-Jun-23 13:09 edustudio/model/CD/kscd.py
+-rw-rw-r--  2.0 unx     7658 b- defN 23-Jun-23 13:09 edustudio/model/CD/mgcd.py
+-rw-rw-r--  2.0 unx     2534 b- defN 23-Jun-23 13:09 edustudio/model/CD/mirt.py
+-rw-rw-r--  2.0 unx     3085 b- defN 23-Jun-23 13:09 edustudio/model/CD/ncdm.py
+-rw-rw-r--  2.0 unx     9516 b- defN 23-Jun-23 13:09 edustudio/model/CD/rcd.py
+-rw-rw-r--  2.0 unx      763 b- defN 23-Jun-23 13:09 edustudio/model/KT/__init__.py
+-rw-rw-r--  2.0 unx    13500 b- defN 23-Jun-23 13:09 edustudio/model/KT/akt.py
+-rw-rw-r--  2.0 unx     6326 b- defN 23-Jun-23 13:09 edustudio/model/KT/atkt.py
+-rw-rw-r--  2.0 unx     7248 b- defN 23-Jun-23 13:09 edustudio/model/KT/ckt.py
+-rw-rw-r--  2.0 unx    20437 b- defN 23-Jun-23 13:09 edustudio/model/KT/cl4kt.py
+-rw-rw-r--  2.0 unx    12123 b- defN 23-Jun-23 13:09 edustudio/model/KT/ct_ncm.py
+-rw-rw-r--  2.0 unx     3850 b- defN 23-Jun-23 13:09 edustudio/model/KT/deep_irt.py
+-rw-rw-r--  2.0 unx     6471 b- defN 23-Jun-23 13:09 edustudio/model/KT/dimkt.py
+-rw-rw-r--  2.0 unx     2850 b- defN 23-Jun-23 13:09 edustudio/model/KT/dkt.py
+-rw-rw-r--  2.0 unx     3368 b- defN 23-Jun-23 13:09 edustudio/model/KT/dkt_dsc.py
+-rw-rw-r--  2.0 unx     5904 b- defN 23-Jun-23 13:09 edustudio/model/KT/dkt_forget.py
+-rw-rw-r--  2.0 unx     1519 b- defN 23-Jun-23 13:09 edustudio/model/KT/dkt_plus.py
+-rw-rw-r--  2.0 unx     3489 b- defN 23-Jun-23 13:09 edustudio/model/KT/dkvmn.py
+-rw-rw-r--  2.0 unx    15251 b- defN 23-Jun-23 13:09 edustudio/model/KT/dtransformer.py
+-rw-rw-r--  2.0 unx     4684 b- defN 23-Jun-23 13:09 edustudio/model/KT/eernn.py
+-rw-rw-r--  2.0 unx     2038 b- defN 23-Jun-23 13:09 edustudio/model/KT/ekt.py
+-rw-rw-r--  2.0 unx     4773 b- defN 23-Jun-23 13:09 edustudio/model/KT/hawkeskt.py
+-rw-rw-r--  2.0 unx    14052 b- defN 23-Jun-23 13:09 edustudio/model/KT/iekt.py
+-rw-rw-r--  2.0 unx     4882 b- defN 23-Jun-23 13:09 edustudio/model/KT/kqn.py
+-rw-rw-r--  2.0 unx     5518 b- defN 23-Jun-23 13:09 edustudio/model/KT/lpkt.py
+-rw-rw-r--  2.0 unx     6315 b- defN 23-Jun-23 13:09 edustudio/model/KT/lpkt_s.py
+-rw-rw-r--  2.0 unx     5032 b- defN 23-Jun-23 13:09 edustudio/model/KT/qdkt.py
+-rw-rw-r--  2.0 unx     9877 b- defN 23-Jun-23 13:09 edustudio/model/KT/qikt.py
+-rw-rw-r--  2.0 unx    10306 b- defN 23-Jun-23 13:09 edustudio/model/KT/rkt.py
+-rw-rw-r--  2.0 unx    10776 b- defN 23-Jun-23 13:09 edustudio/model/KT/saint.py
+-rw-rw-r--  2.0 unx    11405 b- defN 23-Jun-23 13:09 edustudio/model/KT/saint_plus.py
+-rw-rw-r--  2.0 unx     3469 b- defN 23-Jun-23 13:09 edustudio/model/KT/sakt.py
+-rw-rw-r--  2.0 unx    14429 b- defN 23-Jun-23 13:09 edustudio/model/KT/simplekt.py
+-rw-rw-r--  2.0 unx    14776 b- defN 23-Jun-23 13:09 edustudio/model/KT/skvmn.py
 -rw-rw-r--  2.0 unx       20 b- defN 23-Jun-18 09:30 edustudio/model/KT/GKT/__init__.py
 -rw-rw-r--  2.0 unx    11497 b- defN 23-Jun-18 09:30 edustudio/model/KT/GKT/building_blocks.py
--rw-rw-r--  2.0 unx    21294 b- defN 23-Jun-18 09:30 edustudio/model/KT/GKT/gkt.py
+-rw-rw-r--  2.0 unx    21563 b- defN 23-Jun-23 13:09 edustudio/model/KT/GKT/gkt.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jun-18 09:30 edustudio/model/utils/__init__.py
 -rw-rw-r--  2.0 unx     2871 b- defN 23-Jun-18 09:30 edustudio/model/utils/common.py
 -rw-rw-r--  2.0 unx     5122 b- defN 23-Jun-18 09:30 edustudio/model/utils/components.py
 -rw-rw-r--  2.0 unx       38 b- defN 23-Jun-18 09:30 edustudio/quickstart/__init__.py
--rw-rw-r--  2.0 unx     1495 b- defN 23-Jun-18 09:30 edustudio/quickstart/init_all.py
--rw-rw-r--  2.0 unx     9066 b- defN 23-Jun-18 09:30 edustudio/quickstart/parse_cfg.py
--rw-rw-r--  2.0 unx     2090 b- defN 23-Jun-18 09:30 edustudio/quickstart/quickstart.py
+-rw-rw-r--  2.0 unx      213 b- defN 23-Jun-23 13:09 edustudio/quickstart/atom_cmds.py
+-rw-rw-r--  2.0 unx     1501 b- defN 23-Jun-23 13:09 edustudio/quickstart/init_all.py
+-rw-rw-r--  2.0 unx    11099 b- defN 23-Jun-23 13:09 edustudio/quickstart/parse_cfg.py
+-rw-rw-r--  2.0 unx     2096 b- defN 23-Jun-23 13:09 edustudio/quickstart/quickstart.py
 -rw-rw-r--  2.0 unx      281 b- defN 23-Jun-18 09:30 edustudio/trainfmt/__init__.py
 -rw-rw-r--  2.0 unx     8516 b- defN 23-Jun-18 09:30 edustudio/trainfmt/atkt_trainfmt.py
 -rw-rw-r--  2.0 unx     2922 b- defN 23-Jun-18 09:30 edustudio/trainfmt/base_trainfmt.py
 -rw-rw-r--  2.0 unx     6854 b- defN 23-Jun-18 09:30 edustudio/trainfmt/cd_inter_trainfmt.py
 -rw-rw-r--  2.0 unx     3317 b- defN 23-Jun-18 09:30 edustudio/trainfmt/gd_trainfmt.py
 -rw-rw-r--  2.0 unx     6761 b- defN 23-Jun-18 09:30 edustudio/trainfmt/kt_inter_trainfmt.py
+-rw-rw-r--  2.0 unx      281 b- defN 23-Jun-23 13:09 edustudio/traintpl/__init__.py
+-rw-rw-r--  2.0 unx     8895 b- defN 23-Jun-23 13:09 edustudio/traintpl/atkt_traintpl.py
+-rw-rw-r--  2.0 unx     3349 b- defN 23-Jun-23 13:09 edustudio/traintpl/base_traintpl.py
+-rw-rw-r--  2.0 unx     7047 b- defN 23-Jun-23 13:09 edustudio/traintpl/cd_inter_traintpl.py
+-rw-rw-r--  2.0 unx     5191 b- defN 23-Jun-23 13:09 edustudio/traintpl/gd_traintpl.py
+-rw-rw-r--  2.0 unx     7071 b- defN 23-Jun-23 13:09 edustudio/traintpl/kt_inter_traintpl.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jun-18 09:30 edustudio/utils/__init__.py
 -rw-rw-r--  2.0 unx      486 b- defN 23-Jun-18 09:30 edustudio/utils/callback/__init__.py
 -rw-rw-r--  2.0 unx     3220 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callBackList.py
 -rw-rw-r--  2.0 unx      161 b- defN 23-Jun-18 09:30 edustudio/utils/callback/modeState.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/__init__.py
 -rw-rw-r--  2.0 unx     1761 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/baseLogger.py
 -rw-rw-r--  2.0 unx     1137 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/callback.py
 -rw-rw-r--  2.0 unx     2242 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/earlyStopping.py
 -rw-rw-r--  2.0 unx      932 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/epochPredict.py
--rw-rw-r--  2.0 unx     2477 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/history.py
+-rw-rw-r--  2.0 unx     2586 b- defN 23-Jun-23 13:09 edustudio/utils/callback/callbacks/history.py
 -rw-rw-r--  2.0 unx     2772 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/modelCheckPoint.py
 -rw-rw-r--  2.0 unx      547 b- defN 23-Jun-18 09:30 edustudio/utils/callback/callbacks/tensorboardCallBack.py
 -rw-rw-r--  2.0 unx      259 b- defN 23-Jun-18 09:30 edustudio/utils/common/__init__.py
 -rw-rw-r--  2.0 unx     2990 b- defN 23-Jun-18 09:30 edustudio/utils/common/commonUtil.py
 -rw-rw-r--  2.0 unx     4915 b- defN 23-Jun-18 09:30 edustudio/utils/common/configUtil.py
 -rw-rw-r--  2.0 unx     1996 b- defN 23-Jun-18 09:30 edustudio/utils/common/loggerUtil.py
--rw-rw-r--  2.0 unx     1064 b- defN 23-Jun-18 09:31 edustudio-0.0.1a1.dist-info/LICENSE
--rw-rw-r--  2.0 unx      927 b- defN 23-Jun-18 09:31 edustudio-0.0.1a1.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Jun-18 09:31 edustudio-0.0.1a1.dist-info/WHEEL
--rw-rw-r--  2.0 unx       10 b- defN 23-Jun-18 09:31 edustudio-0.0.1a1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    11135 b- defN 23-Jun-18 09:31 edustudio-0.0.1a1.dist-info/RECORD
-124 files, 585312 bytes uncompressed, 156151 bytes compressed:  73.3%
+-rw-rw-r--  2.0 unx     1064 b- defN 23-Jun-23 13:24 edustudio-1.0.0a2.dist-info/LICENSE
+-rw-rw-r--  2.0 unx      929 b- defN 23-Jun-23 13:24 edustudio-1.0.0a2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-23 13:24 edustudio-1.0.0a2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       72 b- defN 23-Jun-23 13:24 edustudio-1.0.0a2.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       10 b- defN 23-Jun-23 13:24 edustudio-1.0.0a2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    18328 b- defN 23-Jun-23 13:24 edustudio-1.0.0a2.dist-info/RECORD
+198 files, 816275 bytes uncompressed, 224924 bytes compressed:  72.4%
```

## zipnote {}

```diff
@@ -3,14 +3,125 @@
 
 Filename: edustudio/settings.py
 Comment: 
 
 Filename: edustudio/assets/datasets.yaml
 Comment: 
 
+Filename: edustudio/atom_op/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/CD/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/CD/data_split4cd.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/CD/filter_records4cd.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/KT/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/KT/build_seq_inter_feats.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/KT/cpt_as_exer.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/KT/gen_cpt_seq.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/KT/gen_unfold_cpt_seq.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/base_mid2cache.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/build_cpt_relation.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/gen_q_mat.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/label2int.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/merge_divided_splits.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/common/remapid.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/single/M2C_DIMKT_OP.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/single/M2C_DKTDSC_OP.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/single/M2C_DKTForget_OP.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/single/M2C_EERNN_OP.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/single/M2C_LPKT_OP.py
+Comment: 
+
+Filename: edustudio/atom_op/mid2cache/single/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/__init__.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/aaai_2023.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/algebra2005.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/assist_0910.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/assist_1213.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/assist_1516.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/bridge2006.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/ednet_kt1.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/frcsub.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/junyi_area_topic_as_cpt.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/junyi_exer_as_cpt.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/math1.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/math2.py
+Comment: 
+
+Filename: edustudio/atom_op/raw2mid/raw2mid.py
+Comment: 
+
 Filename: edustudio/datafmt/__init__.py
 Comment: 
 
 Filename: edustudio/datafmt/base_datafmt.py
 Comment: 
 
 Filename: edustudio/datafmt/CD/__init__.py
@@ -99,26 +210,113 @@
 
 Filename: edustudio/datafmt/utils/pad_seq_util.py
 Comment: 
 
 Filename: edustudio/datafmt/utils/spliter_util.py
 Comment: 
 
+Filename: edustudio/datatpl/__init__.py
+Comment: 
+
+Filename: edustudio/datatpl/CD/CDInterDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/CD/CDInterExtendsQDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/CD/IRRDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/CD/MGCDDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/CD/__init__.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/DIMKTDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/DKTDSCDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/DKTForgetDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/EERNNDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/KTInterCptAsExerDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/KTInterCptUnfoldDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/KTInterDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/KTInterExtendsQDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/LPKTDataTPL.py
+Comment: 
+
+Filename: edustudio/datatpl/KT/__init__.py
+Comment: 
+
+Filename: edustudio/datatpl/common/__init__.py
+Comment: 
+
+Filename: edustudio/datatpl/common/base_datatpl.py
+Comment: 
+
+Filename: edustudio/datatpl/common/edu_datatpl.py
+Comment: 
+
+Filename: edustudio/datatpl/common/general_datatpl.py
+Comment: 
+
+Filename: edustudio/datatpl/common/proxy_datatpl.py
+Comment: 
+
+Filename: edustudio/datatpl/utils/__init__.py
+Comment: 
+
+Filename: edustudio/datatpl/utils/common.py
+Comment: 
+
+Filename: edustudio/datatpl/utils/pad_seq_util.py
+Comment: 
+
+Filename: edustudio/datatpl/utils/spliter_util.py
+Comment: 
+
 Filename: edustudio/evalfmt/__init__.py
 Comment: 
 
 Filename: edustudio/evalfmt/base_evalfmt.py
 Comment: 
 
 Filename: edustudio/evalfmt/bc_evalfmt.py
 Comment: 
 
 Filename: edustudio/evalfmt/cd_evalfmt.py
 Comment: 
 
+Filename: edustudio/evaltpl/__init__.py
+Comment: 
+
+Filename: edustudio/evaltpl/base_evaltpl.py
+Comment: 
+
+Filename: edustudio/evaltpl/bc_evaltpl.py
+Comment: 
+
+Filename: edustudio/evaltpl/cd_evaltpl.py
+Comment: 
+
 Filename: edustudio/model/__init__.py
 Comment: 
 
 Filename: edustudio/model/basemodel.py
 Comment: 
 
 Filename: edustudio/model/gd_basemodel.py
@@ -276,14 +474,17 @@
 
 Filename: edustudio/model/utils/components.py
 Comment: 
 
 Filename: edustudio/quickstart/__init__.py
 Comment: 
 
+Filename: edustudio/quickstart/atom_cmds.py
+Comment: 
+
 Filename: edustudio/quickstart/init_all.py
 Comment: 
 
 Filename: edustudio/quickstart/parse_cfg.py
 Comment: 
 
 Filename: edustudio/quickstart/quickstart.py
@@ -303,14 +504,32 @@
 
 Filename: edustudio/trainfmt/gd_trainfmt.py
 Comment: 
 
 Filename: edustudio/trainfmt/kt_inter_trainfmt.py
 Comment: 
 
+Filename: edustudio/traintpl/__init__.py
+Comment: 
+
+Filename: edustudio/traintpl/atkt_traintpl.py
+Comment: 
+
+Filename: edustudio/traintpl/base_traintpl.py
+Comment: 
+
+Filename: edustudio/traintpl/cd_inter_traintpl.py
+Comment: 
+
+Filename: edustudio/traintpl/gd_traintpl.py
+Comment: 
+
+Filename: edustudio/traintpl/kt_inter_traintpl.py
+Comment: 
+
 Filename: edustudio/utils/__init__.py
 Comment: 
 
 Filename: edustudio/utils/callback/__init__.py
 Comment: 
 
 Filename: edustudio/utils/callback/callBackList.py
@@ -351,23 +570,26 @@
 
 Filename: edustudio/utils/common/configUtil.py
 Comment: 
 
 Filename: edustudio/utils/common/loggerUtil.py
 Comment: 
 
-Filename: edustudio-0.0.1a1.dist-info/LICENSE
+Filename: edustudio-1.0.0a2.dist-info/LICENSE
+Comment: 
+
+Filename: edustudio-1.0.0a2.dist-info/METADATA
 Comment: 
 
-Filename: edustudio-0.0.1a1.dist-info/METADATA
+Filename: edustudio-1.0.0a2.dist-info/WHEEL
 Comment: 
 
-Filename: edustudio-0.0.1a1.dist-info/WHEEL
+Filename: edustudio-1.0.0a2.dist-info/entry_points.txt
 Comment: 
 
-Filename: edustudio-0.0.1a1.dist-info/top_level.txt
+Filename: edustudio-1.0.0a2.dist-info/top_level.txt
 Comment: 
 
-Filename: edustudio-0.0.1a1.dist-info/RECORD
+Filename: edustudio-1.0.0a2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## edustudio/__init__.py

```diff
@@ -1,5 +1,5 @@
 from __future__ import absolute_import
 from __future__ import print_function
 from __future__ import division
 
-__version__ = 'v0.0.1-alpha1'
+__version__ = '1.0.0-alpha2'
```

## edustudio/assets/datasets.yaml

```diff
@@ -1,14 +1,10 @@
-assist-0910:
-  url: https://alist.kervias.com/d/localdata/edustudio/datasets/assist-0910.zip?sign=33aUPdDcCd6S1DB3yvZswDMLKcbGP62rvOXBHuFLGW8=:0
-junyi-relation:
-  url: https://alist.kervias.com/d/localdata/edustudio/datasets/junyi-relation.zip?sign=KD-sxpctNZhRxlDAcbhNamAdjBSKo6mHW0_JtJrkkDg=:0
-aaai2023_gktc:
-  url: https://alist.kervias.com/d/localdata/edustudio/datasets/aaai2023_gktc.zip?sign=d9_hkjIEDhMvuMl9LLr3_MZv9HbwxGtRP6zIfMl5ZDs=:0
-assist-2015-cpt:
-  url: https://alist.kervias.com/d/localdata/edustudio/datasets/assist-2015-cpt.zip?sign=PCmma24UCF1GnzR3fKUO8gdRfqAD2BBOzDsziQv5yoI=:0
-  note: the dataset regards knowledge concept as exercise, for dkt 
-algebra-2005-cpt:
-  url: https://alist.kervias.com/d/localdata/edustudio/datasets/algebra-2005-cpt.zip?sign=051ItL2FAlAZrIGunNbgJi0BNtrp7XFYZ7Jh4Ox36i4=:0
-  note: dkt-forget
-assist-2017:
-  url: https://alist.kervias.com/d/localdata/edustudio/datasets/assist-2017.zip?sign=tyfKcgzmweR2-fOAIfg6r0XcWLUEIJlx3dbeGZbewY4=:0
+ASSIST_0910:
+  middata_url: https://gitlab.com/hfut-lec/edudatafiles/-/raw/main/ASSIST_0910/ASSIST_0910-middata.zip
+FrcSub:
+  middata_url: https://gitlab.com/hfut-lec/edudatafiles/-/raw/main/FrcSub/FrcSub-middata.zip
+Math1:
+  middata_url: https://gitlab.com/hfut-lec/edudatafiles/-/raw/main/Math1/Math1-middata.zip
+Math2:
+  middata_url: https://gitlab.com/hfut-lec/edudatafiles/-/raw/main/Math2/Math2-middata.zip
+AAAI_2023:
+  middata_url: https://gitlab.com/hfut-lec/edudatafiles/-/raw/main/AAAI_2023/AAAI_2023-middata.zip
```

## edustudio/model/basemodel.py

```diff
@@ -8,19 +8,19 @@
 import importlib
 
 class BaseModel(nn.Module):
     default_cfg = {}
     def __init__(self, cfg):
         super().__init__()
         self.cfg: UnifyConfig = cfg
-        self.datafmt_cfg: UnifyConfig = cfg.datafmt_cfg
-        self.evalfmt_cfg: UnifyConfig = cfg.evalfmt_cfg
-        self.trainfmt_cfg: UnifyConfig = cfg.trainfmt_cfg
+        self.datatpl_cfg: UnifyConfig = cfg.datatpl_cfg
+        self.evaltpl_cfg: UnifyConfig = cfg.evaltpl_cfg
+        self.traintpl_cfg: UnifyConfig = cfg.traintpl_cfg
         self.frame_cfg: UnifyConfig = cfg.frame_cfg
-        self.model_cfg: UnifyConfig = cfg.model_cfg
+        self.modeltpl_cfg: UnifyConfig = cfg.modeltpl_cfg
         self.logger: logging.Logger = cfg.logger
 
     @classmethod
     def from_cfg(cls, cfg):
         return cls(cfg)
     
     def add_extra_data(self, **kwargs):
@@ -34,95 +34,95 @@
                 break
             cfg.update(_cls.default_cfg, update_unknown_key_only=True)
         return cfg
 
 
 # class BaseProxyModel(object):
 #     default_cfg = {
-#         'backbone_model_cls': 'BaseModel'
+#         'backbone_modeltpl_cls': 'BaseModel'
 #     }
     
 #     @classmethod
 #     def from_cfg(cls, cfg):
-#         backbone_model_cls = cls.get_backbone_cls(cfg.model_cfg.backbone_model_cls)
-#         cls.register_functions(backbone_cls=backbone_model_cls)
-#         return backbone_model_cls.from_cfg(cfg)
+#         backbone_modeltpl_cls = cls.get_backbone_cls(cfg.modeltpl_cfg.backbone_modeltpl_cls)
+#         cls.register_functions(backbone_cls=backbone_modeltpl_cls)
+#         return backbone_modeltpl_cls.from_cfg(cfg)
     
 #     @classmethod
 #     def register_functions(cls, backbone_cls):
 #         pass
 
 #     @classmethod
-#     def get_backbone_cls(cls, backbone_model_cls):
-#         if isinstance(backbone_model_cls, str):
-#             backbone_model_cls = importlib.import_module('edustudio.model').\
-#                 __getattribute__(backbone_model_cls)
-#         elif isinstance(backbone_model_cls, BaseModel):
-#             backbone_model_cls = backbone_model_cls
+#     def get_backbone_cls(cls, backbone_modeltpl_cls):
+#         if isinstance(backbone_modeltpl_cls, str):
+#             backbone_modeltpl_cls = importlib.import_module('edustudio.model').\
+#                 __getattribute__(backbone_modeltpl_cls)
+#         elif isinstance(backbone_modeltpl_cls, BaseModel):
+#             backbone_modeltpl_cls = backbone_modeltpl_cls
 #         else:
-#             raise ValueError(f"Unknown type of backbone_model_cls: {backbone_model_cls}")
-#         return backbone_model_cls
+#             raise ValueError(f"Unknown type of backbone_modeltpl_cls: {backbone_modeltpl_cls}")
+#         return backbone_modeltpl_cls
 
 #     @classmethod
-#     def get_default_cfg(cls, backbone_model_cls, **kwargs):
+#     def get_default_cfg(cls, backbone_modeltpl_cls, **kwargs):
 #         parent_class = cls.__base__
 #         cfg = UnifyConfig(cls.default_cfg)
-#         cfg.backbone_model_cls = backbone_model_cls or cfg.backbone_model_cls
+#         cfg.backbone_modeltpl_cls = backbone_modeltpl_cls or cfg.backbone_modeltpl_cls
 #         if hasattr(parent_class, 'get_default_cfg'):
-#             cfg.update(parent_class.get_default_cfg(backbone_model_cls=cfg.backbone_model_cls, **kwargs), update_unknown_key_only=True)
+#             cfg.update(parent_class.get_default_cfg(backbone_modeltpl_cls=cfg.backbone_modeltpl_cls, **kwargs), update_unknown_key_only=True)
 #         if cls is BaseProxyModel:
-#             backbone_model_cls = cls.get_backbone_cls(backbone_model_cls=cfg.backbone_model_cls, **kwargs)
-#             cfg.update(backbone_model_cls.get_default_cfg(**kwargs), update_unknown_key_only=True)
+#             backbone_modeltpl_cls = cls.get_backbone_cls(backbone_modeltpl_cls=cfg.backbone_modeltpl_cls, **kwargs)
+#             cfg.update(backbone_modeltpl_cls.get_default_cfg(**kwargs), update_unknown_key_only=True)
 #         return cfg
 
 
 
 class BaseProxyModel(object):
     default_cfg = {
-        'backbone_model_cls': 'BaseModel'
+        'backbone_modeltpl_cls': 'BaseModel'
     }
     
     @classmethod
     def from_cfg_proxy(cls, cfg):
-        backbone_model_cls = cls.get_backbone_cls(cfg.model_cfg.backbone_model_cls)
-        new_cls = cls.get_new_cls(p_cls=backbone_model_cls)
+        backbone_modeltpl_cls = cls.get_backbone_cls(cfg.modeltpl_cfg.backbone_modeltpl_cls)
+        new_cls = cls.get_new_cls(p_cls=backbone_modeltpl_cls)
         return new_cls.from_cfg(cfg)
     
     @classmethod
-    def get_backbone_cls(cls, backbone_model_cls):
-        if isinstance(backbone_model_cls, str):
-            backbone_model_cls = importlib.import_module('edustudio.model').\
-                __getattribute__(backbone_model_cls)
-        elif issubclass(backbone_model_cls, BaseModel):
-            backbone_model_cls = backbone_model_cls
+    def get_backbone_cls(cls, backbone_modeltpl_cls):
+        if isinstance(backbone_modeltpl_cls, str):
+            backbone_modeltpl_cls = importlib.import_module('edustudio.model').\
+                __getattribute__(backbone_modeltpl_cls)
+        elif issubclass(backbone_modeltpl_cls, BaseModel):
+            backbone_modeltpl_cls = backbone_modeltpl_cls
         else:
-            raise ValueError(f"Unknown type of backbone_model_cls: {backbone_model_cls}")
-        return backbone_model_cls
+            raise ValueError(f"Unknown type of backbone_modeltpl_cls: {backbone_modeltpl_cls}")
+        return backbone_modeltpl_cls
 
     @classmethod
     def get_new_cls(cls, p_cls):
         new_cls = type(cls.__name__ + "_proxy", (cls, p_cls), {})
         return new_cls
 
     @classmethod
-    def get_default_cfg(cls, backbone_model_cls):
+    def get_default_cfg(cls, backbone_modeltpl_cls):
         bb_cls = None
-        if backbone_model_cls is not None:
-            bb_cls = cls.get_backbone_cls(backbone_model_cls)
+        if backbone_modeltpl_cls is not None:
+            bb_cls = cls.get_backbone_cls(backbone_modeltpl_cls)
         else:
             for _cls in cls.__mro__:
                 if not hasattr(_cls, 'default_cfg'):
                     break
-                bb_cls = _cls.default_cfg.get('backbone_model_cls', None)
+                bb_cls = _cls.default_cfg.get('backbone_modeltpl_cls', None)
                 if bb_cls is not None: break
             assert bb_cls is not None
             bb_cls = cls.get_backbone_cls(bb_cls)
         
         cfg = UnifyConfig()
-        cfg.backbone_model_cls = bb_cls
-        cfg.backbone_model_cls_name = bb_cls.__name__
+        cfg.backbone_modeltpl_cls = bb_cls
+        cfg.backbone_modeltpl_cls_name = bb_cls.__name__
         new_cls = cls.get_new_cls(p_cls=bb_cls)
         for _cls in new_cls.__mro__:
             if not hasattr(_cls, 'default_cfg'):
                 break
             cfg.update(_cls.default_cfg, update_unknown_key_only=True)
         return cfg
```

## edustudio/model/gd_basemodel.py

```diff
@@ -7,15 +7,15 @@
 class GDBaseModel(BaseModel):
     default_cfg = {
         'param_init_type': 'xavier_normal',
         'pretrained_file_path': "",
     }
     def __init__(self, cfg):
         super().__init__(cfg)
-        self.device = self.trainfmt_cfg['device']
+        self.device = self.traintpl_cfg['device']
         self.share_callback_dict = {
             "stop_training": False
         }
 
     @abstractmethod
     def build_cfg(self):
         """
@@ -28,29 +28,29 @@
         """
             construct model component
         """
         pass
 
 
     def _init_params(self):
-        if self.model_cfg['param_init_type'] == 'default':
+        if self.modeltpl_cfg['param_init_type'] == 'default':
             pass
-        elif self.model_cfg['param_init_type'] == 'xavier_normal':
+        elif self.modeltpl_cfg['param_init_type'] == 'xavier_normal':
             self.apply(xavier_normal_initialization)
-        elif self.model_cfg['param_init_type'] == 'xavier_uniform':
+        elif self.modeltpl_cfg['param_init_type'] == 'xavier_uniform':
             self.apply(xavier_uniform_initialization)
-        elif self.model_cfg['param_init_type'] == 'kaiming_normal':
+        elif self.modeltpl_cfg['param_init_type'] == 'kaiming_normal':
             self.apply(kaiming_normal_initialization)
-        elif self.model_cfg['param_init_type'] == 'kaiming_uniform':
+        elif self.modeltpl_cfg['param_init_type'] == 'kaiming_uniform':
             self.apply(kaiming_uniform_initialization)
-        elif self.model_cfg['param_init_type'] == 'init_from_pretrained':
+        elif self.modeltpl_cfg['param_init_type'] == 'init_from_pretrained':
             self._load_params_from_pretrained()
 
     def _load_params_from_pretrained(self):
-        self.load_state_dict(torch.load(self.model_cfg['pretrained_file_path']))
+        self.load_state_dict(torch.load(self.modeltpl_cfg['pretrained_file_path']))
 
     def predict(self, **kwargs):
         pass
 
     def get_loss_dict(self, **kwargs):
         pass
```

## edustudio/model/CD/cdgk.py

```diff
@@ -74,17 +74,17 @@
             return self.stu_emb(stu_id)
         else:
             return self.stu_emb.weight
 
 
 class CDGK_SINGLE(GDBaseModel):
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def build_model(self):
         self.cdgk = CDGK_META(
             stu_count=self.n_user,
             exer_count=self.n_item,
             cpt_count=self.n_cpt
         )
@@ -101,17 +101,17 @@
     
     def get_stu_status(self, stu_id=None):
         return self.cdgk.get_stu_status(stu_id=stu_id)
 
 
 class CDGK_MULTI(GDBaseModel):
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     
     def add_extra_data(self, **kwargs):
         # 1. 知识点与图对应情况
         # 2. 知识点分组情况
         self.cpt2group = {}
         self.df_cpt2group = None
```

## edustudio/model/CD/cdmfkc.py

```diff
@@ -1,52 +1,67 @@
+r"""
+CDMFKC
+##################################
+Reference:
+    Li et al. "Cognitive Diagnosis Focusing on Knowledge Concepts." in CIKM 2022.
+"""
 import torch
 import torch.nn as nn
 from ..utils.components import PosMLP
 import torch.nn.functional as F
 from ..gd_basemodel import GDBaseModel
 
 
 class CDMFKC(GDBaseModel):
+    """
+    dnn_units: dimensions of the middle layers of a multilayer perceptron
+    dropout_rate: dropout rate of a multilayer perceptron
+    activation: activation function of a multilayer perceptron
+    g_impact_a: hyperparameters of the original formula 5
+    g_impact_b: hyperparameters of the original formula 5
+    """
     default_cfg = {
         'dnn_units': [512, 256],
         'dropout_rate': 0.5,
-        'disc_scale': 10,
         'activation': 'sigmoid',
         'g_impact_a': 0.5,
         'g_impact_b': 0.5
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+
+    def add_extra_data(self, **kwargs):
+        self.Q_mat = kwargs['Q_mat'].to(self.device)
 
     def build_model(self):
         self.student_emb = nn.Embedding(self.n_user, self.n_cpt)
         self.k_difficulty = nn.Embedding(self.n_item, self.n_cpt)
         self.e_difficulty = nn.Embedding(self.n_item, 1)
         self.k_impact = nn.Embedding(self.n_item, self.n_cpt)
         self.pd_net = PosMLP(
-            input_dim=self.n_cpt, output_dim=1, activation=self.model_cfg['activation'],
-            dnn_units=self.model_cfg['dnn_units'], dropout_rate=self.model_cfg['dropout_rate']
+            input_dim=self.n_cpt, output_dim=1, activation=self.modeltpl_cfg['activation'],
+            dnn_units=self.modeltpl_cfg['dnn_units'], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
 
-    def forward(self, stu_id, exer_id, Q_mat, **kwargs):
+    def forward(self, stu_id, exer_id, **kwargs):
         # before prednet
-        items_Q_mat = Q_mat[exer_id]  # Q_mat: exer_num * n_cpt; items_Q_mat: batch_exer_num * n_cpt
+        items_Q_mat = self.Q_mat[exer_id]  # Q_mat: exer_num * n_cpt; items_Q_mat: batch_exer_num * n_cpt
         stu_emb = self.student_emb(stu_id)
         stat_emb = torch.sigmoid(stu_emb)
 
         k_difficulty = torch.sigmoid(self.k_difficulty(exer_id))
-        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.model_cfg['disc_scale']
+        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id))
         h_impact = torch.sigmoid(self.k_impact(exer_id))
-        g_impact = torch.sigmoid(self.model_cfg['g_impact_a'] * h_impact + 
-                                 self.model_cfg['g_impact_b'] * k_difficulty * e_difficulty)
+        g_impact = torch.sigmoid(self.modeltpl_cfg['g_impact_a'] * h_impact + 
+                                 self.modeltpl_cfg['g_impact_b'] * k_difficulty * e_difficulty)
         # k_num = torch.sum(items_Q_mat, dim=1)  #  batch_exer_num
         # avg_impact = torch.multiply(k_num, torch.sum(torch.multiply(items_Q_mat, g_impact), dim=1))
         # k_difficulty_sum = torch.sum(items_Q_mat * k_difficulty, dim=1)
         # stu_stat_sum = torch.sum(stat_emb * items_Q_mat, dim=1)
         # slip = avg_impact * torch.div(k_difficulty_sum, stu_stat_sum)
         # guess = avg_impact * torch.div(stu_stat_sum, k_difficulty_sum)
         # prednet
@@ -59,28 +74,27 @@
         return pd
 
 
     def get_main_loss(self, **kwargs):
         stu_id = kwargs['stu_id']
         exer_id = kwargs['exer_id']
         label = kwargs['label']
-        Q_mat = kwargs['Q_mat']
-        pd = self(stu_id, exer_id, Q_mat).flatten()
+        pd = self(stu_id, exer_id).flatten()
         loss = F.binary_cross_entropy(input=pd, target=label)
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
     
     @torch.no_grad()
-    def predict(self, stu_id, exer_id, Q_mat, **kwargs):
+    def predict(self, stu_id, exer_id,  **kwargs):
         return {
-            'y_pd': self(stu_id, exer_id, Q_mat).flatten(),
+            'y_pd': self(stu_id, exer_id).flatten(),
         }
     
     def get_stu_status(self, stu_id=None):
         if stu_id is not None:
             return self.student_emb(stu_id)
         else:
             return self.student_emb.weight
```

## edustudio/model/CD/cncd_f.py

```diff
@@ -1,7 +1,18 @@
+r"""
+CNCD-F
+##########################################
+
+Reference:
+    Fei Wang et al. "Neural Cognitive Diagnosis for Intelligent Education Systems" in AAAI 2020.
+
+Reference Code:
+    https://github.com/bigdata-ustc/Neural_Cognitive_Diagnosis-NeuralCD
+
+"""
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 from ..utils.components import PosMLP
 import torch
 import torch.nn.functional as F
 import numpy as np
 
@@ -60,57 +71,68 @@
         x = torch.transpose(x, 1, 2)
         x = F.max_pool1d(x, self.channel_num3)
         x = torch.transpose(x, 1, 2).view(-1, self.full_in)
         ret = self.full(x)     # 使用的损失函数包含sigmoid，在预测时需在网络外加sigmoid
         return ret
 
 class CNCD_F(GDBaseModel):
+    r"""
+    CNCD-F
+
+    default_cfg:
+       'dnn_units': [512, 256]  # dimension list of hidden layer in prediction layer
+       'dropout_rate': 0.5      # dropout rate
+       'activation': 'sigmoid'  # activation function in prediction layer
+       'disc_scale': 10         # discrimination scale
+       'max_len': 600,          # the maximum length of the exercise text
+        'text_embedding_dim': 100 # dimension of text embedding
+    """
     default_cfg = {
         'dnn_units': [512, 256],
         'dropout_rate': 0.5,
         'activation': 'sigmoid',
         'disc_scale': 10,
         'max_len': 600,
         'text_embedding_dim': 100
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.text_dim = self.model_cfg["text_embedding_dim"]
-        self.max_len = self.model_cfg["max_len"]
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.text_dim = self.modeltpl_cfg["text_embedding_dim"]
+        self.max_len = self.modeltpl_cfg["max_len"]
 
     def get_from_text(self):
         x = []
         for e in self.content_list:
             word_ids = []
             for word in e[:self.max_len]:  # 固定长度为self.max_len
                 word_id = self.word2id.get(word)
                 if word_id is not None:
                     word_ids.append(word_id)
             if len(word_ids) < self.max_len:
                 word_ids += [0] * (self.max_len - len(word_ids))  # padding到self.max_len
             x.append(word_ids)
-        return torch.tensor(x, device=self.trainfmt_cfg['device'])
+        return torch.tensor(x, device=self.traintpl_cfg['device'])
 
     def build_model(self):
         # prediction sub-net
-        self.textcnn = TextCNN(self.trainfmt_cfg["batch_size"], self.n_cpt, self.text_dim)
+        self.textcnn = TextCNN(self.traintpl_cfg["batch_size"], self.n_cpt, self.text_dim)
         self.word2id = self.textcnn.prepare_embedding(self.content_list)
         self.word_ids = self.get_from_text()
         self.out_text_factor = nn.Linear(self.text_dim, 1)
         self.student_emb = nn.Embedding(self.n_user, self.n_cpt+1)
         self.k_difficulty = nn.Embedding(self.n_item, self.n_cpt)
         self.e_difficulty = nn.Embedding(self.n_item, 1)
         self.pd_net = PosMLP(
-            input_dim=self.n_cpt+1, output_dim=1, activation=self.model_cfg['activation'],
-            dnn_units=self.model_cfg['dnn_units'], dropout_rate=self.model_cfg['dropout_rate']
+            input_dim=self.n_cpt+1, output_dim=1, activation=self.modeltpl_cfg['activation'],
+            dnn_units=self.modeltpl_cfg['dnn_units'], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
 
     def add_extra_data(self, **kwargs):
         self.content_list = kwargs['content']
 
     def forward(self, stu_id, exer_id, Q_mat):
         # before prednet
@@ -118,17 +140,17 @@
         items_content = self.word_ids[exer_id]
         text_embedding = self.textcnn(items_content)
         text_factor = torch.sigmoid(self.out_text_factor(text_embedding))
         stu_emb = self.student_emb(stu_id)
         stat_emb = torch.sigmoid(stu_emb)
         k_difficulty = torch.sigmoid(self.k_difficulty(exer_id))
         k_difficulty = torch.cat((k_difficulty, text_factor), dim=1)
-        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.model_cfg['disc_scale']
+        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.modeltpl_cfg['disc_scale']
         # prednet
-        text_factor_q = torch.ones((items_Q_mat.shape[0], 1), device=self.trainfmt_cfg['device'])
+        text_factor_q = torch.ones((items_Q_mat.shape[0], 1), device=self.traintpl_cfg['device'])
         input_knowledge_point = torch.cat((items_Q_mat, text_factor_q), dim=1)
         input_x = e_difficulty * (stat_emb - k_difficulty) * input_knowledge_point
         pd = self.pd_net(input_x).sigmoid()
         return pd
 
     @torch.no_grad()
     def predict(self, stu_id, exer_id, Q_mat, **kwargs):
```

## edustudio/model/CD/cncd_q.py

```diff
@@ -1,50 +1,71 @@
+r"""
+CNCD-Q
+##########################################
+
+Reference:
+    Fei Wang et al. "Neural Cognitive Diagnosis for Intelligent Education Systems" in AAAI 2020.
+
+Reference Code:
+    https://github.com/bigdata-ustc/Neural_Cognitive_Diagnosis-NeuralCD
+    https://github.com/LegionKing/NeuralCDM_plus
+
+"""
 import numpy as np
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 from ..utils.components import PosMLP
 import torch
 import torch.nn.functional as F
 
 
 class CNCD_Q(GDBaseModel):
+    r"""
+    CNCD-Q
+
+    default_cfg:
+       'dnn_units': [512, 256]  # dimension list of hidden layer in prediction layer
+       'dropout_rate': 0.5      # dropout rate
+       'activation': 'sigmoid'  # activation function in prediction layer
+       'disc_scale': 10         # discrimination scale
+    """
     default_cfg = {
         'dnn_units': [512, 256],
         'dropout_rate': 0.5,
         'activation': 'sigmoid',
         'disc_scale': 10
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def build_model(self):
         # prediction sub-net
         self.student_emb = nn.Embedding(self.n_user, self.n_cpt)
         self.k_difficulty = nn.Embedding(self.n_item, self.n_cpt)
         self.e_difficulty = nn.Embedding(self.n_item, 1)
         self.pd_net = PosMLP(
-            input_dim=self.n_cpt, output_dim=1, activation=self.model_cfg['activation'],
-            dnn_units=self.model_cfg['dnn_units'], dropout_rate=self.model_cfg['dropout_rate']
+            input_dim=self.n_cpt, output_dim=1, activation=self.modeltpl_cfg['activation'],
+            dnn_units=self.modeltpl_cfg['dnn_units'], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
         self.e_k_prob = nn.Embedding(self.n_item, self.n_cpt)
 
     def forward(self, stu_id, exer_id, Q_mat, **kwargs):
         # before prednet
         users = stu_id
         items = exer_id
         items_Q_mat = Q_mat[items]
         stu_emb = self.student_emb(users)
         stat_emb = torch.sigmoid(stu_emb)
         k_difficulty = torch.sigmoid(self.k_difficulty(items))
-        e_difficulty = torch.sigmoid(self.e_difficulty(items)) * self.model_cfg['disc_scale']
+        e_difficulty = torch.sigmoid(self.e_difficulty(items)) * self.modeltpl_cfg['disc_scale']
         # prednet
         e_k_prob = self.e_k_prob(items)
         e_k_prob_2 = F.sigmoid(e_k_prob)  # knowledge relevancy vectors of the exercises
         input_x = e_difficulty * (stat_emb - k_difficulty) * (items_Q_mat * e_k_prob_2)
         pd = self.pd_net(input_x).sigmoid()
         if self.training:
             return pd, e_k_prob
@@ -57,18 +78,18 @@
             'y_pd': self(stu_id, exer_id, Q_mat).flatten(),
         }
 
     def get_main_loss(self, **kwargs):
         normal_mean, normal_C = 0, 2
         means = torch.ones(self.n_cpt) * normal_mean  # the mean of the multidimensional gaussian distribution
         means.require_grad = False
-        means = means.to(self.trainfmt_cfg['device'])
+        means = means.to(self.traintpl_cfg['device'])
         C = torch.ones(self.n_cpt) * normal_C  # the diagonal of the covariance matrix
         C.require_grad = False
-        C = C.to(self.trainfmt_cfg['device'])
+        C = C.to(self.traintpl_cfg['device'])
         stu_id = kwargs['stu_id']
         exer_id = kwargs['exer_id']
         label = kwargs['label']
         Q_mat = kwargs['Q_mat']
         knowledge_pairs_kw = kwargs['knowledge_pairs']
         # kn_tops = kwargs["kn_tops"]
         # kn_tags = kwargs["kn_tags"]
```

## edustudio/model/CD/dina.py

```diff
@@ -1,9 +1,17 @@
-"""
-    # reference: https://github.com/bigdata-ustc/EduCDM/blob/main/EduCDM/DINA/GD/DINA.py
+r"""
+DINA
+##########################################
+
+Reference:
+    Jimmy De La Torre. Dina model and parameter estimation: A didactic. Journal of educational and behavioral statistics, 34(1):115–130, 2009
+
+Reference Code:
+    https://github.com/bigdata-ustc/EduCDM/blob/main/EduCDM/DINA/
+
 """
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import numpy as np
 from ..gd_basemodel import GDBaseModel
@@ -16,32 +24,35 @@
         "max_step": 1000,
         "max_slip": 0.4,
         "max_guess": 0.4,
     }
     def __init__(self, cfg):
         super().__init__(cfg)
     
+    def add_extra_data(self, **kwargs):
+        self.Q_mat = kwargs['Q_mat'].to(self.device)
+
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
         self.step = 0
-        self.max_step = self.model_cfg['max_step']
-        self.max_slip =  self.model_cfg['max_slip']
-        self.max_guess =  self.model_cfg['max_guess']
+        self.max_step = self.modeltpl_cfg['max_step']
+        self.max_slip =  self.modeltpl_cfg['max_slip']
+        self.max_guess =  self.modeltpl_cfg['max_guess']
         self.emb_dim = self.n_cpt
 
     def build_model(self):
         self.guess = nn.Embedding(self.n_item, 1)
         self.slip = nn.Embedding(self.n_item, 1)
         self.theta = nn.Embedding(self.n_user, self.emb_dim)
 
-    def forward(self, stu_id, exer_id, Q_mat, **kwargs):
-        items_Q_mat = Q_mat[exer_id]
+    def forward(self, stu_id, exer_id, **kwargs):
+        items_Q_mat = self.Q_mat[exer_id]
         theta = self.theta(stu_id)
         slip = torch.squeeze(torch.sigmoid(self.slip(exer_id)) * self.max_slip)
         guess = torch.squeeze(torch.sigmoid(self.guess(exer_id)) * self.max_guess)
 
         knowledge = items_Q_mat
         if self.training:
             n = torch.sum(knowledge * (torch.sigmoid(theta) - 0.5), dim=1)
@@ -55,28 +66,27 @@
             n = torch.prod(knowledge * (theta >= 0) + (1 - knowledge), dim=1)
             return (1 - slip) ** n * guess ** (1 - n)
     
     def get_main_loss(self, **kwargs):
         stu_id = kwargs['stu_id']
         exer_id = kwargs['exer_id']
         label = kwargs['label']
-        Q_mat = kwargs['Q_mat']
-        pd = self(stu_id, exer_id, Q_mat).flatten()
+        pd = self(stu_id, exer_id).flatten()
         loss = F.binary_cross_entropy(input=pd, target=label)
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
     
     @torch.no_grad()
-    def predict(self, stu_id, exer_id, Q_mat, **kwargs):
+    def predict(self, stu_id, exer_id, **kwargs):
         return {
-            'y_pd': self(stu_id, exer_id, Q_mat).flatten(),
+            'y_pd': self(stu_id, exer_id).flatten(),
         }
                 
     def get_stu_status(self, stu_id=None):
         if stu_id is not None:
             return self.theta(stu_id)
         else:
             return self.theta.weight
@@ -106,25 +116,24 @@
         "max_guess": 0.4,
     }
     def __init__(self, cfg):
         super().__init__(cfg)
         self.sign = StraightThroughEstimator()
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
-        self.max_slip =  self.model_cfg['max_slip']
-        self.max_guess =  self.model_cfg['max_guess']
+        self.max_slip =  self.modeltpl_cfg['max_slip']
+        self.max_guess =  self.modeltpl_cfg['max_guess']
         self.emb_dim = self.n_cpt
 
-    def forward(self, stu_id, exer_id, items_Q_mat):
+    def forward(self, stu_id, exer_id):
         theta = self.theta(stu_id)
-        items_Q_mat = items_Q_mat[exer_id]
         theta = self.sign(self.theta(stu_id))
-        knowledge = items_Q_mat
+        knowledge = self.Q_mat[exer_id]
         slip = torch.squeeze(torch.sigmoid(self.slip(exer_id)) * self.max_slip)
         guess = torch.squeeze(torch.sigmoid(self.guess(exer_id)) * self.max_guess)
         mask_theta = (knowledge == 0) + (knowledge == 1) * theta
         n = torch.prod((mask_theta + 1) / 2, dim=-1)
         return torch.pow(1 - slip, n) * torch.pow(guess, 1 - n)
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## edustudio/model/CD/ecd.py

```diff
@@ -1,37 +1,55 @@
+r"""
+ECD
+##########################################
+
+Reference:
+    Yuqiang Zhou et al. "Modeling Context-aware Features for Cognitive Diagnosis in Student Learning" in KDD 2021.
+
+
+"""
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 from ..utils.components import PosMLP
 import torch
 import torch.nn.functional as F
 
 class ECD(GDBaseModel):
+    r"""
+    ECD
+
+    default_cfg:
+        'dnn_units': [512, 256]  # dimension list of hidden layer in prediction layer
+        'dropout_rate': 0.5      # dropout rate
+        'activation': 'sigmoid'  # activation function in prediction layer
+        'disc_scale': 10         # discrimination scale
+        'emb_dim': 10           # dimension of q,k
+        'con_dim': 1            # dimension of v
+    """
     default_cfg = {
         'dnn_units': [512, 256],
         'dropout_rate': 0.5,
         'activation': 'sigmoid',
         'disc_scale': 10,
-        'max_len': 600,
         'emb_dim': 10,
         'con_dim': 1,
-        'text_embedding_dim': 100
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.qk_dim = self.model_cfg["emb_dim"]
-        self.con_dim = self.model_cfg["con_dim"]
-        self.batch_size = self.trainfmt_cfg['batch_size']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.qk_dim = self.modeltpl_cfg["emb_dim"]
+        self.con_dim = self.modeltpl_cfg["con_dim"]
+        self.batch_size = self.traintpl_cfg['batch_size']
 
     def build_model(self):
-        self.con_ans_num = self.datafmt_cfg['dt_info']['qqq_count']
+        self.con_ans_num = self.datatpl_cfg['dt_info']['qqq_count']
         self.stu_q = nn.Embedding(self.n_user, self.qk_dim, padding_idx=0)
         self.qqq_group = [torch.tensor(k).to(self.device) for k in self.qqq_group_list]
         self.group_len = len(self.qqq_group)
         self.con_ans_v = nn.Embedding(self.con_ans_num, self.con_dim, padding_idx=0)
         self.con_ans_k = nn.Embedding(self.con_ans_num, self.qk_dim, padding_idx=0)
 
         self.d_t = nn.Embedding(self.n_user, 1, padding_idx=0)
@@ -94,33 +112,33 @@
         "fix_a": False,
         "fix_c": True,
         'loss_weight': [4, 0],
     }
     def build_model(self):
         super().build_model()
         self.theta = nn.Embedding(self.n_user, 1)  # student ability
-        self.a = 0.0 if self.model_cfg['fix_a'] else nn.Embedding(self.n_item, 1)  # exer discrimination
+        self.a = 0.0 if self.modeltpl_cfg['fix_a'] else nn.Embedding(self.n_item, 1)  # exer discrimination
         self.b = nn.Embedding(self.n_item, 1)  # exer difficulty
 
     @staticmethod
     def irf(theta, a, b,  D=1.702):
         return 1 / (1 + torch.exp(-D * a * (theta - b)))
 
     def forward(self, stu_id, exer_id, Q_mat, QQQ_list):
         items_Q_mat = Q_mat[exer_id]
         stus_qqq = QQQ_list[stu_id]
         theta_inner = self.theta(stu_id)
         a = self.a(exer_id)
         b = self.b(exer_id)
         theta_context, dt_w = super().forward(stu_id, stus_qqq)
         theta_all = theta_context * dt_w + theta_inner * (1 - dt_w)
-        if self.model_cfg['diff_range'] is not None:
-            b = self.model_cfg['diff_range'] * (torch.sigmoid(b) - 0.5)
-        if self.model_cfg['a_range'] is not None:
-            a = self.model_cfg['a_range'] * torch.sigmoid(a)
+        if self.modeltpl_cfg['diff_range'] is not None:
+            b = self.modeltpl_cfg['diff_range'] * (torch.sigmoid(b) - 0.5)
+        if self.modeltpl_cfg['a_range'] is not None:
+            a = self.modeltpl_cfg['a_range'] * torch.sigmoid(a)
         else:
             a = F.softplus(a) # 让区分度大于0，保持单调性假设
         if torch.max(theta_inner != theta_inner) or torch.max(a != a) or torch.max(b != b):  # pragma: no cover
             raise ValueError('ValueError:theta,a,b may contains nan!  The diff_range or a_range is too large.')
         pre_all = self.irf(theta_all, a, b)
         pre_context = self.irf(theta_context, a, b)
         pre_inner = self.irf(theta_inner, a, b)
@@ -142,15 +160,15 @@
         Q_mat = kwargs['Q_mat']
         QQQ_list = kwargs['QQQ_list']
         pd_all, pd_context, pd_inner = self(stu_id, exer_id, Q_mat, QQQ_list)
         pd_all, pd_context, pd_inner = pd_all.flatten(), pd_context.flatten(), pd_inner.flatten()
         loss_all = F.binary_cross_entropy(input=pd_all, target=label)
         loss_context = F.binary_cross_entropy(input=pd_context, target=label)
         loss_inner = F.binary_cross_entropy(input=pd_inner, target=label)
-        w = self.model_cfg['loss_weight']
+        w = self.modeltpl_cfg['loss_weight']
         # loss = loss_all+w[0]*loss_context+w[1]*loss_inner
         return {
             'loss_main': loss_all,
             'loss_context': w[0] * loss_context,
             'loss_inner': w[1] * loss_inner
         }
 
@@ -161,15 +179,15 @@
     default_cfg = {
         "a_range": -1.0,  # disc range
         "emb_dim": 32,
         'loss_weight': [0, 4],
     }
     def build_model(self):
         super().build_model()
-        self.emb_dim = self.model_cfg['emb_dim']
+        self.emb_dim = self.modeltpl_cfg['emb_dim']
         self.theta = nn.Embedding(self.n_user, self.emb_dim)  # student ability
         self.a = nn.Embedding(self.n_item, self.emb_dim)  # exer discrimination
         self.b = nn.Embedding(self.n_item, 1)  # exer intercept term
 
     @staticmethod
     def irf(theta, a, b):
         return 1 / (1 + torch.exp(- torch.sum(torch.multiply(a, theta), axis=-1) + b))
@@ -178,16 +196,16 @@
         items_Q_mat = Q_mat[exer_id]
         stus_qqq = QQQ_list[stu_id]
         theta_inner = self.theta(stu_id)
         a = self.a(exer_id)
         b = self.b(exer_id).flatten()
         theta_context, dt_w = super().forward(stu_id, stus_qqq)
         theta_all = theta_context * dt_w + theta_inner * (1 - dt_w)
-        if self.model_cfg['a_range'] is not None:
-            a = self.model_cfg['a_range'] * torch.sigmoid(a)
+        if self.modeltpl_cfg['a_range'] is not None:
+            a = self.modeltpl_cfg['a_range'] * torch.sigmoid(a)
         else:
             a = F.softplus(a) # 让区分度大于0，保持单调性假设
         if torch.max(theta_inner != theta_inner) or torch.max(a != a) or torch.max(b != b):  # pragma: no cover
             raise ValueError('ValueError:theta,a,b may contains nan!  The diff_range or a_range is too large.')
         pre_all = self.irf(theta_all, a, b)
         pre_context = self.irf(theta_context, a, b)
         pre_inner = self.irf(theta_inner, a, b)
@@ -209,15 +227,15 @@
         Q_mat = kwargs['Q_mat']
         QQQ_list = kwargs['QQQ_list']
         pd_all, pd_context, pd_inner = self(stu_id, exer_id, Q_mat, QQQ_list)
         pd_all, pd_context, pd_inner = pd_all.flatten(), pd_context.flatten(), pd_inner.flatten()
         loss_all = F.binary_cross_entropy(input=pd_all, target=label)
         loss_context = F.binary_cross_entropy(input=pd_context, target=label)
         loss_inner = F.binary_cross_entropy(input=pd_inner, target=label)
-        w = self.model_cfg['loss_weight']
+        w = self.modeltpl_cfg['loss_weight']
         # loss = loss_all+w[0]*loss_context+w[1]*loss_inner
         return {
             'loss_main': loss_all,
             'loss_context': w[0] * loss_context,
             'loss_inner': w[1] * loss_inner
         }
 
@@ -234,26 +252,26 @@
     }
     def build_model(self):
         super().build_model()
         self.student_emb = nn.Embedding(self.n_user, self.n_cpt)
         self.k_difficulty = nn.Embedding(self.n_item, self.n_cpt)
         self.e_difficulty = nn.Embedding(self.n_item, 1)
         self.pd_net = PosMLP(
-            input_dim=self.n_cpt, output_dim=1, activation=self.model_cfg['activation'],
-            dnn_units=self.model_cfg['dnn_units'], dropout_rate=self.model_cfg['dropout_rate']
+            input_dim=self.n_cpt, output_dim=1, activation=self.modeltpl_cfg['activation'],
+            dnn_units=self.modeltpl_cfg['dnn_units'], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
 
     def forward(self, stu_id, exer_id, Q_mat, QQQ_list):
         items_Q_mat = Q_mat[exer_id]
         stus_qqq = QQQ_list[stu_id]
 
         stu_emb = self.student_emb(stu_id)
         theta_inner = torch.sigmoid(stu_emb)
         k_difficulty = torch.sigmoid(self.k_difficulty(exer_id))
-        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.model_cfg['disc_scale']
+        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.modeltpl_cfg['disc_scale']
         # prednet
         input_knowledge_point = items_Q_mat
         theta_context, dt_w = super().forward(stu_id, stus_qqq)
         theta_all = theta_context * dt_w + theta_inner * (1 - dt_w)
 
         pre_all = self.pd_net(e_difficulty * (theta_all - k_difficulty) * input_knowledge_point).sigmoid()
         pre_context = self.pd_net(e_difficulty * (theta_context - k_difficulty) * input_knowledge_point).sigmoid()
@@ -278,15 +296,15 @@
         Q_mat = kwargs['Q_mat']
         QQQ_list = kwargs['QQQ_list']
         pd_all, pd_context, pd_inner = self(stu_id, exer_id, Q_mat, QQQ_list)
         pd_all, pd_context, pd_inner = pd_all.flatten(), pd_context.flatten(), pd_inner.flatten()
         loss_all = F.binary_cross_entropy(input=pd_all, target=label)
         loss_context = F.binary_cross_entropy(input=pd_context, target=label)
         loss_inner = F.binary_cross_entropy(input=pd_inner, target=label)
-        w = self.model_cfg['loss_weight']
+        w = self.modeltpl_cfg['loss_weight']
         # loss = loss_all+w[0]*loss_context+w[1]*loss_inner
         return {
             'loss_main': loss_all,
             'loss_context': w[0]*loss_context,
             'loss_inner': w[1]*loss_inner
         }
```

## edustudio/model/CD/hier_cdf.py

```diff
@@ -1,7 +1,20 @@
+r"""
+HierCDF
+##########################################
+
+Reference:
+    Jiatong Li et al. "HierCDF: A Bayesian Network-Based Hierarchical Cognitive Diagnosis Framework" in KDD 2022.
+
+Reference Code:
+    https://github.com/CSLiJT/HCD-code
+
+"""
+
+
 import torch
 import torch.nn as nn
 import networkx as nx
 from ..gd_basemodel import GDBaseModel
 import numpy as np 
 import pandas as pd 
 from ..utils.components import PosLinear
@@ -32,19 +45,19 @@
         'hidden_dim': 1,
         'lambda': 0.001, 
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.hidden_dim = self.model_cfg['hidden_dim']
-        self.itf_type = self.model_cfg['itf_type']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.hidden_dim = self.modeltpl_cfg['hidden_dim']
+        self.itf_type = self.modeltpl_cfg['itf_type']
 
         self.set_itf(self.itf_type)
 
     def build_model(self):
         # the conditional mastery degree when parent is mastered
         self.condi_p = nn.Embedding(self.n_user, self.know_graph.shape[0])
 
@@ -101,15 +114,15 @@
             # for each knowledge k, do:
             if len_p == 0:
                 priori = batch_priori[:,k]
                 posterior[:,k] = priori.reshape(-1)
                 continue
 
             # format of masks
-            fmt = '{0:0%db}'%(len_p)
+            tpl = '{0:0%db}'%(len_p)
             # number of parent master condition
             n_condi = 2 ** len_p
 
             priori = posterior[:,predecessors]
 
 
             pred_idx = self.know_graph[self.know_graph['cpt_tail'] == k].sort_values(by='cpt_head').index
@@ -119,15 +132,15 @@
             margin_p = condi_p * priori
             margin_n = condi_n * (1.0-priori)
 
             posterior_k = torch.zeros((1,n_batch)).to(self.device)
 
             for idx in range(n_condi):
                 # for each parent mastery condition, do:
-                mask = fmt.format(idx)
+                mask = tpl.format(idx)
                 mask = torch.Tensor(np.array(list(mask)).astype(int)).to(self.device)
 
                 margin = mask * margin_p + (1-mask) * margin_n
                 margin = torch.prod(margin, dim = 1).unsqueeze(dim = 0)
 
                 posterior_k = torch.cat([posterior_k, margin], dim = 0)
             posterior_k = (torch.sum(posterior_k, dim = 0)).squeeze()
@@ -207,15 +220,15 @@
         return {
             'loss_main': loss
         }
 
     def get_J_loss(self, **kwargs):
         stu_id = kwargs['stu_id']
         return {
-            'loss_J': self.model_cfg['lambda'] * \
+            'loss_J': self.modeltpl_cfg['lambda'] * \
                 torch.sum(torch.relu(self.condi_n(stu_id)-self.condi_p(stu_id)))
         }
     
     def get_loss_dict(self, **kwargs):
         ret_dict = self.get_main_loss(**kwargs)
         ret_dict.update(self.get_J_loss(**kwargs))
         return ret_dict
```

## edustudio/model/CD/irr.py

```diff
@@ -1,13 +1,20 @@
+r"""
+IRR
+##################################
+Reference:
+    Tong et al. "Item Response Ranking for Cognitive Diagnosis." in IJCAI 2021.
+"""
 from ..basemodel import BaseProxyModel
 import torch
 import torch.nn as nn
 
 
 class PairSCELoss(nn.Module):
+    """IRR loss function"""
     def __init__(self):
         super(PairSCELoss, self).__init__()
         self._loss = nn.CrossEntropyLoss()
 
     def forward(self, pred1, pred2, sign=1, *args):
         """
         sign is either 1 or -1
@@ -16,14 +23,17 @@
         -1: otherwise
         """
         pred = torch.stack([pred1, pred2], dim=1)
         return self._loss(pred, ((torch.ones(pred1.shape[0], device=pred.device) - sign) / 2).long())
 
 
 class IRR(BaseProxyModel):
+    """
+    backbone_model_cls: The backbone model of IRR
+    """
     default_cfg = {
         "backbone_model_cls": "IRT",
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
```

## edustudio/model/CD/irt.py

```diff
@@ -1,59 +1,62 @@
+r"""
+IRT
+##########################################
+
+Reference Code:
+    https://github.com/bigdata-ustc/EduCDM/tree/main/EduCDM/IRT
+
 """
-    # reference: https://github.com/bigdata-ustc/EduCDM/blob/main/EduCDM/IRT/GD/IRT.py
-    IRT 三种形式
-"""
+
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from ..gd_basemodel import GDBaseModel
 
 
 class IRT(GDBaseModel):
-    """
-        第一种: fix_a = True, fix_c = True
-        第二种: fix_a = False, fix_c = True
-        第三种: fix_a = False, fix_c = False
+    r"""
+    IRT
     """
     default_cfg = {
         "a_range": -1.0, # disc range
         "diff_range": -1.0, # diff range
         "fix_a": False,
         "fix_c": True,
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        if self.model_cfg['a_range']  < 0: self.model_cfg['a_range'] = None
-        if self.model_cfg['diff_range'] < 0: self.model_cfg['diff_range'] = None
+        if self.modeltpl_cfg['a_range']  < 0: self.modeltpl_cfg['a_range'] = None
+        if self.modeltpl_cfg['diff_range'] < 0: self.modeltpl_cfg['diff_range'] = None
 
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
 
         # 确保c固定时，a一定不能固定
-        if self.model_cfg['fix_c'] is False: assert self.model_cfg['fix_a'] is False
+        if self.modeltpl_cfg['fix_c'] is False: assert self.modeltpl_cfg['fix_a'] is False
 
     def build_model(self):
         self.theta = nn.Embedding(self.n_user, 1) # student ability
-        self.a = 0.0 if self.model_cfg['fix_a'] else nn.Embedding(self.n_item, 1) # exer discrimination
+        self.a = 0.0 if self.modeltpl_cfg['fix_a'] else nn.Embedding(self.n_item, 1) # exer discrimination
         self.b = nn.Embedding(self.n_item, 1) # exer difficulty
-        self.c = 0.0 if self.model_cfg['fix_c'] else nn.Embedding(self.n_item, 1)
+        self.c = 0.0 if self.modeltpl_cfg['fix_c'] else nn.Embedding(self.n_item, 1)
 
     def forward(self, stu_id, exer_id, **kwargs):
         theta = self.theta(stu_id)
         a = self.a(exer_id)
         b = self.b(exer_id)
-        c = self.c if self.model_cfg['fix_c'] else self.c(exer_id).sigmoid()
+        c = self.c if self.modeltpl_cfg['fix_c'] else self.c(exer_id).sigmoid()
 
-        if self.model_cfg['diff_range'] is not None:
-            b = self.model_cfg['diff_range'] * (torch.sigmoid(b) - 0.5)
-        if self.model_cfg['a_range'] is not None:
-            a = self.model_cfg['a_range'] * torch.sigmoid(a)
+        if self.modeltpl_cfg['diff_range'] is not None:
+            b = self.modeltpl_cfg['diff_range'] * (torch.sigmoid(b) - 0.5)
+        if self.modeltpl_cfg['a_range'] is not None:
+            a = self.modeltpl_cfg['a_range'] * torch.sigmoid(a)
         else:
             a = F.softplus(a) # 让区分度大于0，保持单调性假设
         if torch.max(theta != theta) or torch.max(a != a) or torch.max(b != b):  # pragma: no cover
             raise ValueError('ValueError:theta,a,b may contains nan!  The diff_range or a_range is too large.')
         return self.irf(theta, a, b, c)
 
     @staticmethod
```

## edustudio/model/CD/kancd.py

```diff
@@ -1,7 +1,19 @@
+r"""
+KaNCD
+##########################################
+
+Reference:
+    Fei Wang et al. "NeuralCD: A General Framework for Cognitive Diagnosis" in TKDE 2022.
+
+Reference Code:
+    https://github.com/bigdata-ustc/EduCDM/tree/main/EduCDM/KaNCD
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 from ..utils.components import PosLinear
 import torch
 import torch.nn.functional as F
 
 
@@ -11,24 +23,27 @@
         'prednet_len1': 256,
         'prednet_len2': 128,
         'emb_dim': 20,
         'mf_type': 'gmf'
     }
     def __init__(self, cfg):
         super().__init__(cfg)
-        assert self.model_cfg['mf_type'] in ['mf', 'gmf', 'ncf1', 'ncf2']
+        assert self.modeltpl_cfg['mf_type'] in ['mf', 'gmf', 'ncf1', 'ncf2']
+
+    def add_extra_data(self, **kwargs):
+        self.Q_mat = kwargs['Q_mat'].to(self.device)
 
     def build_cfg(self):
-        self.knowledge_n = self.datafmt_cfg['dt_info']['cpt_count']
-        self.exer_n = self.datafmt_cfg['dt_info']['exer_count']
-        self.student_n = self.datafmt_cfg['dt_info']['stu_count']
-        self.emb_dim = self.model_cfg['emb_dim']
-        self.mf_type = self.model_cfg['mf_type']
+        self.knowledge_n = self.datatpl_cfg['dt_info']['cpt_count']
+        self.exer_n = self.datatpl_cfg['dt_info']['exer_count']
+        self.student_n = self.datatpl_cfg['dt_info']['stu_count']
+        self.emb_dim = self.modeltpl_cfg['emb_dim']
+        self.mf_type = self.modeltpl_cfg['mf_type']
         self.prednet_input_len = self.knowledge_n
-        self.prednet_len1, self.prednet_len2 = self.model_cfg['prednet_len1'], self.model_cfg['prednet_len2']
+        self.prednet_len1, self.prednet_len2 = self.modeltpl_cfg['prednet_len1'], self.modeltpl_cfg['prednet_len2']
 
     def build_model(self):
         # prediction sub-net
         self.student_emb = nn.Embedding(self.student_n, self.emb_dim)
         self.exercise_emb = nn.Embedding(self.exer_n, self.emb_dim)
         self.knowledge_emb = nn.Parameter(torch.zeros(self.knowledge_n, self.emb_dim))
         self.e_discrimination = nn.Embedding(self.exer_n, 1)
@@ -48,17 +63,17 @@
             self.k_diff_full1 = nn.Linear(2 * self.emb_dim, self.emb_dim)
             self.k_diff_full2 = nn.Linear(self.emb_dim, 1)
             self.stat_full1 = nn.Linear(2 * self.emb_dim, self.emb_dim)
             self.stat_full2 = nn.Linear(self.emb_dim, 1)
 
         nn.init.xavier_normal_(self.knowledge_emb)
 
-    def forward(self, stu_id, exer_id, Q_mat, **kwargs):
+    def forward(self, stu_id, exer_id, **kwargs):
         input_exercise = exer_id
-        input_knowledge_point = Q_mat[exer_id]
+        input_knowledge_point = self.Q_mat[exer_id]
         # before prednet
         stu_emb = self.student_emb(stu_id)
         exer_emb = self.exercise_emb(input_exercise)
         # get knowledge proficiency
         batch, dim = stu_emb.size()
         stu_emb = stu_emb.view(batch, 1, dim).repeat(1, self.knowledge_n, 1)
         knowledge_emb = self.knowledge_emb.repeat(batch, 1).view(batch, self.knowledge_n, -1)
@@ -94,28 +109,27 @@
 
         return output_1.view(-1)
     
     def get_main_loss(self, **kwargs):
         stu_id = kwargs['stu_id']
         exer_id = kwargs['exer_id']
         label = kwargs['label']
-        Q_mat = kwargs['Q_mat']
-        pd = self(stu_id, exer_id, Q_mat).flatten()
+        pd = self(stu_id, exer_id).flatten()
         loss = F.binary_cross_entropy(input=pd, target=label)
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
     
     @torch.no_grad()
-    def predict(self, stu_id, exer_id, Q_mat, **kwargs):
+    def predict(self, stu_id, exer_id,**kwargs):
         return {
-            'y_pd': self(stu_id, exer_id, Q_mat).flatten(),
+            'y_pd': self(stu_id, exer_id).flatten(),
         }
 
     def get_stu_status(self, stu_id=None):
         if stu_id is not None:
             stu_emb = self.student_emb(stu_id)
         else:
             stu_emb = self.student_emb.weight
```

## edustudio/model/CD/kscd.py

```diff
@@ -1,7 +1,19 @@
+r"""
+KSCD
+##########################################
+
+Reference:
+    Haiping Ma et al. "Knowledge-Sensed Cognitive Diagnosis for Intelligent Education Platforms" in CIKM 2022.
+
+Reference Code:
+    https://github.com/BIMK/Intelligent-Education/tree/main/KSCD_Code_F
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 from ..utils.components import PosMLP, PosLinear
 
 
@@ -19,96 +31,98 @@
         'interaction_type_kscd': {
             'dropout_rate': 0.0,
         }
     }
     def __init__(self, cfg):
         super().__init__(cfg)    
 
+    def add_extra_data(self, **kwargs):
+        self.Q_mat = kwargs['Q_mat'].to(self.device)
+
     def build_cfg(self):
-        self.stu_count = self.datafmt_cfg['dt_info']['stu_count']
-        self.exer_count = self.datafmt_cfg['dt_info']['exer_count']
-        self.cpt_count = self.datafmt_cfg['dt_info']['cpt_count']
+        self.stu_count = self.datatpl_cfg['dt_info']['stu_count']
+        self.exer_count = self.datatpl_cfg['dt_info']['exer_count']
+        self.cpt_count = self.datatpl_cfg['dt_info']['cpt_count']
     
-        self.lowdim = self.model_cfg['emb_dim']
-        self.interaction_type = self.model_cfg['interaction_type']
+        self.lowdim = self.modeltpl_cfg['emb_dim']
+        self.interaction_type = self.modeltpl_cfg['interaction_type']
 
     def build_model(self):
         self.stu_emb = nn.Embedding(self.stu_count, self.lowdim)
         self.cpt_emb = nn.Embedding(self.cpt_count, self.lowdim)
         self.exer_emb = nn.Embedding(self.exer_count, self.lowdim)
 
-        if self.model_cfg['interaction_type'] == 'ncdm':
+        if self.modeltpl_cfg['interaction_type'] == 'ncdm':
             # self.exer_disc_infer = nn.Linear(self.lowdim, 1)
             self.layer1 = nn.Linear(self.lowdim, 1)
             self.pd_net = PosMLP(
                 input_dim=self.cpt_count, output_dim=1, 
-                activation=self.model_cfg['interaction_type_ncdm']['activation'],
-                dnn_units=self.model_cfg['interaction_type_ncdm']['dnn_units'], 
-                dropout_rate=self.model_cfg['interaction_type_ncdm']['dropout_rate']
+                activation=self.modeltpl_cfg['interaction_type_ncdm']['activation'],
+                dnn_units=self.modeltpl_cfg['interaction_type_ncdm']['dnn_units'], 
+                dropout_rate=self.modeltpl_cfg['interaction_type_ncdm']['dropout_rate']
             )
-        elif self.model_cfg['interaction_type'] == 'kscd':
+        elif self.modeltpl_cfg['interaction_type'] == 'kscd':
             self.prednet_full1 = PosLinear(self.cpt_count + self.lowdim, self.cpt_count, bias=False)
-            self.drop_1 = nn.Dropout(p=self.model_cfg['interaction_type_kscd']['dropout_rate'])
+            self.drop_1 = nn.Dropout(p=self.modeltpl_cfg['interaction_type_kscd']['dropout_rate'])
             self.prednet_full2 = PosLinear(self.cpt_count + self.lowdim, self.cpt_count, bias=False)
-            self.drop_2 = nn.Dropout(p=self.model_cfg['interaction_type_kscd']['dropout_rate'])
+            self.drop_2 = nn.Dropout(p=self.modeltpl_cfg['interaction_type_kscd']['dropout_rate'])
             self.prednet_full3 = PosLinear(1 * self.cpt_count, 1)
         else:
-            raise ValueError(f"unknown interaction_type: {self.model_cfg['interaction_type']}")
+            raise ValueError(f"unknown interaction_type: {self.modeltpl_cfg['interaction_type']}")
 
-    def forward(self, stu_id, exer_id, Q_mat, **kwargs):
+    def forward(self, stu_id, exer_id, **kwargs):
         
         stu_emb = self.stu_emb(stu_id)
         exer_emb = self.exer_emb(exer_id)
-        exer_q_mat = Q_mat[exer_id]
+        exer_q_mat = self.Q_mat[exer_id]
 
         stu_ability = torch.mm(stu_emb, self.cpt_emb.weight.T).sigmoid()
         exer_diff = torch.mm(exer_emb, self.cpt_emb.weight.T).sigmoid()
         
-        if self.model_cfg['interaction_type'] == 'ncdm':
-            # exer_disc = self.exer_disc_infer(exer_emb).sigmoid() * self.model_cfg['interaction_type_ncdm']['disc_scale']
-            exer_disc = torch.sigmoid(self.layer1(exer_emb)) * self.model_cfg['interaction_type_ncdm']['disc_scale']
+        if self.modeltpl_cfg['interaction_type'] == 'ncdm':
+            # exer_disc = self.exer_disc_infer(exer_emb).sigmoid() * self.modeltpl_cfg['interaction_type_ncdm']['disc_scale']
+            exer_disc = torch.sigmoid(self.layer1(exer_emb)) * self.modeltpl_cfg['interaction_type_ncdm']['disc_scale']
             input_x = exer_disc * (stu_ability - exer_diff) * exer_q_mat
             y_pd = self.pd_net(input_x).sigmoid()
-        elif self.model_cfg['interaction_type'] == 'kscd':
+        elif self.modeltpl_cfg['interaction_type'] == 'kscd':
             batch_stu_vector = stu_ability.repeat(1, self.cpt_count).reshape(stu_ability.shape[0], self.cpt_count, stu_ability.shape[1])
             batch_exer_vector = exer_diff.repeat(1, self.cpt_count).reshape(exer_diff.shape[0], self.cpt_count, exer_diff.shape[1])
 
             kn_vector = self.cpt_emb.weight.repeat(stu_ability.shape[0], 1).reshape(stu_ability.shape[0], self.cpt_count, self.lowdim)
 
             # CD
             preference = torch.sigmoid(self.prednet_full1(torch.cat((batch_stu_vector, kn_vector), dim=2)))
             diff = torch.sigmoid(self.prednet_full2(torch.cat((batch_exer_vector, kn_vector), dim=2)))
             o = torch.sigmoid(self.prednet_full3(preference - diff))
 
             sum_out = torch.sum(o * exer_q_mat.unsqueeze(2), dim=1)
             count_of_concept = torch.sum(exer_q_mat, dim=1).unsqueeze(1)
             y_pd = sum_out / count_of_concept
         else:
-            raise ValueError(f"unknown interaction_type: {self.model_cfg['interaction_type']}")
+            raise ValueError(f"unknown interaction_type: {self.modeltpl_cfg['interaction_type']}")
 
         return y_pd
 
     def get_main_loss(self, **kwargs):
         stu_id = kwargs['stu_id']
         exer_id = kwargs['exer_id']
         label = kwargs['label']
-        Q_mat = kwargs['Q_mat']
-        pd = self(stu_id=stu_id, exer_id=exer_id, Q_mat=Q_mat).flatten()
+        pd = self(stu_id=stu_id, exer_id=exer_id).flatten()
         loss = F.binary_cross_entropy(input=pd, target=label)
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
     
     @torch.no_grad()
-    def predict(self, stu_id, exer_id, Q_mat, **kwargs):
+    def predict(self, stu_id, exer_id, **kwargs):
         return {
-            'y_pd': self(stu_id=stu_id, exer_id=exer_id, Q_mat=Q_mat).flatten(),
+            'y_pd': self(stu_id=stu_id, exer_id=exer_id).flatten(),
         }
 
     def get_stu_status(self, stu_id=None):
         if stu_id is not None:
             stu_emb = self.stu_emb(stu_id)
         else:
             stu_emb = self.stu_emb.weight
```

## edustudio/model/CD/mgcd.py

```diff
@@ -1,16 +1,26 @@
+r"""
+MGCD
+##################################
+Reference:
+    Huang et al. "Group-level cognitive diagnosis: A multi-task learning perspective." in ICDM 2021.
+"""
 import numpy as np
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 from ..utils.components import PosMLP
 import torch
 import torch.nn.functional as F
 
 
 class MGCD(GDBaseModel):
+    """
+    prednet_len1: The dimension of the first hidden layer of the fully connected layer before predicting the score
+    prednet_len2: The dimension of the second hidden layer of the fully connected layer before predicting the score
+    """
     default_cfg = {
         'prednet_len1': 128,
         'prednet_len2': 64,
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
@@ -33,21 +43,21 @@
             if stu_id not in self.stu2exe:
                 self.stu2exe[stu_id] = [exer_id]
             else:
                 self.stu2exe[stu_id].append(exer_id)
             self.stu_exe2label[(stu_id, exer_id)] = label
 
     def build_cfg(self):
-        self.group_n = self.datafmt_cfg['dt_info']['group_count']
-        self.exer_n = self.datafmt_cfg['dt_info']['exer_count']
-        self.knowledge_dim = self.datafmt_cfg['dt_info']['cpt_count']
+        self.group_n = self.datatpl_cfg['dt_info']['group_count']
+        self.exer_n = self.datatpl_cfg['dt_info']['exer_count']
+        self.knowledge_dim = self.datatpl_cfg['dt_info']['cpt_count']
         self.stu_dim = self.knowledge_dim
         self.prednet_input_len = self.knowledge_dim
-        self.prednet_len1 = self.model_cfg['prednet_len1']
-        self.prednet_len2 = self.model_cfg['prednet_len2']
+        self.prednet_len1 = self.modeltpl_cfg['prednet_len1']
+        self.prednet_len2 = self.modeltpl_cfg['prednet_len2']
         self.num_hidden = self.stu_dim
 
 
     def build_model(self):
         self.R = nn.Embedding(self.stu_n, self.stu_dim)
         # h
         self.h = nn.Parameter(torch.randn(self.stu_dim, 1, requires_grad=True))
@@ -180,14 +190,17 @@
         if stu_id is not None:
             return self.W_c(stu_id)
         else:
             return self.W_c.weight
 
 
 class NoneNegClipper(object):
+    """
+    Make the parameters of the fully connected layer non-negative
+    """
     def __init__(self):
         super(NoneNegClipper, self).__init__()
 
     def __call__(self, module):
         if hasattr(module, 'weight'):
             w = module.weight.data
             a = torch.relu(torch.neg(w))
```

## edustudio/model/CD/mirt.py

```diff
@@ -1,11 +1,19 @@
+r"""
+MIRT
+##########################################
+
+Reference:
+    Mark D Reckase et al. "Multidimensional item response theory models". Springer, 2009.
+
+Reference Code:
+    https://github.com/bigdata-ustc/EduCDM/tree/main/EduCDM/MIRT
+
 """
-    # reference: https://github.com/bigdata-ustc/EduCDM/blob/main/EduCDM/MIRT/MIRT.py
-    MIRT经典形式
-"""
+
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from ..gd_basemodel import GDBaseModel
 
 
 class MIRT(GDBaseModel):
@@ -18,32 +26,32 @@
         "a_range": -1.0, # disc range
         "emb_dim": 32
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        if self.model_cfg['a_range']  < 0: self.model_cfg['a_range'] = None
+        if self.modeltpl_cfg['a_range']  < 0: self.modeltpl_cfg['a_range'] = None
 
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.emb_dim = self.model_cfg['emb_dim']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.emb_dim = self.modeltpl_cfg['emb_dim']
 
     def build_model(self):
         self.theta = nn.Embedding(self.n_user, self.emb_dim) # student ability
         self.a = nn.Embedding(self.n_item, self.emb_dim) # exer discrimination
         self.b = nn.Embedding(self.n_item, 1) # exer intercept term
 
     def forward(self, stu_id, exer_id, **kwargs):
         theta = self.theta(stu_id)
         a = self.a(exer_id)
         b = self.b(exer_id).flatten()
 
-        if self.model_cfg['a_range'] is not None:
-            a = self.model_cfg['a_range'] * torch.sigmoid(a)
+        if self.modeltpl_cfg['a_range'] is not None:
+            a = self.modeltpl_cfg['a_range'] * torch.sigmoid(a)
         else:
             a = F.softplus(a) # 让区分度大于0，保持单调性假设
         if torch.max(theta != theta) or torch.max(a != a) or torch.max(b != b):  # pragma: no cover
             raise ValueError('ValueError:theta,a,b may contains nan!  The diff_range or a_range is too large.')
         return self.irf(theta, a, b)
 
     @staticmethod
```

## edustudio/model/CD/ncdm.py

```diff
@@ -1,64 +1,90 @@
+r"""
+NCDM
+##########################################
+
+Reference:
+    Fei Wang et al. "Neural Cognitive Diagnosis for Intelligent Education Systems" in AAAI 2020.
+
+Reference Code:
+    https://github.com/bigdata-ustc/Neural_Cognitive_Diagnosis-NeuralCD
+    https://github.com/bigdata-ustc/EduCDM/tree/main/EduCDM/NCDM
+
+"""
+
+from typing import Any
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 from ..utils.components import PosMLP
 import torch
 import torch.nn.functional as F
 
 
 class NCDM(GDBaseModel):
+    r"""
+    NCDM
+
+    default_cfg:
+        'dnn_units': [512, 256]  # dimension list of hidden layer in prediction layer
+        'dropout_rate': 0.5      # dropout rate
+        'activation': 'sigmoid'  # activation function in prediction layer
+        'disc_scale': 10         # discrimination scale
+    """
+    
     default_cfg = {
         'dnn_units': [512, 256],
         'dropout_rate': 0.5,
         'activation': 'sigmoid',
         'disc_scale': 10
     }
+
     def __init__(self, cfg):
         super().__init__(cfg)
 
+    def add_extra_data(self, **kwargs):
+        self.Q_mat = kwargs['Q_mat'].to(self.device)
+
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def build_model(self):
         # prediction sub-net
         self.student_emb = nn.Embedding(self.n_user, self.n_cpt)
         self.k_difficulty = nn.Embedding(self.n_item, self.n_cpt)
         self.e_difficulty = nn.Embedding(self.n_item, 1)
         self.pd_net = PosMLP(
-            input_dim=self.n_cpt, output_dim=1, activation=self.model_cfg['activation'],
-            dnn_units=self.model_cfg['dnn_units'], dropout_rate=self.model_cfg['dropout_rate']
+            input_dim=self.n_cpt, output_dim=1, activation=self.modeltpl_cfg['activation'],
+            dnn_units=self.modeltpl_cfg['dnn_units'], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
 
-    def forward(self, stu_id, exer_id, Q_mat, **kwargs):
+    def forward(self, stu_id, exer_id, **kwargs):
         # before prednet
-        items_Q_mat = Q_mat[exer_id]
         stu_emb = self.student_emb(stu_id)
         stat_emb = torch.sigmoid(stu_emb)
         k_difficulty = torch.sigmoid(self.k_difficulty(exer_id))
-        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.model_cfg['disc_scale']
+        e_difficulty = torch.sigmoid(self.e_difficulty(exer_id)) * self.modeltpl_cfg['disc_scale']
         # prednet
-        input_knowledge_point = items_Q_mat
+        input_knowledge_point = self.Q_mat[exer_id]
         input_x = e_difficulty * (stat_emb - k_difficulty) * input_knowledge_point
         pd = self.pd_net(input_x).sigmoid()
         return pd
 
     @torch.no_grad()
-    def predict(self, stu_id, exer_id, Q_mat, **kwargs):
+    def predict(self, stu_id, exer_id, **kwargs):
         return {
-            'y_pd': self(stu_id, exer_id, Q_mat).flatten(),
+            'y_pd': self(stu_id, exer_id).flatten(),
         }
 
     def get_main_loss(self, **kwargs):
         stu_id = kwargs['stu_id']
         exer_id = kwargs['exer_id']
         label = kwargs['label']
-        Q_mat = kwargs['Q_mat']
-        pd = self(stu_id, exer_id, Q_mat).flatten()
+        pd = self(stu_id, exer_id).flatten()
         loss = F.binary_cross_entropy(input=pd, target=label)
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
```

## edustudio/model/CD/rcd.py

```diff
@@ -116,28 +116,28 @@
         'prednet_len1': 512,
         'prednet_len2': 256
     }
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def add_extra_data(self, **kwargs):
         self.local_map = kwargs.pop('local_map')
 
     def build_model(self):
         self.knowledge_dim = self.n_cpt
         self.exer_n = self.n_item
         self.emb_num = self.n_user
         self.stu_dim = self.knowledge_dim
         self.prednet_input_len = self.knowledge_dim
-        self.prednet_len1, self.prednet_len2 = self.model_cfg['prednet_len1'], self.model_cfg['prednet_len2']
+        self.prednet_len1, self.prednet_len2 = self.modeltpl_cfg['prednet_len1'], self.modeltpl_cfg['prednet_len2']
         self.directed_g = self.local_map['directed_g'].to(self.device)
         self.undirected_g = self.local_map['undirected_g'].to(self.device)
         self.k_from_e = self.local_map['k_from_e'].to(self.device)
         self.e_from_k = self.local_map['e_from_k'].to(self.device)
         self.u_from_e = self.local_map['u_from_e'].to(self.device)
         self.e_from_u = self.local_map['e_from_u'].to(self.device)
```

## edustudio/model/KT/__init__.py

```diff
@@ -3,15 +3,15 @@
 from .dkt_plus import DKT_plus
 from .iekt import IEKT
 from .dkt_forget import DKTForget
 from .akt import AKT
 from .ckt import CKT
 from .hawkeskt import HawkesKT
 from .kqn import KQN
-from .deep_irt import DEEP_IRT
+from .deep_irt import DeepIRT
 from .sakt import SAKT
 from .dkt_dsc import DKTDSC
 from .lpkt import LPKT
 from .simplekt import SimpleKT
 from .saint import SAINT
 from .skvmn import SKVMN
 from .saint_plus import SAINT_plus
```

## edustudio/model/KT/akt.py

```diff
@@ -1,17 +1,44 @@
+r"""
+AKT
+##########################################
+
+Reference:
+    Aritra Ghosh et al. "Context-Aware Attentive Knowledge Tracing" in KDD 2020.
+
+Reference Code:
+    https://github.com/pykt-team/pykt-toolkit/blob/main/pykt/models/akt.py
+    https://github.com/arghosh/AKT
+
+"""
 import math
 
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 import numpy as np
 from torch.nn.init import xavier_uniform_, constant_
 
 class AKT(GDBaseModel):
+    r"""
+    AKT
+
+    default_cfg:
+        'l2': 1e-5              # weight of l2 regularization
+        'kq_same': 1              # if k and q share the same structure, 1 denotes yes,0 denotes no,used in MultiHeadAttention
+        'dropout_rate': 0.05      # dropout rate
+        'separate_qa': False      # Whether to separate questions and answers
+        'd_model': 256      # dimension of attention input/output
+        'n_blocks':1      # number of stacked blocks in the attention
+        'final_fc_dim': 512      # dimension of final fully connected net before prediction
+        'n_heads': 8      # number of heads. n_heads*d_feature = d_model
+        'd_ff': 2048      # dimension for fully conntected net inside the basic block
+    """
+
     default_cfg = {
         'l2': 1e-5,
         'kq_same': 1,
         'dropout_rate': 0.05,
         'separate_qa': False,
         'd_model': 256,
         'n_blocks':1,
@@ -24,26 +51,26 @@
         self.reset()
 
     def reset(self):
         for p in self.parameters():
             if p.size(0) == self.n_pid + 1 and self.n_pid > 0:
                 constant_(p, 0.)
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_question = self.datafmt_cfg['dt_info']['cpt_count']
-        self.dropout = self.model_cfg['dropout_rate']
-        self.kq_same = self.model_cfg['kq_same']
-        self.l2 = self.model_cfg['l2']
-        self.separate_qa = self.model_cfg['separate_qa']
-        self.d_model = self.model_cfg['d_model']
-        self.n_blocks = self.model_cfg['n_blocks']
-        self.final_fc_dim = self.model_cfg['final_fc_dim']
-        self.n_heads = self.model_cfg['n_heads']
-        self.d_ff = self.model_cfg['d_ff']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_question = self.datatpl_cfg['dt_info']['cpt_count']
+        self.dropout = self.modeltpl_cfg['dropout_rate']
+        self.kq_same = self.modeltpl_cfg['kq_same']
+        self.l2 = self.modeltpl_cfg['l2']
+        self.separate_qa = self.modeltpl_cfg['separate_qa']
+        self.d_model = self.modeltpl_cfg['d_model']
+        self.n_blocks = self.modeltpl_cfg['n_blocks']
+        self.final_fc_dim = self.modeltpl_cfg['final_fc_dim']
+        self.n_heads = self.modeltpl_cfg['n_heads']
+        self.d_ff = self.modeltpl_cfg['d_ff']
         
     def build_model(self):
         embed_l = self.d_model
         self.n_pid = self.n_item
         if self.n_pid > 0:
             self.difficult_param = nn.Embedding(self.n_pid + 1, 1)
             self.q_embed_diff = nn.Embedding(self.n_question + 1, embed_l)
```

## edustudio/model/KT/atkt.py

```diff
@@ -1,59 +1,98 @@
+r"""
+ATKT
+##################################
+Reference:
+    Xiaopeng Guo et al. "Enhancing knowledge tracing via adversarial training." in MM 2021.
+Reference code:
+    https://github.com/xiaopengguo/ATKT
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
 class ATKT(GDBaseModel):
+    """
+    skill_dim: dimensions of knowledge concept representation
+    answer_dim: representation dimensions of students' answers to exercises
+    hidden_dim: dimensions of the hidden layer between the convolutional neural network and the output layer
+    attention_dim: dimensions of parameters in the attention mechanism
+    """
     default_cfg = {
         'skill_dim': 256,
         'answer_dim': 96,
         'hidden_dim': 80,
         'attention_dim': 80,
     }
 
     def __init__(self, cfg):
+        """Pass parameters from other templates into the model
+
+        Args:
+            cfg (UnifyConfig): parameters from other templates
+        """
         super().__init__(cfg)
 
     def _init_params(self):
-        # super()._init_params()
+        """Skip initialization of parameters for individual components of the model"""
         pass
 
     def build_cfg(self):
-        self.output_dim = self.datafmt_cfg['dt_info']['cpt_count']
-        self.skill_dim = self.model_cfg['skill_dim']
-        self.answer_dim = self.model_cfg['answer_dim']
-        self.hidden_dim = self.model_cfg['hidden_dim']
-        self.attention_dim = self.model_cfg['attention_dim']
+        """Initialize the parameters of the model"""
+        self.output_dim = self.datatpl_cfg['dt_info']['cpt_count']
+        self.skill_dim = self.modeltpl_cfg['skill_dim']
+        self.answer_dim = self.modeltpl_cfg['answer_dim']
+        self.hidden_dim = self.modeltpl_cfg['hidden_dim']
+        self.attention_dim = self.modeltpl_cfg['attention_dim']
 
     def build_model(self):
+        """Initialize the various components of the model"""
         self.rnn = nn.LSTM(self.skill_dim+self.answer_dim, self.hidden_dim, batch_first=True)
         self.fc = nn.Linear(self.hidden_dim*2, self.output_dim)
         self.sig = nn.Sigmoid()
         
         self.skill_emb = nn.Embedding(self.output_dim+1, self.skill_dim)
         self.skill_emb.weight.data[-1]= 0
         
         self.answer_emb = nn.Embedding(2+1, self.answer_dim)
         self.answer_emb.weight.data[-1]= 0
 
         self.mlp = nn.Linear(self.hidden_dim, self.attention_dim)
         self.similarity = nn.Linear(self.attention_dim, 1, bias=False)
 
     def _get_next_pred(self, res, skill):
+        """Get how well the model predicts students' responses to exercise questions
+
+        Args:
+            res (torch.Tensor): Shape of [batch_size, seq_len-1, 123]
+            skill (torch.Tensor): Sequence of knowledge concepts related to exercises. Shape of [batch_size, seq_len]
+
+        Returns:
+            torch.Tensor: the model predictions of students' responses to exercise questions. Shape of [batch_size, seq_len-1]
+        """
         one_hot = torch.eye(self.output_dim, device=res.device)
-        one_hot = torch.cat((one_hot, torch.zeros(1, self.output_dim)), dim=0)
+        one_hot = torch.cat((one_hot, torch.zeros(1, self.output_dim).to(self.device)), dim=0)
         next_skill = skill[:, 1:]
         one_hot_skill = F.embedding(next_skill, one_hot)
         
         pred = (res * one_hot_skill).sum(dim=-1)
         return pred
     
     def attention_module(self, lstm_output):
+        """
+
+        Args:
+            lstm_output (torch.Tensor): output of lstm. Shape of [batch_size, seq_len, attention_dim]
+
+        Returns:
+            torch.Tensor: output of attention module. Shape of [batch_size, seq_len, 2*attention_dim]
+        """
         att_w = self.mlp(lstm_output)
         att_w = torch.tanh(att_w)
         att_w = self.similarity(att_w)
         
         alphas=nn.Softmax(dim=1)(att_w)
         
         attn_ouput=alphas*lstm_output
@@ -61,20 +100,31 @@
         attn_output_cum_1=attn_output_cum-attn_ouput
 
         final_output=torch.cat((attn_output_cum_1, lstm_output),2)
         
         return final_output
 
     def forward(self, cpt_unfold_seq, label_seq, mask_seq, p_adv=None, **kwargs):
-        skill = torch.where(mask_seq==0, torch.tensor([self.output_dim]), cpt_unfold_seq)
-        answer = torch.where(mask_seq==0, torch.tensor([2]), label_seq).long()
+        """A function of how well the model predicts students' responses to exercise questions
+
+        Args:
+            cpt_unfold_seq (torch.Tensor): Sequence of knowledge concepts related to exercises. Shape of [batch_size, seq_len]
+            label_seq (torch.Tensor): Sequence of students' answers to exercises. Shape of [batch_size, seq_len]
+            mask_seq (torch.Tensor): Sequence of mask. Mask=1 indicates that the student has answered the exercise, otherwise vice versa. Shape of [batch_size, seq_len] 
+            p_adv (torch.Tensor, optional): perturbation to skill_answer_embedding. Defaults to None.
+
+        Returns:
+            torch.Tensor: The predictions of the model and the skill answer embedding
+        """
+        skill = torch.where(mask_seq==0, torch.tensor([self.output_dim]).to(self.device), cpt_unfold_seq)
+        answer = torch.where(mask_seq==0, torch.tensor([2]).to(self.device), label_seq).long()
         perturbation = p_adv
         
-        skill_embedding=self.skill_emb(skill)  # skill:24*500(batch_size*seq_len), 若知识点所对应的序列学生没有做，则转换为self.output_dim
-        answer_embedding=self.answer_emb(answer)  # answer:24*500, 若学生没有做对应的习题，则转化为2
+        skill_embedding=self.skill_emb(skill)  # skill:24*500(batch_size*seq_len)
+        answer_embedding=self.answer_emb(answer)  # answer:24*500
         
         skill_answer=torch.cat((skill_embedding,answer_embedding), 2)
         answer_skill=torch.cat((answer_embedding,skill_embedding), 2)
         
         answer=answer.unsqueeze(2).expand_as(skill_answer)
         
         skill_answer_embedding=torch.where(answer==1, skill_answer, answer_skill)
@@ -91,14 +141,19 @@
         res = res[:, :-1, :]
         pred_res = self._get_next_pred(res, skill)  # 24*499(batch_size*(seq_len-1))
         
         return pred_res, skill_answer_embedding1
 
     @torch.no_grad()
     def predict(self, **kwargs):
+        """A function of get how well the model predicts students' responses to exercise questions and the groundtruth
+
+        Returns:
+            dict: The predictions of the model and the real situation
+        """
         y_pd, _ = self(**kwargs)
         y_pd = y_pd[kwargs['mask_seq'][:, 1:] == 1]
         y_gt = None
         if kwargs.get('label_seq', None) is not None:
             y_gt = kwargs['label_seq'][:, 1:]
             y_gt = y_gt[kwargs['mask_seq'][:, 1:] == 1]
         return {
```

### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

## edustudio/model/KT/ckt.py

```diff
@@ -11,37 +11,37 @@
         'k2': 6
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
 
-        self.hidden_size = self.model_cfg['hidden_size']
+        self.hidden_size = self.modeltpl_cfg['hidden_size']
         self.num_skills = self.n_item
 
     def build_model(self):
         skill_w = torch.empty(self.num_skills, self.hidden_size, device=self.device)
         torch.nn.init.xavier_uniform_(skill_w)
         self.skill_w = torch.nn.Parameter(skill_w)
 
         zeros = torch.zeros((self.num_skills, self.hidden_size), dtype=torch.float32, device=self.device)
         t1 = torch.cat([self.skill_w, zeros], dim=-1)
         t2 = torch.cat([zeros, self.skill_w], dim=-1)
         self.input_w = torch.cat([t1, t2], dim=0)
 
-        self.cnn_block = CNNBlock(self.model_cfg['hidden_size'],
-                                  self.model_cfg['k1'],
-                                  self.model_cfg['k2'],
-                                  self.model_cfg['drop_rate'],
+        self.cnn_block = CNNBlock(self.modeltpl_cfg['hidden_size'],
+                                  self.modeltpl_cfg['k1'],
+                                  self.modeltpl_cfg['k2'],
+                                  self.modeltpl_cfg['drop_rate'],
                                   self.device).to(self.device)
 
-        self.cnn = CNN(self.model_cfg['hidden_size'],
+        self.cnn = CNN(self.modeltpl_cfg['hidden_size'],
                        self.cnn_block,
                        self.device
                        ).to(self.device)
 
     def forward(self, exer_seq, label_seq, **kwargs):
         input_data, input_skill, l, next_id = self.data_helper(exer_seq, label_seq)
         skills = torch.nn.functional.embedding(input_skill.long(), self.skill_w)
@@ -78,16 +78,16 @@
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
 
     def data_helper(self, exer_seq, label_seq):
-        num_steps = self.datafmt_cfg['window_size']
-        batch_size = self.trainfmt_cfg['batch_size']
+        num_steps = self.datatpl_cfg['dt_info']['real_window_size']
+        batch_size = self.traintpl_cfg['batch_size']
 
         input_data = torch.zeros((batch_size, num_steps), device=self.device)
         input_skill = torch.zeros((batch_size, num_steps), device=self.device)
         next_id = torch.zeros((batch_size, num_steps), device=self.device)
         l = torch.ones((batch_size, num_steps, self.num_skills), device=self.device)
         for i in range(batch_size):
             problem_ids = exer_seq[i]
```

## edustudio/model/KT/cl4kt.py

```diff
@@ -2,15 +2,15 @@
 import random
 import math
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 from edustudio.utils.common import set_same_seeds
 import numpy as np
-from ...datafmt.utils import PadSeqUtil
+from ...datatpl.utils import PadSeqUtil
 
 
 class CL4KT(GDBaseModel):
     default_cfg = {
         'emb_size': 100,
         'hidden_size': 100,
         'num_blocks': 2,
@@ -30,73 +30,73 @@
         'hard_negative_weight': 1.0,
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def build_model(self):
         self.question_embed = nn.Embedding(
-            self.n_cpt  + 2, self.model_cfg['emb_size']
+            self.n_cpt  + 2, self.modeltpl_cfg['emb_size']
         )
         self.interaction_embed = nn.Embedding(
-            2 * (self.n_cpt + 2), self.model_cfg['emb_size']
+            2 * (self.n_cpt + 2), self.modeltpl_cfg['emb_size']
         )
-        self.sim = Similarity(temp=self.model_cfg["temp"])
+        self.sim = Similarity(temp=self.modeltpl_cfg["temp"])
         self.cpt_encoder = nn.ModuleList(
             [
                 CL4KTTransformerLayer(
-                    self.model_cfg['hidden_size'],
-                    self.model_cfg['hidden_size'] // self.model_cfg['num_attn_heads'],
-                    self.model_cfg['d_ff'],
-                    self.model_cfg['num_attn_heads'],
-                    self.model_cfg['dropout'],
-                    self.model_cfg['kq_same']
+                    self.modeltpl_cfg['hidden_size'],
+                    self.modeltpl_cfg['hidden_size'] // self.modeltpl_cfg['num_attn_heads'],
+                    self.modeltpl_cfg['d_ff'],
+                    self.modeltpl_cfg['num_attn_heads'],
+                    self.modeltpl_cfg['dropout'],
+                    self.modeltpl_cfg['kq_same']
                     )
-                for _ in range(self.model_cfg['num_blocks'])
+                for _ in range(self.modeltpl_cfg['num_blocks'])
             ]
         )
         self.interaction_encoder = nn.ModuleList(
             [
                 CL4KTTransformerLayer(
-                    self.model_cfg['hidden_size'],
-                    self.model_cfg['hidden_size'] // self.model_cfg['num_attn_heads'],
-                    self.model_cfg['d_ff'],
-                    self.model_cfg['num_attn_heads'],
-                    self.model_cfg['dropout'],
-                    self.model_cfg['kq_same']
+                    self.modeltpl_cfg['hidden_size'],
+                    self.modeltpl_cfg['hidden_size'] // self.modeltpl_cfg['num_attn_heads'],
+                    self.modeltpl_cfg['d_ff'],
+                    self.modeltpl_cfg['num_attn_heads'],
+                    self.modeltpl_cfg['dropout'],
+                    self.modeltpl_cfg['kq_same']
                     )
-                for _ in range(self.model_cfg['num_blocks'])
+                for _ in range(self.modeltpl_cfg['num_blocks'])
             ]
         )
         self.knoweldge_retriever = nn.ModuleList(
             [
                 CL4KTTransformerLayer(
-                    self.model_cfg['hidden_size'],
-                    self.model_cfg['hidden_size'] // self.model_cfg['num_attn_heads'],
-                    self.model_cfg['d_ff'],
-                    self.model_cfg['num_attn_heads'],
-                    self.model_cfg['dropout'],
-                    self.model_cfg['kq_same']
+                    self.modeltpl_cfg['hidden_size'],
+                    self.modeltpl_cfg['hidden_size'] // self.modeltpl_cfg['num_attn_heads'],
+                    self.modeltpl_cfg['d_ff'],
+                    self.modeltpl_cfg['num_attn_heads'],
+                    self.modeltpl_cfg['dropout'],
+                    self.modeltpl_cfg['kq_same']
                     )
-                for _ in range(self.model_cfg['num_blocks'])
+                for _ in range(self.modeltpl_cfg['num_blocks'])
             ]
         )
 
         self.out = nn.Sequential(
-            nn.Linear(self.model_cfg['hidden_size'] * 2, self.model_cfg['dim_fc']),
+            nn.Linear(self.modeltpl_cfg['hidden_size'] * 2, self.modeltpl_cfg['dim_fc']),
             nn.GELU(),
-            nn.Dropout(self.model_cfg['dropout']),
-            nn.Linear(self.model_cfg['dim_fc'], self.model_cfg['dim_fc'] // 2),
+            nn.Dropout(self.modeltpl_cfg['dropout']),
+            nn.Linear(self.modeltpl_cfg['dim_fc'], self.modeltpl_cfg['dim_fc'] // 2),
             nn.GELU(),
-            nn.Dropout(self.model_cfg['dropout']),
-            nn.Linear(self.model_cfg['dim_fc'] // 2, 1),
+            nn.Dropout(self.modeltpl_cfg['dropout']),
+            nn.Linear(self.modeltpl_cfg['dim_fc'] // 2, 1),
         )
 
     def forward(self, **kwargs):
         cpt_embed = self.question_embed(kwargs['cpt_unfold_seq'])
         inter_embed = self.get_interaction_embed(kwargs['cpt_unfold_seq'], kwargs['label_seq'].long(), kwargs['mask_seq'])
 
         x, y = cpt_embed, inter_embed
@@ -137,48 +137,48 @@
         _, aug_c_seq_2, aug_r_seq_2, _, attention_mask_2 = self.augment_kt_seqs(seed_change=True,**kwargs)
         aug_r_seq_1, aug_r_seq_2, negative_r_seq = aug_r_seq_1.long(), aug_r_seq_2.long(), negative_r_seq.long()
         attention_mask_1, attention_mask_2 = attention_mask_1.long(), attention_mask_2.long()
 
         # CL loss
         cpt_i_embed, cpt_j_embed = self.question_embed(aug_c_seq_1), self.question_embed(aug_c_seq_2)
         inter_i_embed, inter_j_embed = self.get_interaction_embed(aug_c_seq_1, aug_r_seq_1, attention_mask_1), self.get_interaction_embed(aug_c_seq_2, aug_r_seq_2, attention_mask_2)
-        if self.model_cfg['hard_negative']: inter_k_embed = self.get_interaction_embed(kwargs['cpt_unfold_seq'], negative_r_seq, kwargs['mask_seq'])
+        if self.modeltpl_cfg['hard_negative']: inter_k_embed = self.get_interaction_embed(kwargs['cpt_unfold_seq'], negative_r_seq, kwargs['mask_seq'])
 
         cpt_i_score, cpt_j_score = cpt_i_embed, cpt_j_embed
         inter_i_score, inter_j_score = inter_i_embed, inter_j_embed
         for block in self.cpt_encoder:
             cpt_i_score, _ = block(mask=2, query=cpt_i_score, key=cpt_i_score, values=cpt_i_embed, apply_pos=False)
             cpt_j_score, _ = block(mask=2, query=cpt_j_score, key=cpt_j_score, values=cpt_j_embed, apply_pos=False)
         for block in self.interaction_encoder:
             inter_i_score, _ = block(mask=2, query=inter_i_score, key=inter_i_score, values=inter_i_embed, apply_pos=False)
             inter_j_score, _ = block(mask=2, query=inter_j_score, key=inter_j_score, values=inter_j_embed, apply_pos=False)
-            if self.model_cfg['hard_negative']: inter_k_embed, _ = block(mask=2, query=inter_k_embed, key=inter_k_embed, values=inter_k_embed, apply_pos=False)
+            if self.modeltpl_cfg['hard_negative']: inter_k_embed, _ = block(mask=2, query=inter_k_embed, key=inter_k_embed, values=inter_k_embed, apply_pos=False)
         
         pool_cpt_i_score = (cpt_i_score * attention_mask_1.unsqueeze(-1)).sum(1) / attention_mask_1.sum(-1).unsqueeze(-1)
         pool_cpt_j_score = (cpt_j_score * attention_mask_2.unsqueeze(-1)).sum(1) / attention_mask_2.sum(-1).unsqueeze(-1)
         cpt_cos_sim = self.sim(pool_cpt_i_score.unsqueeze(1), pool_cpt_j_score.unsqueeze(0))
         cpt_labels = torch.arange(cpt_cos_sim.size(0)).long().to(aug_c_seq_1.device)
         cpt_cls_loss = F.cross_entropy(
             input=cpt_cos_sim, target=cpt_labels, reduction="mean"
         )
 
         pool_inter_i_score = (inter_i_score * attention_mask_1.unsqueeze(-1)).sum(1) / attention_mask_1.sum(-1).unsqueeze(-1)
         pool_inter_j_score = (inter_j_score * attention_mask_2.unsqueeze(-1)).sum(1) / attention_mask_2.sum(-1).unsqueeze(-1)
         inter_cos_sim = self.sim(pool_inter_i_score.unsqueeze(1), pool_inter_j_score.unsqueeze(0))
-        if self.model_cfg['hard_negative']: 
+        if self.modeltpl_cfg['hard_negative']: 
             pool_inter_k_score = (inter_k_embed * kwargs['mask_seq'].unsqueeze(-1)).sum(1) / kwargs['mask_seq'].sum(-1).unsqueeze(-1)
             neg_inter_cos_sim = self.sim(pool_inter_i_score.unsqueeze(1), pool_inter_k_score.unsqueeze(0))
             inter_cos_sim = torch.cat([inter_cos_sim, neg_inter_cos_sim], 1)
         inter_labels = torch.arange(inter_cos_sim.size(0)).long().to(aug_c_seq_1.device)
-        if self.model_cfg['hard_negative']:
+        if self.modeltpl_cfg['hard_negative']:
             weights = torch.tensor(
                     [
                         [0.0] * (inter_cos_sim.size(-1) - neg_inter_cos_sim.size(-1))
                         + [0.0] * i
-                        + [self.model_cfg['hard_negative_weight']]
+                        + [self.modeltpl_cfg['hard_negative_weight']]
                         + [0.0] * (neg_inter_cos_sim.size(-1) - i - 1)
                         for i in range(neg_inter_cos_sim.size(-1))
                     ]
             ).to(aug_c_seq_1.device)
             inter_cos_sim = inter_cos_sim + weights
         inter_cls_loss = F.cross_entropy(
             input=inter_cos_sim, target=inter_labels, reduction="mean"
@@ -192,88 +192,88 @@
         y_pd = y_pd[kwargs['mask_seq'][:, 1:] == 1]
         y_gt = kwargs['label_seq'][:, 1:]
         y_gt = y_gt[kwargs['mask_seq'][:, 1:] == 1]
         loss = F.binary_cross_entropy(
             input=y_pd, target=y_gt, reduction="mean"
         )
         return {
-            'loss_main': loss + cl_loss * self.model_cfg['reg_cl']
+            'loss_main': loss + cl_loss * self.modeltpl_cfg['reg_cl']
         }
         
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
 
     def augment_kt_seqs(self, seed_change=False, **kwargs):
         if seed_change:
-            random.Random(self.trainfmt_cfg['seed'] + 1)
-            np.random.seed(self.trainfmt_cfg['seed'] + 1)
+            random.Random(self.traintpl_cfg['seed'] + 1)
+            np.random.seed(self.traintpl_cfg['seed'] + 1)
         bs = kwargs['exer_seq'].size(0)
         lens = (kwargs['mask_seq'] > 0).sum(dim=1)
 
         # Data Augmentation
         cpt_seq_ = kwargs['cpt_unfold_seq'].clone()
         label_seq_ = kwargs['label_seq'].clone()
         exer_seq_ = kwargs['exer_seq'].clone()
         
         # Manipulate order: Question mask
-        if self.model_cfg['mask_prob'] > 0:
+        if self.modeltpl_cfg['mask_prob'] > 0:
            for b in range(bs):
-                if self.datafmt_cfg['sequence_option'] == 'recent':
-                    idx = random.sample(range(self.datafmt_cfg['window_size']-lens[b], self.datafmt_cfg['window_size']-1), max(1, int(lens[b] * self.model_cfg['mask_prob'])))
+                if self.datatpl_cfg['sequence_option'] == 'recent':
+                    idx = random.sample(range(self.datatpl_cfg['window_size']-lens[b], self.datatpl_cfg['window_size']-1), max(1, int(lens[b] * self.modeltpl_cfg['mask_prob'])))
                 else:
-                    idx = random.sample(range(lens[b]-1), max(1, int(lens[b] * self.model_cfg['mask_prob'])))
+                    idx = random.sample(range(lens[b]-1), max(1, int(lens[b] * self.modeltpl_cfg['mask_prob'])))
                 for i in idx:
                         cpt_seq_[b, i] = self.n_cpt + 1
                         exer_seq_[b, i] = self.n_item + 1
         # Hard negative
-        label_seq_flip = kwargs['label_seq'].clone() if self.model_cfg['hard_negative'] else label_seq_
+        label_seq_flip = kwargs['label_seq'].clone() if self.modeltpl_cfg['hard_negative'] else label_seq_
         for b in range(bs):
-            if self.datafmt_cfg['sequence_option'] == 'recent':
-                idx = torch.arange(self.datafmt_cfg['window_size']-lens[b], self.datafmt_cfg['window_size']) 
+            if self.datatpl_cfg['sequence_option'] == 'recent':
+                idx = torch.arange(self.datatpl_cfg['window_size']-lens[b], self.datatpl_cfg['window_size']) 
             else:
                 idx = torch.arange(lens[b])
             for i in idx:
                 label_seq_flip[b, i] = 1 - label_seq_flip[b, i]
         # Manipulate order:Question replace
-        if self.model_cfg['replace_prob'] > 0:
+        if self.modeltpl_cfg['replace_prob'] > 0:
             for b in range(bs):
-                if self.datafmt_cfg['sequence_option'] == 'recent':
-                    idx = random.sample(range(self.datafmt_cfg['window_size']-lens[b], self.datafmt_cfg['window_size']-1), max(1, int(lens[b] * self.model_cfg['replace_prob'])))
+                if self.datatpl_cfg['sequence_option'] == 'recent':
+                    idx = random.sample(range(self.datatpl_cfg['window_size']-lens[b], self.datatpl_cfg['window_size']-1), max(1, int(lens[b] * self.modeltpl_cfg['replace_prob'])))
                 else:
-                    idx = random.sample(range(lens[b]-1), max(1, int(lens[b] * self.model_cfg['replace_prob'])))
+                    idx = random.sample(range(lens[b]-1), max(1, int(lens[b] * self.modeltpl_cfg['replace_prob'])))
                 for i in idx:
-                    if cpt_seq_[b, i] != self.n_cpt + 1 and i in self.datafmt_cfg['dt_info']['train_harder_cpts'] and i in self.datafmt_cfg['dt_info']['train_harder_cpts']:
-                        cpt_seq_[b, i] = self.datafmt_cfg['dt_info']['train_harder_cpts'][i]  if label_seq_[b, i] == 0 else self.datafmt_cfg['dt_info']['train_harder_cpts'][i]
+                    if cpt_seq_[b, i] != self.n_cpt + 1 and i in self.datatpl_cfg['dt_info']['train_harder_cpts'] and i in self.datatpl_cfg['dt_info']['train_harder_cpts']:
+                        cpt_seq_[b, i] = self.datatpl_cfg['dt_info']['train_harder_cpts'][i]  if label_seq_[b, i] == 0 else self.datatpl_cfg['dt_info']['train_harder_cpts'][i]
         # Manipulate order:Interaction permute
-        if self.model_cfg['permute_prob'] > 0:
+        if self.modeltpl_cfg['permute_prob'] > 0:
             for b in range(bs):
-                reorder_seq_len = int(lens[b] * self.model_cfg['permute_prob'])
-                if self.datafmt_cfg['sequence_option'] == 'recent':
-                    start_pos = random.sample(range(self.datafmt_cfg['window_size']-lens[b], self.datafmt_cfg['window_size']-reorder_seq_len-1), 1)
+                reorder_seq_len = int(lens[b] * self.modeltpl_cfg['permute_prob'])
+                if self.datatpl_cfg['sequence_option'] == 'recent':
+                    start_pos = random.sample(range(self.datatpl_cfg['window_size']-lens[b], self.datatpl_cfg['window_size']-reorder_seq_len-1), 1)
                 else:
                     start_pos = random.sample(range(lens[b]-reorder_seq_len-1), 1)
 
                 perm = np.random.permutation(reorder_seq_len)
                 exer_seq_[b, start_pos[0]:start_pos[0]+reorder_seq_len] = exer_seq_[b, start_pos[0]:start_pos[0]+reorder_seq_len][perm]
                 cpt_seq_[b, start_pos[0]:start_pos[0]+reorder_seq_len] = cpt_seq_[b, start_pos[0]:start_pos[0]+reorder_seq_len][perm]
                 label_seq_[b, start_pos[0]:start_pos[0]+reorder_seq_len] = label_seq_[b, start_pos[0]:start_pos[0]+reorder_seq_len][perm]
         # Manipulate order:Interaction crop
         exer_seq_final, cpt_seq_fianl, label_seq_final, mask = torch.zeros_like(exer_seq_), torch.zeros_like(cpt_seq_), torch.zeros_like(label_seq_), torch.zeros_like(kwargs['mask_seq'])
-        if self.model_cfg['crop_prob'] > 0:
+        if self.modeltpl_cfg['crop_prob'] > 0:
             for b in range(bs):
-                crop_seq_len = 1 if int(lens[b] * self.model_cfg['permute_prob']) == 0 else int(lens[b] * self.model_cfg['permute_prob'])
-                if self.datafmt_cfg['sequence_option'] == 'recent':
-                    start_pos = random.sample(range(self.datafmt_cfg['window_size']-lens[b], self.datafmt_cfg['window_size']-crop_seq_len-1), 1)
+                crop_seq_len = 1 if int(lens[b] * self.modeltpl_cfg['permute_prob']) == 0 else int(lens[b] * self.modeltpl_cfg['permute_prob'])
+                if self.datatpl_cfg['sequence_option'] == 'recent':
+                    start_pos = random.sample(range(self.datatpl_cfg['window_size']-lens[b], self.datatpl_cfg['window_size']-crop_seq_len-1), 1)
                     exer_seq_final[b, -crop_seq_len:] = exer_seq_[b, start_pos[0]:start_pos[0] + crop_seq_len]
                     cpt_seq_fianl[b, -crop_seq_len:] = cpt_seq_[b, start_pos[0]:start_pos[0] + crop_seq_len]
                     label_seq_final[b, -crop_seq_len:] = label_seq_[b, start_pos[0]:start_pos[0] + crop_seq_len]
                     mask[b, -crop_seq_len:] = 1
                 else:
-                    start_pos = random.sample(range(self.datafmt_cfg['window_size']-lens[b], self.datafmt_cfg['window_size']-crop_seq_len-1), 1)
+                    start_pos = random.sample(range(self.datatpl_cfg['window_size']-lens[b], self.datatpl_cfg['window_size']-crop_seq_len-1), 1)
                     exer_seq_final[b, :crop_seq_len] = exer_seq_[b, start_pos[0]:start_pos[0] + crop_seq_len]
                     cpt_seq_fianl[b, :crop_seq_len] = cpt_seq_[b, start_pos[0]:start_pos[0] + crop_seq_len]
                     label_seq_final[b, :crop_seq_len] = label_seq_[b, start_pos[0]:start_pos[0] + crop_seq_len]
                     mask[b, crop_seq_len] = 1
 
         return exer_seq_final, cpt_seq_fianl, label_seq_final, label_seq_flip, mask
```

## edustudio/model/KT/ct_ncm.py

```diff
@@ -1,178 +1,260 @@
-# -*-coding:utf-8 -*-
-
+r"""
+CT_NCM
+##################################
+Reference:
+    Haiping Ma et al. "Reconciling cognitive modeling with knowledge forgetting: A continuous time-aware neural network approach." in IJCAI 2022.
+Reference code:
+    https://github.com/BIMK/Intelligent-Education/tree/main/CTNCM
+"""
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 from ..gd_basemodel import GDBaseModel
 
 
-
 class CT_NCM(GDBaseModel):
+    """
+    hidden_size: dimensions of LSTM hidden layerd
+    embed_size: dimensions of student-knowledge concept interaction embedding
+    prelen1: the first layer of performance prediction
+    prelen2: the second layer of performance prediction
+    dropout1: the proportion of first fully connected layer dropout before getting the prediction score
+    dropout2: the proportion of second fully connected layer dropout before getting the prediction score
+    """
     default_cfg = {
         'hidden_size': 64,
         'embed_size': 64,
-        'prelen1': 256,  # the first-second layer of performance prediction.
+        'prelen1': 256,
         'prelen2': 128,
         'dropout1': 0,
         'dropout2': 0,
     }
 
     def __init__(self, cfg):
+        """Pass parameters from other templates into the model
+
+        Args:
+            cfg (UnifyConfig): parameters from other templates
+        """
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.problem_num = self.datafmt_cfg['dt_info']['exer_count']  # 习题数量
-        self.skill_num = self.datafmt_cfg['dt_info']['cpt_count']  # 知识点数量
-        self.device = self.trainfmt_cfg['device']
-        self.hidden_size = self.model_cfg['hidden_size']
-        self.embed_size = self.model_cfg['embed_size']
+        """Initialize the parameters of the model"""
+        self.problem_num = self.datatpl_cfg['dt_info']['exer_count']
+        self.skill_num = self.datatpl_cfg['dt_info']['cpt_count']
+        self.device = self.traintpl_cfg['device']
+        self.hidden_size = self.modeltpl_cfg['hidden_size']
+        self.embed_size = self.modeltpl_cfg['embed_size']
         self.knowledge_dim = self.hidden_size
         self.input_len = self.knowledge_dim
-        self.prelen1 = self.model_cfg['prelen1']
-        self.prelen2 = self.model_cfg['prelen2']
+        self.prelen1 = self.modeltpl_cfg['prelen1']
+        self.prelen2 = self.modeltpl_cfg['prelen2']
         self.loss_function = torch.nn.BCELoss()
 
     def build_model(self):
-        self.dropout1 = nn.Dropout(p=self.model_cfg['dropout1'])
-        self.dropout2 = nn.Dropout(p=self.model_cfg['dropout2'])
+        """Initialize the various components of the model"""
+        self.dropout1 = nn.Dropout(p=self.modeltpl_cfg['dropout1'])
+        self.dropout2 = nn.Dropout(p=self.modeltpl_cfg['dropout2'])
 
         self.inter_embedding = torch.nn.Embedding(2 * self.skill_num, self.embed_size)
         self.reclstm = torch.nn.Linear(self.embed_size + self.hidden_size, 7 * self.hidden_size)
 
         self.problem_disc = torch.nn.Embedding(self.problem_num, 1)
         self.problem_diff = torch.nn.Embedding(self.problem_num, self.knowledge_dim)
 
         self.linear1 = torch.nn.Linear(self.input_len, self.prelen1)
         self.linear2 = torch.nn.Linear(self.prelen1, self.prelen2)
         self.linear3 = torch.nn.Linear(self.prelen2, 1)
-    
-    def _init_params(self):
-        # super()._init_params()
-        pass
 
-    def forward(self, exer_seq, time_lag_seq, cpt_unfold_seq, label_seq, mask_seq, **kwargs):
+    def forward(self, exer_seq, start_timestamp_seq, cpt_unfold_seq, label_seq, mask_seq, **kwargs):
+        """A function of how well the model predicts students' responses to exercise questions
+
+        Args:
+            exer_seq (torch.Tensor): Sequence of exercise id. Shape of [batch_size, seq_len]
+            start_timestamp_seq (torch.Tensor): Sequence of Students start answering time. Shape of [batch_size, seq_len]
+            cpt_unfold_seq (torch.Tensor): Sequence of knowledge concepts related to exercises. Shape of [batch_size, seq_len]
+            label_seq (torch.Tensor): Sequence of students' answers to exercises. Shape of [batch_size, seq_len]
+            mask_seq (torch.Tensor): Sequence of mask. Mask=1 indicates that the student has answered the exercise, otherwise vice versa. Shape of [batch_size, seq_len] 
+
+        Returns:
+            dict: The predictions of the model and the real situation
+        """
         problem_seqs_tensor = exer_seq[:,1:].to(self.device)
         skill_seqs_tensor = cpt_unfold_seq.to(self.device)
-        time_lag_seqs_tensor = time_lag_seq[:,1:].to(self.device)
+        start_timestamp_seqs_tensor = start_timestamp_seq[:,1:].to(self.device)
         correct_seqs_tensor = label_seq.to(self.device)
         mask_labels = mask_seq.long().to(self.device)
         seqs_length = torch.sum(mask_labels, dim=1)
         delete_row = 0
         for i in range(len(seqs_length)):
             if seqs_length[i] == 1:
                 problem_seqs_tensor = problem_seqs_tensor[torch.arange(problem_seqs_tensor.size(0))!=i-delete_row] 
                 skill_seqs_tensor = skill_seqs_tensor[torch.arange(skill_seqs_tensor.size(0))!=i-delete_row] 
-                time_lag_seqs_tensor = time_lag_seqs_tensor[torch.arange(time_lag_seqs_tensor.size(0))!=i-delete_row] 
+                start_timestamp_seqs_tensor = start_timestamp_seqs_tensor[torch.arange(start_timestamp_seqs_tensor.size(0))!=i-delete_row] 
                 correct_seqs_tensor = correct_seqs_tensor[torch.arange(correct_seqs_tensor.size(0))!=i-delete_row] 
                 mask_labels = mask_labels[torch.arange(mask_labels.size(0))!=i-delete_row] 
                 delete_row = delete_row + 1
 
         correct_seqs_tensor = torch.where(mask_labels == 0, -1, correct_seqs_tensor)
         skill_seqs_tensor = torch.where(mask_labels == 0, 0, skill_seqs_tensor)
         mask_labels_temp = mask_labels[:,1:]
-        time_lag_seqs_tensor = torch.where(mask_labels_temp == 0, 0, time_lag_seqs_tensor)
+        start_timestamp_seqs_tensor = torch.where(mask_labels_temp == 0, 0, start_timestamp_seqs_tensor)
         problem_seqs_tensor = torch.where(mask_labels_temp == 0, 0, problem_seqs_tensor)
-        # for i in range(mask_labels.shape[0]):
-        #     for j in range(mask_labels.shape[1]):
-        #         if mask_labels[i][j] == 0:
-        #             correct_seqs_tensor[i][j] = -1
-        #             skill_seqs_tensor[i][j] = 0
-        #             if j>0:
-        #                 time_lag_seqs_tensor[i][j-1] = 0
-        #                 problem_seqs_tensor[i][j-1] = 0
         seqs_length = torch.sum(mask_labels, dim=1)
 
         inter_embed_tensor = self.inter_embedding(skill_seqs_tensor + self.skill_num * mask_labels)
         batch_size = correct_seqs_tensor.size()[0]
 
-        hidden, _ = self.continues_lstm(inter_embed_tensor, time_lag_seqs_tensor, seqs_length, batch_size)
+        hidden, _ = self.continues_lstm(inter_embed_tensor, start_timestamp_seqs_tensor, seqs_length, batch_size)
         hidden_packed = torch.nn.utils.rnn.pack_padded_sequence(hidden[1:,],
                                                                 seqs_length.cpu() - 1,
                                                                 batch_first=False,
-                                                                enforce_sorted=False)  # 这里有点变动
+                                                                enforce_sorted=False)
         theta = hidden_packed.data
         problem_packed = torch.nn.utils.rnn.pack_padded_sequence(problem_seqs_tensor,
                                                                  seqs_length.cpu() - 1,
                                                                  batch_first=True,
                                                                  enforce_sorted=False)
         predictions = torch.squeeze(self.problem_hidden(theta, problem_packed.data))
         labels_packed = torch.nn.utils.rnn.pack_padded_sequence(correct_seqs_tensor[:,1:],
                                                                 seqs_length.cpu() - 1,
                                                                 batch_first=True,
                                                                 enforce_sorted=False)
         labels = labels_packed.data
-        #  predictions = torch.where(torch.isnan(predictions), torch.full_like(predictions, 0.5), predictions)
         out_dict = {'predictions': predictions, 'labels': labels}
         return out_dict
 
-    def continues_lstm(self, inter_embed_tensor, time_lag_seqs_tensor, seqs_length, batch_size):
+    def continues_lstm(self, inter_embed_tensor, start_timestamp_seqs_tensor, seqs_length, batch_size):
+        """
+
+        Args:
+            inter_embed_tensor (torch.Tensor): interrelated LSTM unit. Shape of [batch_size, seq_len, embed_size]
+            start_timestamp_seqs_tensor (torch.Tensor): Sequence of Students start answering time. Shape of [batch_size, seq_len-1]
+            seqs_length (torch.Tensor): Length of sequence. Shape of [batch_size]
+            batch_size (int): batch size.
+
+        Returns:
+            torch.Tensor: Output of LSTM.
+        """
         self.init_states(batch_size=batch_size)
         h_list = []
         h_list.append(self.h_delay)
         for t in range(max(seqs_length) - 1):
             one_batch = inter_embed_tensor[:, t]
             c, self.c_bar, output_t, delay_t = \
                 self.conti_lstm(one_batch, self.h_delay, self.c_delay,
                                 self.c_bar)
-            time_lag_batch = time_lag_seqs_tensor[:, t]
+            time_lag_batch = start_timestamp_seqs_tensor[:, t]
             self.c_delay, self.h_delay = \
                 self.delay(c, self.c_bar, output_t, delay_t, time_lag_batch)
             self.h_delay = torch.as_tensor(self.h_delay, dtype=torch.float)
             h_list.append(self.h_delay)
         hidden = torch.stack(h_list)
 
         return hidden, seqs_length
 
     def init_states(self, batch_size):
+        """Initialize the state of lstm
+
+        Args:
+            batch_size (int): batch_size
+        """
         self.h_delay = torch.full((batch_size, self.hidden_size), 0.5, dtype=torch.float).to(self.device)
         self.c_delay = torch.full((batch_size, self.hidden_size), 0.5, dtype=torch.float).to(self.device)
         self.c_bar = torch.full((batch_size, self.hidden_size), 0.5, dtype=torch.float).to(self.device)
         self.c = torch.full((batch_size, self.hidden_size), 0.5, dtype=torch.float).to(self.device)
 
     def conti_lstm(self, one_batch_inter_embed, h_d_t, c_d_t, c_bar_t):
+        """
+
+        Args:
+            one_batch_inter_embed (torch.Tensor): one batch of interrelated LSTM unit. Shape of [batch_size, embed_size]
+            h_d_t (torch.Tensor): Shape of [batch_size, embed_size]
+            c_d_t (torch.Tensor): Shape of [batch_size, embed_size]
+            c_bar_t (torch.Tensor): Shape of [batch_size, embed_size]
+
+        Returns:
+            torch.Tensor: Data inside LSTM
+        """
         input = torch.cat((one_batch_inter_embed, h_d_t), dim=1)
         (i, f, z, o, i_bar, f_bar, delay) = torch.chunk(self.reclstm(input), 7, -1)
         i = torch.sigmoid(i)
         f = torch.sigmoid(f)
         z = torch.tanh(z)
         o = torch.sigmoid(o)
         i_bar = torch.sigmoid(i_bar)
         f_bar = torch.sigmoid(f_bar)
         delay = F.softplus(delay)
         c_t = f * c_d_t + i * z
         c_bar_t = f_bar * c_bar_t + i_bar * z
         return c_t, c_bar_t, o, delay
 
     def delay(self, c, c_bar, output, delay, time_lag):
+        """
+
+        Args:
+            c (torch.Tensor): Shape of [batch_size, embed_size]
+            c_bar (torch.Tensor): Shape of [batch_size, embed_size]
+            output (torch.Tensor): Shape of [batch_size, embed_size]
+            delay (torch.Tensor): Shape of [batch_size, embed_size]
+            time_lag (torch.Tensor): Shape of [batch_size]
+
+        Returns:
+            torch.Tensor: Data inside LSTM
+        """
         c_delay = c_bar + (c - c_bar) * torch.exp(- delay * time_lag.unsqueeze(-1))
         h_delay = output * torch.tanh(c_delay)
         return c_delay, h_delay
 
     def problem_hidden(self, theta, problem_data):
+        """Get how well the model predicts students' responses to exercise questions
+
+        Args:
+            theta (torch.Tensor): Student's ability value. Shape of [exer_num, seq_len]
+            problem_data (torch.Tensor): The id of the exercise that the student has answered. Shape of [exer_num]
+
+        Returns:
+            torch.Tensor: the model predictions of students' responses to exercise questions. Shape of [exer_num, 1]
+        """
         problem_diff = torch.sigmoid(self.problem_diff(problem_data))
         problem_disc = torch.sigmoid(self.problem_disc(problem_data))
         input_x = (theta - problem_diff) * problem_disc * 10
         input_x = self.dropout1(torch.sigmoid(self.linear1(input_x)))
         input_x = self.dropout2(torch.sigmoid(self.linear2(input_x)))
         output = torch.sigmoid(self.linear3(input_x))
         return output
 
     def predict(self, **kwargs):
+        """A function of get how well the model predicts students' responses to exercise questions and the groundtruth
+
+        Returns:
+            dict: The predictions of the model and the real situation
+        """
         outdict = self(**kwargs)
         return {
             'y_pd': outdict['predictions'],
             'y_gt': torch.as_tensor(outdict['labels'], dtype=torch.float)
         }
 
     def get_main_loss(self, **kwargs):
+        """
+
+        Returns:
+            dict: loss dict{'loss_main': loss_value}
+        """
         outdict = self(**kwargs)
         predictions = outdict['predictions']
         labels = outdict['labels']
         labels = torch.as_tensor(labels, dtype=torch.float)
         loss = self.loss_function(predictions, labels)
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
+        """
+
+        Returns:
+            dict: loss dict{'loss_main': loss_value}
+        """
         return self.get_main_loss(**kwargs)
```

### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

## edustudio/model/KT/deep_irt.py

```diff
@@ -1,14 +1,14 @@
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
-class DEEP_IRT(GDBaseModel):
+class DeepIRT(GDBaseModel):
     default_cfg = {
         'dim_s': 200,  # 序列长度
         'size_m': 50,
         'drop_out': 0.2,
     }
 
     def __init__(self, cfg):
@@ -17,32 +17,32 @@
     def _init_params(self):
         super()._init_params()
         nn.init.kaiming_normal_(self.Mk)  # 使用正态分布对输入张量进行赋值
         nn.init.kaiming_normal_(self.Mv0)
 
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
 
     def build_model(self):
-        self.k_emb_layer = nn.Embedding(self.n_item, self.model_cfg['dim_s'])
-        self.Mk = nn.Parameter(torch.Tensor(self.model_cfg['size_m'], self.model_cfg['dim_s']))
-        self.Mv0 = nn.Parameter(torch.Tensor(self.model_cfg['size_m'], self.model_cfg['dim_s']))
-
-        self.v_emb_layer = nn.Embedding(self.n_item * 2, self.model_cfg['dim_s'])
-
-        self.f_layer = nn.Linear(self.model_cfg['dim_s'] * 2, self.model_cfg['dim_s'])
-        self.theta_layer = nn.Linear(self.model_cfg['dim_s'], self.model_cfg['dim_s'])
-        self.beta_layer = nn.Linear(self.model_cfg['dim_s'], self.model_cfg['dim_s'])
-        self.dropout_layer = nn.Dropout(self.model_cfg['drop_out'])
-        self.p_layer = nn.Linear(self.model_cfg['dim_s'], 1)
+        self.k_emb_layer = nn.Embedding(self.n_item, self.modeltpl_cfg['dim_s'])
+        self.Mk = nn.Parameter(torch.Tensor(self.modeltpl_cfg['size_m'], self.modeltpl_cfg['dim_s']))
+        self.Mv0 = nn.Parameter(torch.Tensor(self.modeltpl_cfg['size_m'], self.modeltpl_cfg['dim_s']))
+
+        self.v_emb_layer = nn.Embedding(self.n_item * 2, self.modeltpl_cfg['dim_s'])
+
+        self.f_layer = nn.Linear(self.modeltpl_cfg['dim_s'] * 2, self.modeltpl_cfg['dim_s'])
+        self.theta_layer = nn.Linear(self.modeltpl_cfg['dim_s'], self.modeltpl_cfg['dim_s'])
+        self.beta_layer = nn.Linear(self.modeltpl_cfg['dim_s'], self.modeltpl_cfg['dim_s'])
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['drop_out'])
+        self.p_layer = nn.Linear(self.modeltpl_cfg['dim_s'], 1)
 
-        self.e_layer = nn.Linear(self.model_cfg['dim_s'], self.model_cfg['dim_s'])
-        self.a_layer = nn.Linear(self.model_cfg['dim_s'], self.model_cfg['dim_s'])
+        self.e_layer = nn.Linear(self.modeltpl_cfg['dim_s'], self.modeltpl_cfg['dim_s'])
+        self.a_layer = nn.Linear(self.modeltpl_cfg['dim_s'], self.modeltpl_cfg['dim_s'])
 
 
     def forward(self, exer_seq, label_seq, **kwargs):
         batch_size = exer_seq.shape[0]
         x = exer_seq + self.n_item * label_seq
         k = self.k_emb_layer(exer_seq.long())
         v = self.v_emb_layer(x.long())
```

## edustudio/model/KT/dimkt.py

```diff
@@ -1,34 +1,50 @@
-import math
+r"""
+DIMKT
+##########################################
+
+Reference:
+    Shuanghong Shen et al. "Assessing Student’s Dynamic Knowledge State by Exploring the Question Difficulty Effect" in SIGIR 2022.
+
+Reference Code:
+    https://github.com/pykt-team/pykt-toolkit/blob/main/pykt/models/dimkt.py
+
+"""
 from torch.autograd import Variable
 from torch.nn import Embedding, Linear, Sigmoid, Tanh, Dropout
 
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 import numpy as np
 from torch.nn.init import xavier_uniform_, constant_
 
 class DIMKT(GDBaseModel):
+    r"""
+    DIMKT
+
+    default_cfg:
+       'emb_size': 128  # dimension of embedding
+       'dropout_rate': 0.2      # dropout rate
+       'difficult_levels': 100+2         # difficulty level of the exercises
+    """
     default_cfg = {
         'emb_size': 128,
-        'num_steps': 199,
         'difficult_levels': 100+2,
         'dropout':0.2
     }
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.num_q = self.datafmt_cfg['dt_info']['exer_count']
-        self.num_c = self.datafmt_cfg['dt_info']['cpt_count']
-        self.emb_size = self.model_cfg['emb_size']
-        self.dropout = self.model_cfg['dropout']
-        self.difficult_levels = self.model_cfg['difficult_levels']
-        self.num_steps = self.model_cfg['num_steps']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.num_q = self.datatpl_cfg['dt_info']['exer_count']
+        self.num_c = self.datatpl_cfg['dt_info']['cpt_count']
+        self.emb_size = self.modeltpl_cfg['emb_size']
+        self.dropout = self.modeltpl_cfg['dropout']
+        self.difficult_levels = self.modeltpl_cfg['difficult_levels']
         
     def build_model(self):
         self.sigmoid = Sigmoid()
         self.tanh = Tanh()
         self.dropout = Dropout(self.dropout)
         self.knowledge = Variable(torch.randn(1, self.emb_size), requires_grad=True)
 
@@ -41,32 +57,30 @@
         self.linear_1 = Linear(4 * self.emb_size, self.emb_size)
         self.linear_2 = Linear(1 * self.emb_size, self.emb_size)
         self.linear_3 = Linear(1 * self.emb_size, self.emb_size)
         self.linear_4 = Linear(2 * self.emb_size, self.emb_size)
         self.linear_5 = Linear(2 * self.emb_size, self.emb_size)
         self.linear_6 = Linear(4 * self.emb_size, self.emb_size)
 
-
-
     def forward(self, exer_seq, label_seq,  **kwargs):
-
+        self.num_steps = exer_seq.shape[1]-1
         self.bs = len(exer_seq)
         q = exer_seq[:,:-1]
-        c = kwargs['cpt_seq'][:,:-1]
+        c = kwargs['cpt_unfold_seq'][:,:-1]
         sd = kwargs['cd_seq'][:,:-1].int()
         qd = kwargs['qd_seq'][:,:-1].int()
         a = label_seq[:,:-1].int()
         q_emb = self.q_emb(Variable(q))
         c_emb = self.c_emb(Variable(c))
         sd_emb = self.sd_emb(Variable(sd))
         qd_emb = self.qd_emb(Variable(qd))
         a_emb = self.a_emb(Variable(a))
 
         qshft = exer_seq[:, 1:]
-        cshft = kwargs['cpt_seq'][:, 1:]
+        cshft = kwargs['cpt_unfold_seq'][:, 1:]
         sdshft = kwargs['cd_seq'][:, 1:].int()
         qdshft = kwargs['qd_seq'][:, 1:].int()
         target_q = self.q_emb(Variable(qshft))
         target_c = self.c_emb(Variable(cshft))
         target_sd = self.sd_emb(Variable(sdshft))
         target_qd = self.qd_emb(Variable(qdshft))
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## edustudio/model/KT/dkt.py

```diff
@@ -1,7 +1,16 @@
+r"""
+DKT
+##########################################
+
+Reference:
+    Chris Piech et al. "Deep knowledge tracing" in NIPS 2015.
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
 class DKT(GDBaseModel):
@@ -13,34 +22,34 @@
         'rnn_or_lstm': 'lstm',
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        assert self.model_cfg['rnn_or_lstm'] in {'rnn', 'lstm'}
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        assert self.modeltpl_cfg['rnn_or_lstm'] in {'rnn', 'lstm'}
 
     def build_model(self):
         self.exer_emb = nn.Embedding(
-            self.n_item * 2, self.model_cfg['emb_size']
+            self.n_item * 2, self.modeltpl_cfg['emb_size']
         )
-        if self.model_cfg['rnn_or_lstm'] == 'rnn':
+        if self.modeltpl_cfg['rnn_or_lstm'] == 'rnn':
             self.seq_model = nn.RNN(
-                self.model_cfg['emb_size'], self.model_cfg['hidden_size'], 
-                self.model_cfg['num_layers'], batch_first=True
+                self.modeltpl_cfg['emb_size'], self.modeltpl_cfg['hidden_size'], 
+                self.modeltpl_cfg['num_layers'], batch_first=True
             )
         else:
             self.seq_model = nn.LSTM(
-                self.model_cfg['emb_size'], self.model_cfg['hidden_size'], 
-                self.model_cfg['num_layers'], batch_first=True
+                self.modeltpl_cfg['emb_size'], self.modeltpl_cfg['hidden_size'], 
+                self.modeltpl_cfg['num_layers'], batch_first=True
             )
-        self.dropout_layer = nn.Dropout(self.model_cfg['dropout_rate'])
-        self.fc_layer = nn.Linear(self.model_cfg['hidden_size'], self.n_item)
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['dropout_rate'])
+        self.fc_layer = nn.Linear(self.modeltpl_cfg['hidden_size'], self.n_item)
 
     def forward(self, exer_seq, label_seq, **kwargs):
         input_x = self.exer_emb(exer_seq + label_seq.long() * self.n_item)
         output, _ = self.seq_model(input_x)
         output = self.dropout_layer(output)
         y_pd = self.fc_layer(output).sigmoid()
         return y_pd
```

## edustudio/model/KT/dkt_dsc.py

```diff
@@ -17,37 +17,37 @@
     def __init__(self, cfg):
         super().__init__(cfg)
 
     # def add_extra_data(self, **kwargs):
     #     self.cluster = kwargs.pop('cluster')
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_clusters = self.datafmt_cfg['dt_info']['n_cluster']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_clusters = self.datatpl_cfg['dt_info']['n_cluster']
 
     def build_model(self):
         self.exer_emb = nn.Embedding(
-            self.n_item * 2, self.model_cfg['emb_size']
+            self.n_item * 2, self.modeltpl_cfg['emb_size']
         )
         self.next_id_emb = nn.Embedding(
-            self.n_item, self.model_cfg['emb_size']
+            self.n_item, self.modeltpl_cfg['emb_size']
         )
-        if self.model_cfg['rnn_or_lstm'] == 'rnn':
+        if self.modeltpl_cfg['rnn_or_lstm'] == 'rnn':
             self.seq_model = nn.RNN(
-                self.model_cfg['emb_size'] * 2, self.model_cfg['hidden_size'],
-                self.model_cfg['num_layers'], batch_first=True
+                self.modeltpl_cfg['emb_size'] * 2, self.modeltpl_cfg['hidden_size'],
+                self.modeltpl_cfg['num_layers'], batch_first=True
             )
         else:
             self.seq_model = nn.LSTM(
-                self.model_cfg['emb_size'] * 2, self.model_cfg['hidden_size'],
-                self.model_cfg['num_layers'], batch_first=True
+                self.modeltpl_cfg['emb_size'] * 2, self.modeltpl_cfg['hidden_size'],
+                self.modeltpl_cfg['num_layers'], batch_first=True
             )
-        self.dropout_layer = nn.Dropout(self.model_cfg['dropout_rate'])
-        self.fc_layer = nn.Linear(self.model_cfg['hidden_size'], self.n_clusters + 1)
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['dropout_rate'])
+        self.fc_layer = nn.Linear(self.modeltpl_cfg['hidden_size'], self.n_clusters + 1)
 
 
     def forward(self, exer_seq, label_seq, **kwargs):
         seg_seq = kwargs['seg_seq']
         cluster = kwargs['cluster']
 
         zeros = torch.zeros_like(cluster, device=self.device)
```

## edustudio/model/KT/dkt_forget.py

```diff
@@ -1,7 +1,19 @@
+r"""
+DKTForget
+##########################################
+
+Reference:
+    Koki Nagatani et al. "Augmenting Knowledge Tracing by Considering Forgetting Behavior" in WWW 2019.
+
+Reference Code:
+    https://github.com/pykt-team/pykt-toolkit/blob/main/pykt/models/dkt_forget.py
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
 class DKTForget(GDBaseModel):
@@ -10,41 +22,41 @@
         'num_layers': 1,
         'dropout_rate': 0.2,
         'rnn_or_lstm': 'lstm',
         'integration_type': 'concat_multiply'
     }
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_rgap = self.datafmt_cfg['dt_info']['n_rgap']
-        self.n_sgap = self.datafmt_cfg['dt_info']['n_sgap']
-        self.n_pcount = self.datafmt_cfg['dt_info']['n_pcount']
-        assert self.model_cfg['rnn_or_lstm'] in {'rnn', 'lstm'}
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_rgap = self.datatpl_cfg['dt_info']['n_rgap']
+        self.n_sgap = self.datatpl_cfg['dt_info']['n_sgap']
+        self.n_pcount = self.datatpl_cfg['dt_info']['n_pcount']
+        assert self.modeltpl_cfg['rnn_or_lstm'] in {'rnn', 'lstm'}
         
     def build_model(self):
         self.exer_emb = nn.Embedding(
-            self.n_item * 2, self.model_cfg['emb_size']
+            self.n_item * 2, self.modeltpl_cfg['emb_size']
         )
         self.integration_compont = IntegrationComponent(
             n_rgap=self.n_rgap, n_sgap=self.n_sgap, n_pcount=self.n_pcount,
-            emb_dim=self.model_cfg['emb_size'], device=self.device,
-            integration_type=self.model_cfg['integration_type']
+            emb_dim=self.modeltpl_cfg['emb_size'], device=self.device,
+            integration_type=self.modeltpl_cfg['integration_type']
         )
-        if self.model_cfg['rnn_or_lstm'] == 'rnn':
+        if self.modeltpl_cfg['rnn_or_lstm'] == 'rnn':
             self.seq_model = nn.RNN(
-                self.integration_compont.output_dim, self.model_cfg['emb_size'], 
-                self.model_cfg['num_layers'], batch_first=True
+                self.integration_compont.output_dim, self.modeltpl_cfg['emb_size'], 
+                self.modeltpl_cfg['num_layers'], batch_first=True
             )
         else:
             self.seq_model = nn.LSTM(
-                self.integration_compont.output_dim, self.model_cfg['emb_size'], 
-                self.model_cfg['num_layers'], batch_first=True
+                self.integration_compont.output_dim, self.modeltpl_cfg['emb_size'], 
+                self.modeltpl_cfg['num_layers'], batch_first=True
             )
-        self.dropout_layer = nn.Dropout(self.model_cfg['dropout_rate'])
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['dropout_rate'])
         self.fc_layer = nn.Linear(self.integration_compont.output_dim, self.n_item)
 
     def forward(self, exer_seq, label_seq, r_gap, s_gap, p_count, **kwargs):
         input_x = self.exer_emb(exer_seq + label_seq.long() * self.n_item)
         input_x = self.integration_compont(input_x, r_gap, s_gap, p_count)
         h, _ = self.seq_model(input_x)
         output = self.integration_compont(h, r_gap, s_gap, p_count)
```

## edustudio/model/KT/dkt_plus.py

```diff
@@ -25,21 +25,21 @@
         y_curr = pred[kwargs['mask_seq'][:, :-1] == 1]
         y_next = pred_shft[kwargs['mask_seq'][:, 1:] == 1]
 
         gt_curr =  kwargs['label_seq'][:, :-1][kwargs['mask_seq'][:, :-1] == 1]
         gt_next = kwargs['label_seq'][:, 1:][kwargs['mask_seq'][:, 1:] == 1]
 
         loss_main = F.binary_cross_entropy(input=y_next, target=gt_next)
-        loss_r = self.model_cfg['lambda_r'] * F.binary_cross_entropy(input=y_curr, target=gt_curr)
+        loss_r = self.modeltpl_cfg['lambda_r'] * F.binary_cross_entropy(input=y_curr, target=gt_curr)
 
         diff = (pred_shft - pred)[kwargs['mask_seq'][:, 1:] == 1]
         loss_w1 = torch.norm(diff, 1) / len(diff)
-        loss_w1 = self.model_cfg['lambda_w1'] * loss_w1 / self.n_item
+        loss_w1 = self.modeltpl_cfg['lambda_w1'] * loss_w1 / self.n_item
         loss_w2 = torch.norm(diff, 2) / len(diff)
-        loss_w2 = self.model_cfg['lambda_w2'] * loss_w2 / self.n_item
+        loss_w2 = self.modeltpl_cfg['lambda_w2'] * loss_w2 / self.n_item
 
         return {
             'loss_main': loss_main,
             'loss_r': loss_r,
             'loss_w1': loss_w1,
             'loss_w2': loss_w2
         }
```

## edustudio/model/KT/dkvmn.py

```diff
@@ -16,30 +16,30 @@
 
     def _init_params(self):
         super()._init_params()
         nn.init.kaiming_normal_(self.Mk)
         nn.init.kaiming_normal_(self.Mv0)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
 
     def build_model(self):
-        self.k_emb_layer = nn.Embedding(self.n_item, self.model_cfg['dim_s'])
-        self.Mk = nn.Parameter(torch.Tensor(self.model_cfg['size_m'], self.model_cfg['dim_s']))
-        self.Mv0 = nn.Parameter(torch.Tensor(self.model_cfg['size_m'], self.model_cfg['dim_s']))
-
-        self.v_emb_layer = nn.Embedding(self.n_item * 2, self.model_cfg['dim_s'])
-
-        self.f_layer = nn.Linear(self.model_cfg['dim_s'] * 2, self.model_cfg['dim_s'])
-        self.dropout_layer = nn.Dropout(self.model_cfg['drop_out'])
-        self.p_layer = nn.Linear(self.model_cfg['dim_s'], 1)
+        self.k_emb_layer = nn.Embedding(self.n_item, self.modeltpl_cfg['dim_s'])
+        self.Mk = nn.Parameter(torch.Tensor(self.modeltpl_cfg['size_m'], self.modeltpl_cfg['dim_s']))
+        self.Mv0 = nn.Parameter(torch.Tensor(self.modeltpl_cfg['size_m'], self.modeltpl_cfg['dim_s']))
+
+        self.v_emb_layer = nn.Embedding(self.n_item * 2, self.modeltpl_cfg['dim_s'])
+
+        self.f_layer = nn.Linear(self.modeltpl_cfg['dim_s'] * 2, self.modeltpl_cfg['dim_s'])
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['drop_out'])
+        self.p_layer = nn.Linear(self.modeltpl_cfg['dim_s'], 1)
 
-        self.e_layer = nn.Linear(self.model_cfg['dim_s'], self.model_cfg['dim_s'])
-        self.a_layer = nn.Linear(self.model_cfg['dim_s'], self.model_cfg['dim_s'])
+        self.e_layer = nn.Linear(self.modeltpl_cfg['dim_s'], self.modeltpl_cfg['dim_s'])
+        self.a_layer = nn.Linear(self.modeltpl_cfg['dim_s'], self.modeltpl_cfg['dim_s'])
 
 
     def forward(self, exer_seq, label_seq, **kwargs):
         batch_size = exer_seq.shape[0]
         x = exer_seq + self.n_item * label_seq
         k = self.k_emb_layer(exer_seq.long())
         v = self.v_emb_layer(x.long())
```

## edustudio/model/KT/dtransformer.py

```diff
@@ -22,82 +22,82 @@
         'hard_negative': True,
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_exer = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_exer = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def build_model(self):
-        self.cpt_embed = nn.Embedding(self.n_cpt + 1, self.model_cfg['hidden_size'])
-        self.label_embed = nn.Embedding(2, self.model_cfg['hidden_size'])
+        self.cpt_embed = nn.Embedding(self.n_cpt + 1, self.modeltpl_cfg['hidden_size'])
+        self.label_embed = nn.Embedding(2, self.modeltpl_cfg['hidden_size'])
         
-        self.cpt_diff_embed = nn.Embedding(self.n_cpt + 1, self.model_cfg['hidden_size'])
-        self.label_diff_embed = nn.Embedding(2, self.model_cfg['hidden_size'])
+        self.cpt_diff_embed = nn.Embedding(self.n_cpt + 1, self.modeltpl_cfg['hidden_size'])
+        self.label_diff_embed = nn.Embedding(2, self.modeltpl_cfg['hidden_size'])
         self.exer_diff_embed = nn.Embedding(self.n_exer + 1, 1)  # difficult parameter
 
-        self.block1 = DTransformerLayer(self.model_cfg['hidden_size'], self.model_cfg['num_heads'], self.model_cfg['dropout'])
-        self.block2 = DTransformerLayer(self.model_cfg['hidden_size'], self.model_cfg['num_heads'], self.model_cfg['dropout'], kq_same=False)
+        self.block1 = DTransformerLayer(self.modeltpl_cfg['hidden_size'], self.modeltpl_cfg['num_heads'], self.modeltpl_cfg['dropout'])
+        self.block2 = DTransformerLayer(self.modeltpl_cfg['hidden_size'], self.modeltpl_cfg['num_heads'], self.modeltpl_cfg['dropout'], kq_same=False)
 
-        self.know_params = nn.Parameter(torch.empty(self.model_cfg['n_knowledges'], self.model_cfg['hidden_size']))
+        self.know_params = nn.Parameter(torch.empty(self.modeltpl_cfg['n_knowledges'], self.modeltpl_cfg['hidden_size']))
         nn.init.uniform_(self.know_params, -1.0, 1.0)
 
         self.out = nn.Sequential(
-            nn.Linear(self.model_cfg['hidden_size'] * 2, self.model_cfg['dim_fc']),
+            nn.Linear(self.modeltpl_cfg['hidden_size'] * 2, self.modeltpl_cfg['dim_fc']),
             nn.GELU(),
-            nn.Dropout(self.model_cfg['dropout']),
-            nn.Linear(self.model_cfg['dim_fc'], self.model_cfg['dim_fc'] // 2),
+            nn.Dropout(self.modeltpl_cfg['dropout']),
+            nn.Linear(self.modeltpl_cfg['dim_fc'], self.modeltpl_cfg['dim_fc'] // 2),
             nn.GELU(),
-            nn.Dropout(self.model_cfg['dropout']),
-            nn.Linear(self.model_cfg['dim_fc'] // 2, 1),
+            nn.Dropout(self.modeltpl_cfg['dropout']),
+            nn.Linear(self.modeltpl_cfg['dim_fc'] // 2, 1),
         )
 
-        if self.model_cfg['projection_alhead_cl']:
-            self.proj = nn.Sequential(nn.Linear(self.model_cfg['hidden_size'], self.model_cfg['hidden_size']), nn.GELU())
+        if self.modeltpl_cfg['projection_alhead_cl']:
+            self.proj = nn.Sequential(nn.Linear(self.modeltpl_cfg['hidden_size'], self.modeltpl_cfg['hidden_size']), nn.GELU())
         else:
             self.proj = None
         
     def forward(self, exer_seq, cpt_unfold_seq, label_seq, mask_seq, is_train=True, n=1,**kwargs):
         lens = (mask_seq > 0).sum(dim=1)
         q_emb, a_emb, exer_diff = self.embedding(cpt_unfold_seq, label_seq, exer_seq)
         
-        if self.model_cfg['num_layers'] == 1:
+        if self.modeltpl_cfg['num_layers'] == 1:
             hq = q_emb.clone()
             ha = a_emb.clone()
             m, e_score = self.block1(hq, hq, ha, lens, peek_cur=True)
-        elif self.model_cfg['num_layers'] == 2:
+        elif self.modeltpl_cfg['num_layers'] == 2:
             hq = q_emb.clone()
             ha, _ = self.block1(a_emb, a_emb, a_emb, lens, peek_cur=True)
             m, e_score = self.block1(hq, hq, ha, lens, peek_cur=True)
         else:
             hq, _ = self.block1(q_emb, q_emb, q_emb, lens, peek_cur=True)
             ha, _ = self.block1(a_emb, a_emb, a_emb, lens, peek_cur=True)
             m, e_score = self.block1(hq, hq, ha, lens, peek_cur=True)
 
         bs, seqlen = m.size(0), m.size(1)
 
         query = (
             self.know_params[None, :, None, :]
             .expand(bs, -1, seqlen, -1)
             .contiguous()
-            .view(bs * self.model_cfg['n_knowledges'], seqlen, self.model_cfg['hidden_size'])
+            .view(bs * self.modeltpl_cfg['n_knowledges'], seqlen, self.modeltpl_cfg['hidden_size'])
         )
-        hq = hq.unsqueeze(1).expand(-1, self.model_cfg['n_knowledges'], -1, -1).reshape_as(query)  # key embedding
-        m = m.unsqueeze(1).expand(-1, self.model_cfg['n_knowledges'], -1, -1).reshape_as(query)  # value embedding
-        z, c_score = self.block2(query, hq, m, torch.repeat_interleave(lens, self.model_cfg['n_knowledges']), peek_cur=False)
+        hq = hq.unsqueeze(1).expand(-1, self.modeltpl_cfg['n_knowledges'], -1, -1).reshape_as(query)  # key embedding
+        m = m.unsqueeze(1).expand(-1, self.modeltpl_cfg['n_knowledges'], -1, -1).reshape_as(query)  # value embedding
+        z, c_score = self.block2(query, hq, m, torch.repeat_interleave(lens, self.modeltpl_cfg['n_knowledges']), peek_cur=False)
         z = (
-            z.view(bs, self.model_cfg['n_knowledges'], seqlen, self.model_cfg['hidden_size'])  # unpack dimensions
+            z.view(bs, self.modeltpl_cfg['n_knowledges'], seqlen, self.modeltpl_cfg['hidden_size'])  # unpack dimensions
             .transpose(1, 2)  # (bs, seqlen, n_know, d_model)
             .contiguous()
             .view(bs, seqlen, -1)
         )
         c_score = (
-            c_score.view(bs, self.model_cfg['n_knowledges'], self.model_cfg['num_heads'], seqlen, seqlen)  # unpack dimensions
+            c_score.view(bs, self.modeltpl_cfg['n_knowledges'], self.modeltpl_cfg['num_heads'], seqlen, seqlen)  # unpack dimensions
             .permute(0, 2, 3, 1, 4)  # (bs, n_heads, seqlen, n_know, seqlen)
             .contiguous()
         )
         if not is_train:
             return z, q_emb
         else:
             query = q_emb[:, n - 1 :, :]
@@ -107,22 +107,22 @@
             return y, z, q_emb, (exer_diff**2).mean() * 1e-3, (e_score, c_score)
         
     def readout(self, z, query):
         bs, seqlen, _ = query.size()
         key = (
             self.know_params[None, None, :, :]
             .expand(bs, seqlen, -1, -1)
-            .view(bs * seqlen, self.model_cfg['n_knowledges'], -1)
+            .view(bs * seqlen, self.modeltpl_cfg['n_knowledges'], -1)
         )
-        value = z.reshape(bs * seqlen, self.model_cfg['n_knowledges'], -1)
+        value = z.reshape(bs * seqlen, self.modeltpl_cfg['n_knowledges'], -1)
 
         beta = torch.matmul(
             key,
             query.reshape(bs * seqlen, -1, 1),
-        ).view(bs * seqlen, 1, self.model_cfg['n_knowledges'])
+        ).view(bs * seqlen, 1, self.modeltpl_cfg['n_knowledges'])
         alpha = torch.softmax(beta, -1)
 
         return torch.matmul(alpha, value).view(bs, seqlen, -1)
     
     def embedding(self, cpt_seq, label_seq, exer_seq=None):
         cpt_emb = self.cpt_embed(cpt_seq)
         label_emb = self.label_embed(label_seq.long()) + cpt_emb
@@ -180,39 +180,39 @@
         
         # Data Augmentation
         cpt_seq_ = kwargs['cpt_unfold_seq'].clone()
         label_seq_ = kwargs['label_seq'].clone()
         exer_seq_ = kwargs['exer_seq'].clone()
         # Manipulate order: Swap Adjacent Items
         for b in range(bs):
-            idx = random.sample(range(lens[b] - 1), max(1, int(lens[b] * self.model_cfg['dropout'])))
+            idx = random.sample(range(lens[b] - 1), max(1, int(lens[b] * self.modeltpl_cfg['dropout'])))
             for i in idx:
                 cpt_seq_[b, i], cpt_seq_[b, i + 1] = cpt_seq_[b, i + 1], cpt_seq_[b, i]
                 label_seq_[b, i], label_seq_[b, i + 1] = label_seq_[b, i + 1], label_seq_[b, i]
                 exer_seq_[b, i], exer_seq_[b, i + 1] = exer_seq_[b, i + 1], exer_seq_[b, i]
         # Hard negative 
-        label_seq_flip = kwargs['label_seq'].clone() if self.model_cfg['hard_negative'] else label_seq_
+        label_seq_flip = kwargs['label_seq'].clone() if self.modeltpl_cfg['hard_negative'] else label_seq_
         # Manipulate score: Flip Response
         for b in range(bs):
-            idx = random.sample(range(lens[b] - 1), max(1, int(lens[b] * self.model_cfg['dropout'])))
+            idx = random.sample(range(lens[b] - 1), max(1, int(lens[b] * self.modeltpl_cfg['dropout'])))
             for i in idx:
                 label_seq_flip[b, i] = 1 - label_seq_flip[b, i]
-        if not self.model_cfg['hard_negative']: label_seq_ = label_seq_flip
+        if not self.modeltpl_cfg['hard_negative']: label_seq_ = label_seq_flip
 
         # Model loss
         logits, z_1, q_emb, reg_loss, _ = self(**kwargs, is_train=True)
         logits_masked = logits[kwargs['mask_seq'] == 1]
 
         _, z_2, *_ = self(exer_seq_, cpt_seq_, label_seq_, kwargs['mask_seq'], is_train=True)
-        if self.model_cfg['hard_negative']:
+        if self.modeltpl_cfg['hard_negative']:
             _, z_3, *_ = self(kwargs['exer_seq'], kwargs['cpt_unfold_seq'], label_seq_flip, kwargs['mask_seq'], is_train=True)
 
         # CL loss
         input = self.sim(z_1[:, :minlen, :], z_2[:, :minlen, :])
-        if self.model_cfg['hard_negative']:
+        if self.modeltpl_cfg['hard_negative']:
             hard_neg = self.sim(z_1[:, :minlen, :], z_3[:, :minlen, :])
             input = torch.cat([input, hard_neg], dim=1)
         target = (
             torch.arange(kwargs['label_seq'].size(0))[:, None]
             .to(self.know_params.device)
             .expand(-1, minlen)
         )
@@ -222,43 +222,43 @@
 
         # Prediction loss
         labels_masked = kwargs['label_seq'][kwargs['mask_seq'] == 1]
         pred_loss = F.binary_cross_entropy(
             input=logits_masked, target=labels_masked, reduction="mean"
         )
         
-        for i in range(1, self.model_cfg["prediction_window"]):
+        for i in range(1, self.modeltpl_cfg["prediction_window"]):
             y_gt = kwargs['label_seq'][:, i:]
             y_gt = y_gt[kwargs['mask_seq'][:, i:] == 1]
 
             query = q_emb[:, i:, :]
             h = self.readout(z_1[:, : query.size(1), :], query)
             y_pt = torch.sigmoid(self.out(torch.cat([query, h], dim=-1))).squeeze(-1)
             y_pd = y_pd[kwargs['mask_seq'][:, i:] == 1]
 
             pred_loss += F.binary_cross_entropy(
             input=y_pt, target=y_gt, reduction="mean"
         )
-        pred_loss /= self.model_cfg["prediction_window"]
+        pred_loss /= self.modeltpl_cfg["prediction_window"]
 
         return {
-            'loss_main': pred_loss + cl_loss * self.model_cfg['lambda_cl'] + reg_loss,
+            'loss_main': pred_loss + cl_loss * self.modeltpl_cfg['lambda_cl'] + reg_loss,
         }
 
     def get_loss_dict(self, **kwargs):
-        if self.model_cfg['cl_loss']:
+        if self.modeltpl_cfg['cl_loss']:
             return self.get_cl_loss(**kwargs)
         else:
             return self.get_loss(**kwargs)
 
     def sim(self, z1, z2):
         bs, seqlen, _ = z1.size()
-        z1 = z1.unsqueeze(1).view(bs, 1, seqlen, self.model_cfg['n_knowledges'], -1)
-        z2 = z2.unsqueeze(0).view(1, bs, seqlen, self.model_cfg['n_knowledges'], -1)
-        if self.model_cfg['projection_alhead_cl']:
+        z1 = z1.unsqueeze(1).view(bs, 1, seqlen, self.modeltpl_cfg['n_knowledges'], -1)
+        z2 = z2.unsqueeze(0).view(1, bs, seqlen, self.modeltpl_cfg['n_knowledges'], -1)
+        if self.modeltpl_cfg['projection_alhead_cl']:
             z1 = self.proj(z1)
             z2 = self.proj(z2)
         return F.cosine_similarity(z1.mean(-2), z2.mean(-2), dim=-1) / 0.05
 
 class DTransformerLayer(nn.Module):
     def __init__(self, d_model, n_heads, dropout, kq_same=True):
         super().__init__()
```

## edustudio/model/KT/eernn.py

```diff
@@ -1,7 +1,19 @@
+r"""
+EERNN
+##########################################
+
+Reference:
+    Yu Su et al. "Exercise-Enhanced Sequential Modeling for Student Performance Prediction" in AAAI 2018.
+
+Reference Code:
+    https://github.com/shaoliangliang1996/EERNN
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
 class EERNNM(GDBaseModel):
@@ -11,20 +23,20 @@
     }
     
     def add_extra_data(self, **kwargs):
         self.w2v_text_emb = kwargs['w2v_word_emb']
         self.exer_content = kwargs['exer_content'].to(self.device)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_word = self.datafmt_cfg['dt_info']['word_count']
-        self.d_0 = self.datafmt_cfg['dt_info']['word_emb_dim']
-        self.d_v = self.model_cfg['d_v']
-        self.d_h = self.model_cfg['d_h']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_word = self.datatpl_cfg['dt_info']['word_count']
+        self.d_0 = self.datatpl_cfg['dt_info']['word_emb_dim']
+        self.d_v = self.modeltpl_cfg['d_v']
+        self.d_h = self.modeltpl_cfg['d_h']
 
     def build_model(self):
         self.word_emb = nn.Embedding(self.n_word, self.d_0, padding_idx=0)
         self.exer_text_seq_model = nn.LSTM(self.d_0, self.d_v, batch_first=True, bidirectional=True)
         self.stu_inter_seq_model = nn.LSTM(4 * self.d_v, self.d_h, batch_first=True)
         self.pd_layer = nn.Sequential(
             nn.Linear(in_features=self.d_h + 2*self.d_v, out_features=(self.d_h + 2*self.d_v) // 2),
```

## edustudio/model/KT/ekt.py

```diff
@@ -1,27 +1,39 @@
+r"""
+EKT
+##########################################
+
+Reference:
+    Qi Liu et al. "EKT: Exercise-Aware Knowledge Tracing for Student Performance Prediction" in TKDE 2019.
+
+Reference Code:
+    https://github.com/bigdata-ustc/ekt
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 from .eernn import EERNNM, EERNNA
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
 class EKTM(EERNNM):
     default_cfg = {
         'd_k': 25,
     }
 
     def build_cfg(self):
         super().build_cfg()
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
 
     def build_model(self):
         super().build_model()
-        self.cpt_mem_emb = nn.Embedding(self.n_cpt, self.model_cfg['d_k'])
-        self.W_K = nn.Embedding(self.n_cpt, self.model_cfg['d_k'])
+        self.cpt_mem_emb = nn.Embedding(self.n_cpt, self.modeltpl_cfg['d_k'])
+        self.W_K = nn.Embedding(self.n_cpt, self.modeltpl_cfg['d_k'])
 
     def forward(self, exer_seq, label_seq, cpt_seq, cpt_seq_mask, **kwargs):
         exers, idx = exer_seq.unique(return_inverse=True)
         exer_emb = self.get_exer_embedding(exers)[idx]
         fused_exer_emb = exer_emb.repeat(1,1,2)
         cond = torch.where(label_seq == 1)
         fused_exer_emb[cond[0], cond[1], self.d_v*2:] = 0.0
```

## edustudio/model/KT/hawkeskt.py

```diff
@@ -14,18 +14,18 @@
         'time_log': 5,  # Log base of time intervals.
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.problem_num = self.datafmt_cfg['dt_info']['exer_count']  # 习题数量
-        self.skill_num = self.datafmt_cfg['dt_info']['cpt_count']  # 知识点数量
-        self.emb_size = self.model_cfg['emb_size']
-        self.time_log = self.model_cfg['time_log']
+        self.problem_num = self.datatpl_cfg['dt_info']['exer_count']  # 习题数量
+        self.skill_num = self.datatpl_cfg['dt_info']['cpt_count']  # 知识点数量
+        self.emb_size = self.modeltpl_cfg['emb_size']
+        self.time_log = self.modeltpl_cfg['time_log']
 
     def build_model(self):
         self.problem_base = torch.nn.Embedding(self.problem_num, 1)
         self.skill_base = torch.nn.Embedding(self.skill_num, 1)
 
         self.alpha_inter_embeddings = torch.nn.Embedding(self.skill_num * 2, self.emb_size)  # 对应论文中的PA吧
         self.alpha_skill_embeddings = torch.nn.Embedding(self.skill_num, self.emb_size)
@@ -37,20 +37,20 @@
         torch.nn.init.normal_(self.problem_base.weight, mean=0.0, std=0.01)
         torch.nn.init.normal_(self.skill_base.weight, mean=0.0, std=0.01)
         torch.nn.init.normal_(self.alpha_inter_embeddings.weight, mean=0.0, std=0.01)
         torch.nn.init.normal_(self.alpha_skill_embeddings.weight, mean=0.0, std=0.01)
         torch.nn.init.normal_(self.beta_inter_embeddings.weight, mean=0.0, std=0.01)
         torch.nn.init.normal_(self.beta_skill_embeddings.weight, mean=0.0, std=0.01)
 
-    def forward(self, exer_seq, time_lag_seq, cpt_unfold_seq, **kwargs):
+    def forward(self, exer_seq, start_timestamp_seq, cpt_unfold_seq, **kwargs):
         skills = cpt_unfold_seq     # [batch_size, seq_len] 一个习题对应一个知识点
         problems = exer_seq  # [batch_size, seq_len] batch_size个学生的序列
-        # time = [i for i in range(time_lag_seq.shape[1])]
-        # times = torch.Tensor([time for i in range(time_lag_seq.shape[0])])
-        times = time_lag_seq - time_lag_seq[:,[0]]        # [batch_size, seq_len]
+        # time = [i for i in range(start_timestamp_seq.shape[1])]
+        # times = torch.Tensor([time for i in range(start_timestamp_seq.shape[0])])
+        times = start_timestamp_seq - start_timestamp_seq[:,[0]]        # [batch_size, seq_len]
 
         mask_labels = kwargs['mask_seq'].long()
         inters = skills + mask_labels * self.skill_num
 
         alpha_src_emb = self.alpha_inter_embeddings(inters)  # [bs, seq_len, emb]
         alpha_target_emb = self.alpha_skill_embeddings(skills)
         alphas = torch.matmul(alpha_src_emb, alpha_target_emb.transpose(-2, -1))  # [bs, seq_len, seq_len]
```

## edustudio/model/KT/iekt.py

```diff
@@ -1,7 +1,19 @@
+r"""
+IEKT
+##########################################
+
+Reference:
+    Ting Long et al. "Tracing Knowledge State with Individual Cognition and Acquisition Estimation" in SIGIR 2021.
+
+Reference Code:
+    https://github.com/ApexEDM/iekt
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 from ..utils.components import MLP
 from torch.distributions import Categorical
 
@@ -67,42 +79,43 @@
         'n_acq_level': 10,
         'dropout_rate': 0.0,
         'gamma': 0.93,
         'lambda': 40.0,
     }
 
     def build_cfg(self):
-        self.n_stu = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_exer = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.n_cog_level = self.model_cfg['n_cog_level']
-        self.n_acq_level = self.model_cfg['n_acq_level']
-        self.d_v = self.model_cfg['d_h'] + self.model_cfg['d_q'] + self.model_cfg['d_c']
-        self.d_r = self.d_v + self.model_cfg['d_m']
-        self.d_i = self.model_cfg['d_q'] + self.model_cfg['d_c'] + self.model_cfg['d_s']
+        self.n_stu = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_exer = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.window_size = self.datatpl_cfg['dt_info']['real_window_size']
+        self.n_cog_level = self.modeltpl_cfg['n_cog_level']
+        self.n_acq_level = self.modeltpl_cfg['n_acq_level']
+        self.d_v = self.modeltpl_cfg['d_h'] + self.modeltpl_cfg['d_q'] + self.modeltpl_cfg['d_c']
+        self.d_r = self.d_v + self.modeltpl_cfg['d_m']
+        self.d_i = self.modeltpl_cfg['d_q'] + self.modeltpl_cfg['d_c'] + self.modeltpl_cfg['d_s']
 
     def build_model(self):
-        self.exer_emb = nn.Embedding(self.n_exer, self.model_cfg['d_q'])
-        self.cpt_emb = nn.Embedding(self.n_cpt, self.model_cfg['d_c'])
-        self.cog_matrix = nn.Embedding(self.n_cog_level, self.model_cfg['d_m'])
-        self.acq_matrix = nn.Embedding(self.n_acq_level, self.model_cfg['d_s'])
+        self.exer_emb = nn.Embedding(self.n_exer, self.modeltpl_cfg['d_q'])
+        self.cpt_emb = nn.Embedding(self.n_cpt, self.modeltpl_cfg['d_c'])
+        self.cog_matrix = nn.Embedding(self.n_cog_level, self.modeltpl_cfg['d_m'])
+        self.acq_matrix = nn.Embedding(self.n_acq_level, self.modeltpl_cfg['d_s'])
 
         self.pd_layer = MLP(
             input_dim=self.d_r, output_dim=1, 
-            dnn_units=[self.d_r], dropout_rate=self.model_cfg['dropout_rate']
+            dnn_units=[self.d_r], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
         self.f_p = MLP(
             input_dim=self.d_v, output_dim=self.n_cog_level, 
-            dnn_units=[self.d_r], dropout_rate=self.model_cfg['dropout_rate']
+            dnn_units=[self.d_r], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
         self.f_e = MLP(
             input_dim=self.d_v * 4, output_dim=self.n_acq_level,
-            dnn_units=[self.d_r], dropout_rate=self.model_cfg['dropout_rate']
+            dnn_units=[self.d_r], dropout_rate=self.modeltpl_cfg['dropout_rate']
         )
-        self.gru_h = mygru(0, self.d_i, self.model_cfg['d_h'])
+        self.gru_h = mygru(0, self.d_i, self.modeltpl_cfg['d_h'])
 
     def get_exer_representation(self, exer_ids, cpt_seq, cpt_seq_mask):
         exer_emb = self.exer_emb(exer_ids) # windows_size x emb size
         cpt_emb = torch.vstack(
             [self.cpt_emb(cpt_seq[i])[cpt_seq_mask[i] == 1].mean(dim=0) for i in range(cpt_seq.shape[0])]
         )
         return torch.cat([exer_emb, cpt_emb], dim = -1)
@@ -129,15 +142,15 @@
         exer_mask_seq = kwargs['mask_seq']
         cpt_seq = kwargs['cpt_seq']
         cpt_seq_mask = kwargs['cpt_seq_mask']
         label_seq = kwargs['label_seq']
 
         batch_size = exer_seq.shape[0]
         seq_len = exer_seq.shape[1]
-        h = torch.zeros(batch_size, self.model_cfg['d_h']).to(self.device)
+        h = torch.zeros(batch_size, self.modeltpl_cfg['d_h']).to(self.device)
         p_action_list, pre_state_list, emb_action_list, states_list, reward_list, predict_list, ground_truth_list = [], [], [], [], [], [], []
 
 
         for t in range(seq_len):
             # read stage
             exer_seq_col = exer_seq[:, t]
             cpt_seq_col = cpt_seq[:, t]
@@ -188,15 +201,15 @@
 
         # RL 训练
         seq_num = exer_mask_seq.sum(dim=1)
         emb_action_tensor = torch.stack(emb_action_list, dim = 1) # ac的sample操作
         p_action_tensor = torch.stack(p_action_list, dim = 1) # ce的sample操作
         state_tensor = torch.stack(states_list, dim = 1) # 输出的groudtruth和predict合并
         pre_state_tensor = torch.stack(pre_state_list, dim = 1)
-        reward_tensor = torch.stack(reward_list, dim = 1).float() / (seq_num.unsqueeze(-1).repeat(1, self.datafmt_cfg['window_size'])).float()
+        reward_tensor = torch.stack(reward_list, dim = 1).float() / (seq_num.unsqueeze(-1).repeat(1, self.window_size)).float()
         logits_tensor = torch.stack(predict_list, dim = 1)
         ground_truth_tensor = torch.stack(ground_truth_list, dim = 1)
         loss = []
         tracat_logits = []
         tracat_ground_truth = []
         
         for i in range(0, batch_size):
@@ -217,30 +230,30 @@
             td_target_sens = this_reward_list[0: this_seq_len].unsqueeze(1)
             delta_sens = td_target_sens
             delta_sens = delta_sens.detach().cpu().numpy()
 
             advantage_lst_cog = []
             advantage = 0.0
             for delta_t in delta_cog[::-1]:
-                advantage = self.model_cfg['gamma'] * advantage + delta_t[0]
+                advantage = self.modeltpl_cfg['gamma'] * advantage + delta_t[0]
                 advantage_lst_cog.append([advantage])
             advantage_lst_cog.reverse()
             advantage_cog = torch.tensor(advantage_lst_cog, dtype=torch.float).to(self.device)
             
             pi_cog = self.pi_cog_func(this_cog_state[:-1])
             pi_a_cog = pi_cog.gather(1,p_action_tensor[i][0: this_seq_len].unsqueeze(1))
 
             loss_cog = -torch.log(pi_a_cog) * advantage_cog
             
             loss.append(torch.sum(loss_cog))
 
             advantage_lst_sens = []
             advantage = 0.0
             for delta_t in delta_sens[::-1]:
-                advantage = self.model_cfg['gamma'] * advantage + delta_t[0]
+                advantage = self.modeltpl_cfg['gamma'] * advantage + delta_t[0]
                 advantage_lst_sens.append([advantage])
             advantage_lst_sens.reverse()
             advantage_sens = torch.tensor(advantage_lst_sens, dtype=torch.float).to(self.device)
             
             pi_sens = self.pi_sens_func(this_sens_state[:-1])
             pi_a_sens = pi_sens.gather(1,emb_action_tensor[i][0: this_seq_len].unsqueeze(1))
 
@@ -254,15 +267,15 @@
             tracat_ground_truth.append(this_groud_truth)
         
 
         bce = F.binary_cross_entropy_with_logits(torch.cat(tracat_logits, dim = 0), torch.cat(tracat_ground_truth, dim = 0))
            
         label_len = torch.cat(tracat_ground_truth, dim = 0).size()[0]
         loss_l = sum(loss)
-        loss = self.model_cfg['lambda'] * (loss_l / label_len) +  bce
+        loss = self.modeltpl_cfg['lambda'] * (loss_l / label_len) +  bce
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
 
@@ -273,15 +286,15 @@
         exer_mask_seq = kwargs['mask_seq']
         cpt_seq = kwargs['cpt_seq']
         cpt_seq_mask = kwargs['cpt_seq_mask']
         label_seq = kwargs['label_seq']
 
         batch_size = exer_seq.shape[0]
         seq_len = exer_seq.shape[1]
-        h = torch.zeros(batch_size, self.model_cfg['d_h']).to(self.device)
+        h = torch.zeros(batch_size, self.modeltpl_cfg['d_h']).to(self.device)
         batch_probs, uni_prob_list =[], []
 
 
         for t in range(seq_len):
             # read stage
             exer_seq_col = exer_seq[:, t]
             cpt_seq_col = cpt_seq[:, t]
```

## edustudio/model/KT/kqn.py

```diff
@@ -14,51 +14,51 @@
         'dropout': 0.2
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
     
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        # assert self.model_cfg['rnn_or_lstm'] in {'rnn', 'lstm'}
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        # assert self.modeltpl_cfg['rnn_or_lstm'] in {'rnn', 'lstm'}
     
     def build_model(self):
         # helper variable for making a one-hot vector for rnn input
         self.inter_emb = torch.eye(self.n_item * 2)
         # helper variable for making a one-hot vector for skills
         self.cpt_emb = torch.eye(self.n_item)
 
-        if self.model_cfg['rnn_or_lstm'] == 'gru':
+        if self.modeltpl_cfg['rnn_or_lstm'] == 'gru':
             self.seq_model = nn.GRU(
-                2 * self.n_item, self.model_cfg['rnn_hidden_size'], 
-                self.model_cfg['n_rnn_layers'], batch_first=True
+                2 * self.n_item, self.modeltpl_cfg['rnn_hidden_size'], 
+                self.modeltpl_cfg['n_rnn_layers'], batch_first=True
             )
         else:
             self.seq_model = nn.LSTM(
-                2 * self.n_item, self.model_cfg['rnn_hidden_size'], 
-                self.model_cfg['n_rnn_layers'], batch_first=True
+                2 * self.n_item, self.modeltpl_cfg['rnn_hidden_size'], 
+                self.modeltpl_cfg['n_rnn_layers'], batch_first=True
             )
         
         self.skill_encoder = nn.Sequential(
-            nn.Linear(self.n_item, self.model_cfg['mlp_hidden_size']),
+            nn.Linear(self.n_item, self.modeltpl_cfg['mlp_hidden_size']),
             nn.ReLU(),
-            nn.Linear(self.model_cfg['mlp_hidden_size'], self.model_cfg['emb_size']),
+            nn.Linear(self.modeltpl_cfg['mlp_hidden_size'], self.modeltpl_cfg['emb_size']),
             nn.ReLU()
         )
-        self.fc_layer = nn.Linear(self.model_cfg['rnn_hidden_size'], self.model_cfg['emb_size'])
-        self.drop_layer = nn.Dropout(self.model_cfg['dropout'])
+        self.fc_layer = nn.Linear(self.modeltpl_cfg['rnn_hidden_size'], self.modeltpl_cfg['emb_size'])
+        self.drop_layer = nn.Dropout(self.modeltpl_cfg['dropout'])
         self.sigmoid = nn.Sigmoid()
 
     def forward(self, exer_seq, label_seq, **kwargs):
         in_data = self.inter_emb[(exer_seq[:,:-1] + label_seq[:,:-1] * self.n_item).long()]
         next_skills = self.cpt_emb[(exer_seq[:,1:]).long()]
 
-        encoded_knowledge = self.encode_knowledge(in_data.to(self.trainfmt_cfg['device']))
-        encoded_skills = self.encode_skills(next_skills.to(self.trainfmt_cfg['device']))
+        encoded_knowledge = self.encode_knowledge(in_data.to(self.traintpl_cfg['device']))
+        encoded_skills = self.encode_skills(next_skills.to(self.traintpl_cfg['device']))
         encoded_knowledge = self.drop_layer(encoded_knowledge)
 
         y_pd = torch.sum(encoded_knowledge * encoded_skills, dim=2) # (batch_size, max_seq_len)
         y_pd = self.sigmoid(y_pd)
 
         return y_pd
 
@@ -77,19 +77,19 @@
         encoded_skills = self.skill_encoder(next_skills) # (batch_size, max_seq_len, n_hidden)
         encoded_skills = F.normalize(encoded_skills, p=2, dim=2) # L2-normalize
 
         return encoded_skills
 
     def init_hidden(self, batch_size: int):
         weight = next(self.parameters()).data
-        if self.model_cfg['rnn_or_lstm'] == 'lstm':
-            return (Variable(weight.new(self.model_cfg['n_rnn_layers'], batch_size, self.model_cfg['rnn_hidden_size']).zero_()),
-                    Variable(weight.new(self.model_cfg['n_rnn_layers'], batch_size, self.model_cfg['rnn_hidden_size']).zero_()))
+        if self.modeltpl_cfg['rnn_or_lstm'] == 'lstm':
+            return (Variable(weight.new(self.modeltpl_cfg['n_rnn_layers'], batch_size, self.modeltpl_cfg['rnn_hidden_size']).zero_()),
+                    Variable(weight.new(self.modeltpl_cfg['n_rnn_layers'], batch_size, self.modeltpl_cfg['rnn_hidden_size']).zero_()))
         else:
-            return Variable(weight.new(self.model_cfg['n_rnn_layers'], batch_size, self.model_cfg['rnn_hidden_size']).zero_())
+            return Variable(weight.new(self.modeltpl_cfg['n_rnn_layers'], batch_size, self.modeltpl_cfg['rnn_hidden_size']).zero_())
 
     @torch.no_grad()
     def predict(self, **kwargs):
         y_pd = self(**kwargs)
         # y_pd = y_pd[:-1].gather(
         #     index=kwargs['exer_seq'][:, 1:].unsqueeze(dim=-1), dim=1
         # ).squeeze(dim=-1)
@@ -115,8 +115,8 @@
             input=y_pd, target=y_gt
         )
         return {
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
-        return self.get_main_loss(**kwargs)
+        return self.get_main_loss(**kwargs)
```

## edustudio/model/KT/lpkt.py

```diff
@@ -1,7 +1,19 @@
+r"""
+LPKT
+##########################################
+
+Reference:
+    Shuanghong Sheng et al. "Learning Process-consistent Knowledge Tracing" in KDD 2021.
+
+Reference Code:
+    https://github.com/bigdata-ustc/EduKTM/tree/main/EduKTM/LPKT
+
+"""
+
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 
 class LPKT(GDBaseModel):
@@ -11,44 +23,44 @@
         'd_e': 128, 
         'q_gamma': 0.03,
         'drop_rate': 0.2,
         'param_init_type': 'xavier_uniform'
     }
 
     def build_cfg(self):
-        self.n_stu = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_exer = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.n_at = self.datafmt_cfg['dt_info']['answer_time_count'] # answer time
-        self.n_it = self.datafmt_cfg['dt_info']['interval_time_count'] # interval time
-        self.d_k = self.model_cfg['d_k']
-        self.d_e = self.model_cfg['d_e']
-        self.d_a = self.model_cfg['d_a']
+        self.n_stu = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_exer = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.n_at = self.datatpl_cfg['dt_info']['answer_time_count'] # answer time
+        self.n_it = self.datatpl_cfg['dt_info']['interval_time_count'] # interval time
+        self.d_k = self.modeltpl_cfg['d_k']
+        self.d_e = self.modeltpl_cfg['d_e']
+        self.d_a = self.modeltpl_cfg['d_a']
 
     def add_extra_data(self, **kwargs):
         Q_mat = kwargs['Q_mat']
-        Q_mat[Q_mat == 0] = self.model_cfg['q_gamma']
+        Q_mat[Q_mat == 0] = self.modeltpl_cfg['q_gamma']
         self.q_matrix = Q_mat.to(self.device).float()
 
     def build_model(self):
-        d_k = self.model_cfg['d_k']
-        d_e = self.model_cfg['d_e']
-        d_a = self.model_cfg['d_a']
+        d_k = self.modeltpl_cfg['d_k']
+        d_e = self.modeltpl_cfg['d_e']
+        d_a = self.modeltpl_cfg['d_a']
 
         self.at_embed = nn.Embedding(self.n_at, d_k)
         self.it_embed = nn.Embedding(self.n_it, d_k)
         self.exer_embed = nn.Embedding(self.n_exer, d_e)
 
         self.linear_1 = nn.Linear(d_a + d_e + d_k, d_k)
         self.linear_2 = nn.Linear(4 * d_k, d_k)
         self.linear_3 = nn.Linear(4 * d_k, d_k)
         self.linear_4 = nn.Linear(3 * d_k, d_k)
         self.linear_5 = nn.Linear(2 * d_k, d_k)
 
-        self.dropout = nn.Dropout(self.model_cfg['drop_rate'])
+        self.dropout = nn.Dropout(self.modeltpl_cfg['drop_rate'])
 
     def forward(self, exer_seq, answer_time_seq, interval_time_seq, **kwargs):
         a_data = exer_seq
         batch_size, seq_len = exer_seq.shape
         e_embed_data = self.exer_embed(exer_seq)
         at_embed_data = self.at_embed(answer_time_seq)
         it_embed_data = self.it_embed(interval_time_seq)
```

## edustudio/model/KT/lpkt_s.py

```diff
@@ -12,47 +12,47 @@
         'd_s': 128, 
         'q_gamma': 0.03,
         'drop_rate': 0.2,
         'param_init_type': 'xavier_uniform'
     }
 
     def build_cfg(self):
-        self.n_stu = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_exer = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.n_at = self.datafmt_cfg['dt_info']['answer_time_count'] # answer time
-        self.n_it = self.datafmt_cfg['dt_info']['interval_time_count'] # interval time
-        self.d_k = self.model_cfg['d_k']
-        self.d_e = self.model_cfg['d_e']
-        self.d_a = self.model_cfg['d_a']
-        self.d_s = self.model_cfg['d_s']
+        self.n_stu = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_exer = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.n_at = self.datatpl_cfg['dt_info']['answer_time_count'] # answer time
+        self.n_it = self.datatpl_cfg['dt_info']['interval_time_count'] # interval time
+        self.d_k = self.modeltpl_cfg['d_k']
+        self.d_e = self.modeltpl_cfg['d_e']
+        self.d_a = self.modeltpl_cfg['d_a']
+        self.d_s = self.modeltpl_cfg['d_s']
 
     def add_extra_data(self, **kwargs):
         Q_mat = kwargs['Q_mat']
-        Q_mat[Q_mat == 0] = self.model_cfg['q_gamma']
+        Q_mat[Q_mat == 0] = self.modeltpl_cfg['q_gamma']
         self.q_matrix = Q_mat.to(self.device).float()
 
     def build_model(self):
-        d_k = self.model_cfg['d_k']
-        d_e = self.model_cfg['d_e']
-        d_a = self.model_cfg['d_a']
-        d_s = self.model_cfg['d_s']
+        d_k = self.modeltpl_cfg['d_k']
+        d_e = self.modeltpl_cfg['d_e']
+        d_a = self.modeltpl_cfg['d_a']
+        d_s = self.modeltpl_cfg['d_s']
 
         self.at_embed = nn.Embedding(self.n_at, d_k)
         self.it_embed = nn.Embedding(self.n_it, d_k)
         self.exer_embed = nn.Embedding(self.n_exer, d_e)
         self.stu_embed = nn.Embedding(self.n_stu, d_s)
 
         self.linear_1 = nn.Linear(d_a + d_e + d_k, d_k)
         self.linear_2 = nn.Linear(4 * d_k, d_k)
         self.linear_3 = nn.Linear(4 * d_k, d_k)
         self.linear_4 = nn.Linear(4 * d_k, d_k)
         self.linear_5 = nn.Linear(3 * d_k, d_k)
 
-        self.dropout = nn.Dropout(self.model_cfg['drop_rate'])
+        self.dropout = nn.Dropout(self.modeltpl_cfg['drop_rate'])
 
     def forward(self, stu_id, exer_seq, answer_time_seq, interval_time_seq, mask_seq, **kwargs):  # answer_time_seq是学生回答每道习题的时间
         #  interval_time_seq是学生回答习题间的间隔时间
         a_data = exer_seq
         batch_size, seq_len = exer_seq.shape
         e_embed_data = self.exer_embed(exer_seq)
         at_embed_data = self.at_embed(answer_time_seq)
```

## edustudio/model/KT/qdkt.py

```diff
@@ -1,15 +1,34 @@
-import numpy as np
+r"""
+QDKT
+##########################################
 
+Reference:
+    Shashank Sonkar et al. "qDKT: Question-Centric Deep Knowledge Tracing" in EDM 2020.
+
+Reference Code:
+    https://github.com/pykt-team/pykt-toolkit/blob/main/pykt/models/qdkt.py
+
+"""
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 
 class QDKT(GDBaseModel):
+    r"""
+   QDKT
+
+   default_cfg:
+      'emb_size': 100  # dimension of embedding
+      'dropout_rate': 0.2      # dropout rate
+      'hidden_size': 100        # hidden size of LSTM
+        'num_layers': 1         # num layers of LSTM
+        'w_reg':0.01            # weight of loss_reg
+   """
     default_cfg = {
         'emb_size': 100,
         'hidden_size': 100,
         'num_layers': 1,
         'dropout_rate': 0.2,
         'w_reg':0.01
     }
@@ -19,46 +38,46 @@
         self.laplacian = torch.tensor(self.laplacian_matrix).to(self.device).float()
         self.train_dict = kwargs['train_dict']
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.w_reg = self.model_cfg['w_reg']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.w_reg = self.modeltpl_cfg['w_reg']
 
     def _init_params(self):
         super()._init_params()
         for w in self.fasttext_model.words:
             label = int(w[-1])
             index = int(w[:-1])
             fast_weight = self.fasttext_model[w]
             new_index = index+label*index
             sd = self.exer_emb.state_dict()
             sd['weight'][new_index].copy_(torch.tensor(fast_weight))
 
     def build_model(self):
         self.exer_emb = nn.Embedding(
-            self.n_item * 2, self.model_cfg['emb_size']
+            self.n_item * 2, self.modeltpl_cfg['emb_size']
         )
         self.seq_model = nn.LSTM(
-            self.model_cfg['emb_size'], self.model_cfg['hidden_size'],
-            self.model_cfg['num_layers'], batch_first=True
+            self.modeltpl_cfg['emb_size'], self.modeltpl_cfg['hidden_size'],
+            self.modeltpl_cfg['num_layers'], batch_first=True
         )
 
-        self.dropout_layer = nn.Dropout(self.model_cfg['dropout_rate'])
-        self.fc_layer = nn.Linear(self.model_cfg['hidden_size'], self.n_item)
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['dropout_rate'])
+        self.fc_layer = nn.Linear(self.modeltpl_cfg['hidden_size'], self.n_item)
 
         f = open("tmp.txt", "w")
         for l in self.train_fasttext():
             f.writelines(l)
         f.close()
         import fasttext
-        self.fasttext_model = fasttext.train_unsupervised("tmp.txt",  dim = self.model_cfg['emb_size'],minCount=1, wordNgrams=2)
+        self.fasttext_model = fasttext.train_unsupervised("tmp.txt",  dim = self.modeltpl_cfg['emb_size'],minCount=1, wordNgrams=2)
 
     def train_fasttext(self):
         stu_ids = self.train_dict['stu_id'].cpu().numpy()
         exer_ids = self.train_dict['exer_seq'].cpu().numpy()
         label_ids = self.train_dict['label_seq'].cpu().numpy()
         mask_ids = self.train_dict['mask_seq'].cpu().numpy()
         len_s = len(stu_ids)
```

## edustudio/model/KT/qikt.py

```diff
@@ -21,82 +21,82 @@
         'output_mode': 'an_irt',
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_cpt = self.datafmt_cfg['dt_info']['cpt_count']
-        self.output_c_all_lambda = self.model_cfg['output_c_all_lambda']
-        self.output_c_next_lambda = self.model_cfg['output_c_next_lambda']
-        self.output_q_all_lambda = self.model_cfg['output_q_all_lambda']
-        self.output_q_next_lambda = self.model_cfg['output_q_next_lambda']
-        self.loss_c_all_lambda = self.model_cfg['loss_c_all_lambda']
-        self.loss_c_next_lambda = self.model_cfg['loss_c_next_lambda']
-        self.loss_q_all_lambda = self.model_cfg['loss_q_all_lambda']
-        self.loss_q_next_lambda = self.model_cfg['loss_q_next_lambda']
-        self.output_mode = self.model_cfg['output_mode']
-        self.device = self.trainfmt_cfg['device']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_cpt = self.datatpl_cfg['dt_info']['cpt_count']
+        self.output_c_all_lambda = self.modeltpl_cfg['output_c_all_lambda']
+        self.output_c_next_lambda = self.modeltpl_cfg['output_c_next_lambda']
+        self.output_q_all_lambda = self.modeltpl_cfg['output_q_all_lambda']
+        self.output_q_next_lambda = self.modeltpl_cfg['output_q_next_lambda']
+        self.loss_c_all_lambda = self.modeltpl_cfg['loss_c_all_lambda']
+        self.loss_c_next_lambda = self.modeltpl_cfg['loss_c_next_lambda']
+        self.loss_q_all_lambda = self.modeltpl_cfg['loss_q_all_lambda']
+        self.loss_q_next_lambda = self.modeltpl_cfg['loss_q_next_lambda']
+        self.output_mode = self.modeltpl_cfg['output_mode']
+        self.device = self.traintpl_cfg['device']
 
     def build_model(self):
         num_q, num_c = self.n_item, self.n_cpt
         self.exer_emb = nn.Embedding(
-            self.n_item, self.model_cfg['emb_size']
+            self.n_item, self.modeltpl_cfg['emb_size']
         )
         self.cpt_emb = nn.Embedding(
-            self.n_cpt, self.model_cfg['emb_size']
+            self.n_cpt, self.modeltpl_cfg['emb_size']
         )
-        self.que_lstm_layer = nn.LSTM(self.model_cfg['emb_size'] * 4, self.model_cfg['hidden_size'], batch_first=True)
-        self.concept_lstm_layer = nn.LSTM(self.model_cfg['emb_size'] * 2, self.model_cfg['hidden_size'], batch_first=True)
+        self.que_lstm_layer = nn.LSTM(self.modeltpl_cfg['emb_size'] * 4, self.modeltpl_cfg['hidden_size'], batch_first=True)
+        self.concept_lstm_layer = nn.LSTM(self.modeltpl_cfg['emb_size'] * 2, self.modeltpl_cfg['hidden_size'], batch_first=True)
 
-        self.dropout_layer = nn.Dropout(self.model_cfg['dropout_rate'])
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['dropout_rate'])
 
-        self.out_question_next = MLP(self.model_cfg['mlp_layer_num'], self.model_cfg['hidden_size'] * 3, 1, self.model_cfg['dropout_rate'])
-        self.out_question_all = MLP(self.model_cfg['mlp_layer_num'], self.model_cfg['hidden_size'], num_q, self.model_cfg['dropout_rate'])
+        self.out_question_next = MLP(self.modeltpl_cfg['mlp_layer_num'], self.modeltpl_cfg['hidden_size'] * 3, 1, self.modeltpl_cfg['dropout_rate'])
+        self.out_question_all = MLP(self.modeltpl_cfg['mlp_layer_num'], self.modeltpl_cfg['hidden_size'], num_q, self.modeltpl_cfg['dropout_rate'])
 
-        self.out_concept_next = MLP(self.model_cfg['mlp_layer_num'], self.model_cfg['hidden_size'] * 3, num_c, self.model_cfg['dropout_rate'])
-        self.out_concept_all = MLP(self.model_cfg['mlp_layer_num'], self.model_cfg['hidden_size'], num_c, self.model_cfg['dropout_rate'])
+        self.out_concept_next = MLP(self.modeltpl_cfg['mlp_layer_num'], self.modeltpl_cfg['hidden_size'] * 3, num_c, self.modeltpl_cfg['dropout_rate'])
+        self.out_concept_all = MLP(self.modeltpl_cfg['mlp_layer_num'], self.modeltpl_cfg['hidden_size'], num_c, self.modeltpl_cfg['dropout_rate'])
 
-        self.que_disc = MLP(self.model_cfg['mlp_layer_num'], self.model_cfg['hidden_size'] * 2, 1, self.model_cfg['dropout_rate'])
+        self.que_disc = MLP(self.modeltpl_cfg['mlp_layer_num'], self.modeltpl_cfg['hidden_size'] * 2, 1, self.modeltpl_cfg['dropout_rate'])
 
     def forward(self, exer_seq, label_seq, cpt_seq, cpt_seq_mask, **kwargs):
 
 
 
         # obtain emb_q, emb_c, emb_qca, emb_qc
         emb_q = self.exer_emb(exer_seq)
         k = self.cpt_emb(cpt_seq)
-        emb_c = torch.sum(k * (cpt_seq_mask.unsqueeze(3).repeat(1, 1, 1, self.model_cfg['emb_size'])),
-                          dim=2) / cpt_seq_mask.sum(dim=2).unsqueeze(2).repeat(1, 1, self.model_cfg['emb_size'])
+        emb_c = torch.sum(k * (cpt_seq_mask.unsqueeze(3).repeat(1, 1, 1, self.modeltpl_cfg['emb_size'])),
+                          dim=2) / cpt_seq_mask.sum(dim=2).unsqueeze(2).repeat(1, 1, self.modeltpl_cfg['emb_size'])
 
 
         e_tmp = torch.cat((emb_q, emb_c), dim=2)
         mask_e = label_seq.unsqueeze(-1).repeat(1, 1, e_tmp.shape[-1]).to(torch.float)
         emb_qca = torch.cat((mask_e*e_tmp, (1-mask_e)*e_tmp), dim=-1)
 
         mask_c = label_seq.unsqueeze(-1).repeat(1, 1, emb_c.shape[-1]).to(torch.float)
         emb_qc = torch.cat((mask_c * emb_c, (1 - mask_c) * emb_c), dim=-1)
 
         emb_qc_shift = emb_qc[:, 1:, :]
         emb_qca_current = emb_qca[:, :-1, :]
         # question model
         que_h = self.dropout_layer(self.que_lstm_layer(emb_qca_current)[0])
-        que_outputs = self.get_outputs(emb_qc_shift, que_h, data=exer_seq[:, 1:], add_name="", model_type="question")
+        que_outputs = self.get_outputs(emb_qc_shift, que_h, data=exer_seq[:, 1:], add_name="", modeltpl_type="question")
         outputs = que_outputs
 
         # concept model
-        emb_ca = torch.cat([emb_c.mul((1 - label_seq).unsqueeze(-1).repeat(1, 1, self.model_cfg['emb_size'])),
-                            emb_c.mul((label_seq).unsqueeze(-1).repeat(1, 1, self.model_cfg['emb_size']))], dim=-1)  # s_t 扩展，分别对应正确的错误的情况
+        emb_ca = torch.cat([emb_c.mul((1 - label_seq).unsqueeze(-1).repeat(1, 1, self.modeltpl_cfg['emb_size'])),
+                            emb_c.mul((label_seq).unsqueeze(-1).repeat(1, 1, self.modeltpl_cfg['emb_size']))], dim=-1)  # s_t 扩展，分别对应正确的错误的情况
 
         emb_ca_current = emb_ca[:, :-1, :]
         # emb_c_shift = emb_c[:,1:,:]
         concept_h = self.dropout_layer(self.concept_lstm_layer(emb_ca_current)[0])
-        concept_outputs = self.get_outputs(emb_qc_shift, concept_h, data=(cpt_seq[:, 1:, :], cpt_seq_mask[:, 1:, :]), add_name="", model_type="concept")
+        concept_outputs = self.get_outputs(emb_qc_shift, concept_h, data=(cpt_seq[:, 1:, :], cpt_seq_mask[:, 1:, :]), add_name="", modeltpl_type="concept")
         outputs['y_concept_all'] = concept_outputs['y_concept_all']
         outputs['y_concept_next'] = concept_outputs['y_concept_next']
 
 
         if self.output_mode=="an_irt":
             def sigmoid_inverse(x,epsilon=1e-8):
                 return torch.log(x/(1-x+epsilon)+epsilon)
@@ -160,18 +160,18 @@
             'loss_main': loss
         }
 
     def get_loss_dict(self, **kwargs):
         return self.get_main_loss(**kwargs)
 
 
-    def get_outputs(self, emb_qc_shift, h, data, add_name="", model_type='question'):
+    def get_outputs(self, emb_qc_shift, h, data, add_name="", modeltpl_type='question'):
         outputs = {}
 
-        if model_type == 'question':
+        if modeltpl_type == 'question':
             h_next = torch.cat([emb_qc_shift, h], axis=-1)
             y_question_next = torch.sigmoid(self.out_question_next(h_next))
             y_question_all = torch.sigmoid(self.out_question_all(h))
             outputs["y_question_next" + add_name] = y_question_next.squeeze(-1)
             outputs["y_question_all" + add_name] = (y_question_all * F.one_hot(data.long(), self.n_item)).sum(-1)
         else:
             h_next = torch.cat([emb_qc_shift, h], axis=-1)
```

## edustudio/model/KT/rkt.py

```diff
@@ -1,37 +1,59 @@
+r"""
+RKT
+##########################################
+
+Reference:
+    Shalini Pandey et al. "RKT: Relation-Aware Self-Attention for Knowledge Tracing." in CIKM 2020.
+
+Reference Code:
+    https://github.com/shalini1194/RKT/blob/master/RKT/model_rkt.py
+
+"""
 import math
 import copy
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 import numpy as np
 from scipy import sparse
 from torch.nn.init import xavier_uniform_, constant_
 
 class RKT(GDBaseModel):
+    r"""
+   RKT
+
+   default_cfg:
+      'embed_size': 200  # dimension of embedding
+      'drop_prob': 0.2      # dropout rate
+      'num_attn_layers': 1        # number of attention layers
+        'num_heads': 5         # number of parallel attention heads
+        'encode_pos':False            # if True, use relative position embeddings
+         'max_pos': 10          # number of position embeddings to use
+   """
     default_cfg = {
         'embed_size': 200,
         'num_attn_layers': 1,
         'num_heads': 5,
         'encode_pos': False,
         'max_pos': 10,
         'drop_prob':0.2,
     }
 
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.embed_size = self.model_cfg['embed_size']
-        self.num_attn_layers = self.model_cfg['num_attn_layers']
-        self.num_heads = self.model_cfg['num_heads']
-        self.encode_pos = self.model_cfg['encode_pos']
-        self.max_pos = self.model_cfg['max_pos']
-        self.drop_prob = self.model_cfg['drop_prob']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.embed_size = self.modeltpl_cfg['embed_size']
+        self.num_attn_layers = self.modeltpl_cfg['num_attn_layers']
+        self.num_heads = self.modeltpl_cfg['num_heads']
+        self.encode_pos = self.modeltpl_cfg['encode_pos']
+        self.max_pos = self.modeltpl_cfg['max_pos']
+        self.drop_prob = self.modeltpl_cfg['drop_prob']
         
     def build_model(self):
         self.item_embeds = nn.Embedding(self.n_item, self.embed_size, padding_idx=0)
         # self.skill_embeds = nn.Embedding(num_skills + 1, embed_size // 2, padding_idx=0)
 
         self.pos_key_embeds = nn.Embedding(self.max_pos, self.embed_size // self.num_heads)
         self.pos_value_embeds = nn.Embedding(self.max_pos, self.embed_size // self.num_heads)
```

## edustudio/model/KT/saint.py

```diff
@@ -1,67 +1,82 @@
+r"""
+SAINT
+##########################################
+
+Reference:
+     Youngduck Choi et al. "Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing" in L-AT-S 2020.
+
+Reference Code:
+    https://github.com/pykt-team/pykt-toolkit/blob/main/pykt/models/saint.py
+
+"""
 import copy
 
 import math
 import pandas as pd
 from torch.nn import Dropout
 
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 import numpy as np
 from torch.nn.init import xavier_uniform_, constant_
 
 class SAINT(GDBaseModel):
+    r"""
+    SAINT
+
+    default_cfg:
+       'emb_size': 256          # dimension of embedding
+        'num_attn_heads': 8     # number of parallel attention heads
+        'dropout_rate': 0.2     # dropout rate
+        'n_blocks':4          # number of Encoder_blocks
+    """
     default_cfg = {
         'emb_size': 256,
         'num_attn_heads': 8,
         'dropout_rate': 0.2,
-        'emb_type': 'qid',
         'n_blocks':4,
     }
 
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.num_q = self.datafmt_cfg['dt_info']['exer_count']
-        self.num_c = self.datafmt_cfg['dt_info']['cpt_count']
-        self.window_size = self.datafmt_cfg['window_size']
-        self.dropout_r = self.model_cfg['dropout_rate']
-        self.num_attn_heads = self.model_cfg['num_attn_heads']
-        self.emb_size = self.model_cfg['emb_size']
-        self.emb_type = self.model_cfg['emb_type']
-        self.n_blocks = self.model_cfg['n_blocks']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.num_q = self.datatpl_cfg['dt_info']['exer_count']
+        self.num_c = self.datatpl_cfg['dt_info']['cpt_count']
+        self.window_size = self.datatpl_cfg['dt_info']['real_window_size']
+        self.dropout_r = self.modeltpl_cfg['dropout_rate']
+        self.num_attn_heads = self.modeltpl_cfg['num_attn_heads']
+        self.emb_size = self.modeltpl_cfg['emb_size']
+        self.n_blocks = self.modeltpl_cfg['n_blocks']
         
     def build_model(self):
         self.embd_pos = nn.Embedding(self.window_size, embedding_dim=self.emb_size)
-        if self.emb_type.startswith("qid"):
-            self.encoder = get_clones(Encoder_block(self.emb_size, self.num_attn_heads, self.num_q, self.num_c, self.window_size, self.dropout_r, self.device),
+        self.encoder = get_clones(Encoder_block(self.emb_size, self.num_attn_heads, self.num_q, self.num_c, self.window_size, self.dropout_r, self.device),
                                       self.n_blocks)
 
         self.decoder = get_clones(Decoder_block(self.emb_size, 2, self.num_attn_heads, self.window_size, self.dropout_r, self.device), self.n_blocks)
 
         self.dropout = Dropout(self.dropout_r)
         self.out = nn.Linear(in_features=self.emb_size, out_features=1)
 
 
     def forward(self, exer_seq, label_seq, cpt_unfold_seq, **kwargs):
-        emb_type = self.emb_type
         label_seq = label_seq.type(torch.int64)
         if self.num_q > 0:
             in_pos = torch.arange(exer_seq.shape[1]).unsqueeze(0).to(self.device)
         else:
             in_pos = torch.arange(cpt_unfold_seq.shape[1]).unsqueeze(0).to(self.device)
         in_pos = self.embd_pos(in_pos)
         first_block = True
         for i in range(self.n_blocks):
             if i >= 1:
                 first_block = False
-            if emb_type == "qid":
-                exer_seq = self.encoder[i](exer_seq, cpt_unfold_seq, in_pos, first_block=first_block)
+            exer_seq = self.encoder[i](exer_seq, cpt_unfold_seq, in_pos, first_block=first_block)
             cpt_unfold_seq = exer_seq
         first_block = True
         for i in range(self.n_blocks):
             if i >= 1:
                 first_block = False
             label_seq = self.decoder[i](label_seq, in_pos, en_out=exer_seq, first_block=first_block)
         ## Output layer
```

## edustudio/model/KT/saint_plus.py

```diff
@@ -1,45 +1,62 @@
+r"""
+SAINT+
+##########################################
+
+Reference:
+     Dongmin Shin et al. "SAINT+: Integrating Temporal Features for EdNet Correctness Prediction" in LAK 2021.
+
+Reference Code:
+    https://github.com/pykt-team/pykt-toolkit/blob/main/pykt/models/saint_plus_plus.py
+
+"""
 import copy
 
 import math
 import pandas as pd
 from torch.nn import Dropout
 
 from ..gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 import numpy as np
 from torch.nn.init import xavier_uniform_, constant_
 
 class SAINT_plus(GDBaseModel):
+    r"""
+    SAINT+
+
+    default_cfg:
+       'emb_size': 256          # dimension of embedding
+        'num_attn_heads': 8     # number of parallel attention heads
+        'dropout_rate': 0.2     # dropout rate
+        'n_blocks':4          # number of Encoder_blocks
+    """
     default_cfg = {
         'emb_size': 256,
         'num_attn_heads': 8,
         'dropout_rate': 0.2,
-        'emb_type': 'qid',
         'n_blocks':4,
     }
 
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.num_q = self.datafmt_cfg['dt_info']['exer_count']
-        self.num_c = self.datafmt_cfg['dt_info']['cpt_count']
-        self.window_size = self.datafmt_cfg['window_size']
-        self.dropout_r = self.model_cfg['dropout_rate']
-        self.num_attn_heads = self.model_cfg['num_attn_heads']
-        self.emb_size = self.model_cfg['emb_size']
-        self.emb_type = self.model_cfg['emb_type']
-        self.n_blocks = self.model_cfg['n_blocks']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.num_q = self.datatpl_cfg['dt_info']['exer_count']
+        self.num_c = self.datatpl_cfg['dt_info']['cpt_count']
+        self.window_size = self.datatpl_cfg['dt_info']['real_window_size']
+        self.dropout_r = self.modeltpl_cfg['dropout_rate']
+        self.num_attn_heads = self.modeltpl_cfg['num_attn_heads']
+        self.emb_size = self.modeltpl_cfg['emb_size']
+        self.n_blocks = self.modeltpl_cfg['n_blocks']
         
     def build_model(self):
         self.embd_pos = nn.Embedding(self.window_size, embedding_dim=self.emb_size)
-        if self.emb_type.startswith("qid"):
-            self.encoder = get_clones(Encoder_block(self.emb_size, self.num_attn_heads, self.num_q, self.num_c, self.window_size, self.dropout_r, self.device),
+        self.encoder = get_clones(Encoder_block(self.emb_size, self.num_attn_heads, self.num_q, self.num_c, self.window_size, self.dropout_r, self.device),
                                       self.n_blocks)
 
         self.decoder = get_clones(Decoder_block(self.emb_size, 2, self.num_attn_heads, self.window_size,
                                                 self.dropout_r, self.num_q, self.num_c, self.device), self.n_blocks)
 
         self.dropout = Dropout(self.dropout_r)
         self.out = nn.Linear(in_features=self.emb_size, out_features=1)
@@ -54,16 +71,15 @@
         else:
             in_pos = torch.arange(cpt_unfold_seq.shape[1]).unsqueeze(0).to(self.device)
         in_pos = self.embd_pos(in_pos)
         first_block = True
         for i in range(self.n_blocks):
             if i >= 1:
                 first_block = False
-            if self.emb_type == "qid":  # same to qid in saint
-                exer_seq = self.encoder[i](exer_seq, cpt_unfold_seq, in_pos, first_block=first_block)
+            exer_seq = self.encoder[i](exer_seq, cpt_unfold_seq, in_pos, first_block=first_block)
             cpt_unfold_seq = exer_seq
         first_block = True
         for i in range(self.n_blocks):
             if i >= 1:
                 first_block = False
             label_seq = self.decoder[i](raw_in_ex, raw_in_cat, label_seq, in_pos, en_out=exer_seq, first_block=first_block)
```

## edustudio/model/KT/sakt.py

```diff
@@ -12,38 +12,38 @@
         'dropout_rate': 0.2,
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
 
     def build_model(self):
-        self.M = nn.Embedding(self.n_item * 2, self.model_cfg['emb_size'])
-        self.E = nn.Embedding(self.n_item, self.model_cfg['emb_size'])
-        self.P = nn.Parameter(torch.Tensor(self.model_cfg['max_length'] - 1, self.model_cfg['emb_size']))
+        self.M = nn.Embedding(self.n_item * 2, self.modeltpl_cfg['emb_size'])
+        self.E = nn.Embedding(self.n_item, self.modeltpl_cfg['emb_size'])
+        self.P = nn.Parameter(torch.Tensor(self.modeltpl_cfg['max_length'] - 1, self.modeltpl_cfg['emb_size']))
 
         self.attn = nn.MultiheadAttention(
-            self.model_cfg['emb_size'], self.model_cfg['n_attn_heads'], dropout=self.model_cfg['dropout_rate']
+            self.modeltpl_cfg['emb_size'], self.modeltpl_cfg['n_attn_heads'], dropout=self.modeltpl_cfg['dropout_rate']
         )
-        self.attn_dropout = nn.Dropout(self.model_cfg['dropout_rate'])
-        self.attn_layer_norm = nn.LayerNorm(self.model_cfg['emb_size'])
+        self.attn_dropout = nn.Dropout(self.modeltpl_cfg['dropout_rate'])
+        self.attn_layer_norm = nn.LayerNorm(self.modeltpl_cfg['emb_size'])
 
         self.FFN = nn.Sequential(
-            nn.Linear(self.model_cfg['emb_size'], self.model_cfg['emb_size']),
+            nn.Linear(self.modeltpl_cfg['emb_size'], self.modeltpl_cfg['emb_size']),
             nn.ReLU(),
-            nn.Dropout(self.model_cfg['dropout_rate']),
-            nn.Linear(self.model_cfg['emb_size'], self.model_cfg['emb_size']),
-            nn.Dropout(self.model_cfg['dropout_rate']),
+            nn.Dropout(self.modeltpl_cfg['dropout_rate']),
+            nn.Linear(self.modeltpl_cfg['emb_size'], self.modeltpl_cfg['emb_size']),
+            nn.Dropout(self.modeltpl_cfg['dropout_rate']),
         )
-        self.FFN_layer_norm = nn.LayerNorm(self.model_cfg['emb_size'])
+        self.FFN_layer_norm = nn.LayerNorm(self.modeltpl_cfg['emb_size'])
 
-        self.pred = nn.Linear(self.model_cfg['emb_size'], 1)
+        self.pred = nn.Linear(self.modeltpl_cfg['emb_size'], 1)
 
     def forward(self, exer_seq, label_seq, **kwargs):
         q, r, qry = exer_seq[:, :-1].to(torch.int64), label_seq[:, :-1].to(torch.int64), exer_seq[:, 1:].to(torch.int64)
 
         x = q + self.n_item* r
 
         M = self.M(x).permute(1, 0, 2)
```

## edustudio/model/KT/simplekt.py

```diff
@@ -29,28 +29,28 @@
 
     def reset(self):
         for p in self.parameters():
             if p.size(0) == self.n_pid + 1 and self.n_pid > 0:
                 constant_(p, 0.)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
-        self.n_question = self.datafmt_cfg['dt_info']['cpt_count']
-        self.dropout = self.model_cfg['dropout_rate']
-        self.kq_same = self.model_cfg['kq_same']
-        self.l2 = self.model_cfg['l2']
-        self.separate_qa = self.model_cfg['separate_qa']
-        self.d_model = self.model_cfg['d_model']
-        self.n_blocks = self.model_cfg['n_blocks']
-        self.final_fc_dim = self.model_cfg['final_fc_dim']
-        self.n_heads = self.model_cfg['n_heads']
-        self.d_ff = self.model_cfg['d_ff']
-        self.seq_len = self.datafmt_cfg['window_size']
-        self.device = self.trainfmt_cfg['device']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.n_question = self.datatpl_cfg['dt_info']['cpt_count']
+        self.dropout = self.modeltpl_cfg['dropout_rate']
+        self.kq_same = self.modeltpl_cfg['kq_same']
+        self.l2 = self.modeltpl_cfg['l2']
+        self.separate_qa = self.modeltpl_cfg['separate_qa']
+        self.d_model = self.modeltpl_cfg['d_model']
+        self.n_blocks = self.modeltpl_cfg['n_blocks']
+        self.final_fc_dim = self.modeltpl_cfg['final_fc_dim']
+        self.n_heads = self.modeltpl_cfg['n_heads']
+        self.d_ff = self.modeltpl_cfg['d_ff']
+        self.seq_len = self.datatpl_cfg['dt_info']['real_window_size']
+        self.device = self.traintpl_cfg['device']
 
     def build_model(self):
         embed_l = self.d_model
         self.n_pid = self.n_item
         if self.n_pid > 0:
             self.difficult_param = nn.Embedding(self.n_pid + 1, 1)
             self.q_embed_diff = nn.Embedding(self.n_question + 1, embed_l)
```

## edustudio/model/KT/skvmn.py

```diff
@@ -134,68 +134,69 @@
         'dropout': 0.2,
     }
 
     def __init__(self, cfg):
         super().__init__(cfg)
 
     def build_cfg(self):
-        self.n_user = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_item = self.datafmt_cfg['dt_info']['exer_count']
+        self.n_user = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_item = self.datatpl_cfg['dt_info']['exer_count']
+        self.window_size = self.datatpl_cfg['dt_info']['real_window_size']
         
 
     def build_model(self):
-        self.x_emb_layer = nn.Embedding(2 * self.n_item, self.model_cfg['embed_dim'])
-        self.k_emb_layer = nn.Embedding(self.n_item, self.model_cfg['embed_dim'])
-        self.Mk = nn.Parameter(torch.Tensor(self.model_cfg['memory_size'], self.model_cfg['embed_dim']))
-        self.Mv = nn.Parameter(torch.Tensor(self.model_cfg['memory_size'], self.model_cfg['embed_dim']))
+        self.x_emb_layer = nn.Embedding(2 * self.n_item, self.modeltpl_cfg['embed_dim'])
+        self.k_emb_layer = nn.Embedding(self.n_item, self.modeltpl_cfg['embed_dim'])
+        self.Mk = nn.Parameter(torch.Tensor(self.modeltpl_cfg['memory_size'], self.modeltpl_cfg['embed_dim']))
+        self.Mv = nn.Parameter(torch.Tensor(self.modeltpl_cfg['memory_size'], self.modeltpl_cfg['embed_dim']))
 
         nn.init.kaiming_normal_(self.Mk)
         nn.init.kaiming_normal_(self.Mv)
 
         self.read_embed_linear = nn.Linear(
-            2 * self.model_cfg['embed_dim'],
-            self.model_cfg['embed_dim'],
+            2 * self.modeltpl_cfg['embed_dim'],
+            self.modeltpl_cfg['embed_dim'],
             bias=True
         )
         self.a_embed = nn.Linear(
-            2 * self.model_cfg['embed_dim'],
-            self.model_cfg['embed_dim'],
+            2 * self.modeltpl_cfg['embed_dim'],
+            self.modeltpl_cfg['embed_dim'],
             bias=True
             )
         self.mem = DKVMN(
-            memory_size=self.model_cfg['memory_size'],
-            memory_key_state_dim=self.model_cfg['embed_dim'],
-            memory_value_state_dim=self.model_cfg['embed_dim'],
+            memory_size=self.modeltpl_cfg['memory_size'],
+            memory_key_state_dim=self.modeltpl_cfg['embed_dim'],
+            memory_value_state_dim=self.modeltpl_cfg['embed_dim'],
             init_memory_key=self.Mk,
-            device=self.trainfmt_cfg['device']
+            device=self.traintpl_cfg['device']
         )
-        self.hx = nn.Parameter(torch.Tensor(1, self.model_cfg['embed_dim']))
-        self.cx = nn.Parameter(torch.Tensor(1, self.model_cfg['embed_dim']))
+        self.hx = nn.Parameter(torch.Tensor(1, self.modeltpl_cfg['embed_dim']))
+        self.cx = nn.Parameter(torch.Tensor(1, self.modeltpl_cfg['embed_dim']))
         nn.init.kaiming_normal_(self.hx )
         nn.init.kaiming_normal_(self.cx)
         # modify hop_lstm
-        self.lstm_cell = nn.LSTMCell(self.model_cfg['embed_dim'], self.model_cfg['embed_dim'])
-        self.dropout_layer = nn.Dropout(self.model_cfg['dropout'])
-        self.p_layer = nn.Linear(self.model_cfg['embed_dim'], 1, bias=True)
+        self.lstm_cell = nn.LSTMCell(self.modeltpl_cfg['embed_dim'], self.modeltpl_cfg['embed_dim'])
+        self.dropout_layer = nn.Dropout(self.modeltpl_cfg['dropout'])
+        self.p_layer = nn.Linear(self.modeltpl_cfg['embed_dim'], 1, bias=True)
 
     def ut_mask(self, seq_len):
         return torch.triu(torch.ones(seq_len, seq_len), diagonal=0).to(dtype=torch.bool)
     
     def triangular_layer(self, correlation_weight, seqlen=100, a=0.075, b=0.088, c=1.00):
         # w'= min((w-a)/(b-a), (c-w)/(c-b))
         # man(w', 0)
         correlation_weight = correlation_weight.view(self.bs * seqlen, -1)
         correlation_weight = torch.cat([correlation_weight[i] for i in range(correlation_weight.shape[0])], 0).unsqueeze(0)
         correlation_weight = torch.cat([(correlation_weight-a)/(b-a), (c-correlation_weight)/(c-b)], 0)
         correlation_weight, _ = torch.min(correlation_weight, 0)
-        w0 = torch.zeros(correlation_weight.shape[0]).to(self.trainfmt_cfg['device'])
+        w0 = torch.zeros(correlation_weight.shape[0]).to(self.traintpl_cfg['device'])
         correlation_weight = torch.cat([correlation_weight.unsqueeze(0), w0.unsqueeze(0)], 0)
         correlation_weight, _ = torch.max(correlation_weight, 0)
 
-        identity_vector_batch = torch.zeros(correlation_weight.shape[0]).to(self.trainfmt_cfg['device'])
+        identity_vector_batch = torch.zeros(correlation_weight.shape[0]).to(self.traintpl_cfg['device'])
         # >=0.6 set to 2，0.1-0.6 set to 1，<=0.1 set to 0
         identity_vector_batch = identity_vector_batch.masked_fill(correlation_weight.lt(0.1), 0)
         identity_vector_batch = identity_vector_batch.masked_fill(correlation_weight.ge(0.1), 1)
         _identity_vector_batch = identity_vector_batch.masked_fill(correlation_weight.ge(0.6), 2)
 
         identity_vector_batch = _identity_vector_batch.view(self.bs * seqlen, -1)
         identity_vector_batch = torch.reshape(identity_vector_batch,[self.bs, seqlen, -1])  #u(x): [bs, seqlen, size_m]
@@ -205,52 +206,52 @@
         # B^2.T
         unique_iv_square_norm = torch.sum(torch.pow(identity_vector_batch, 2), dim=2, keepdim=True)
         unique_iv_square_norm = unique_iv_square_norm.repeat((1, 1, seqlen)).transpose(2, 1)
         # A * B.T
         iv_matrix_product = torch.bmm(identity_vector_batch, identity_vector_batch.transpose(2,1)) # A * A.T 
         # A^2 + B^2 - 2A*B.T
         iv_distances = iv_square_norm + unique_iv_square_norm - 2 * iv_matrix_product
-        iv_distances = torch.where(iv_distances>0.0, torch.tensor(-1e32).to(self.trainfmt_cfg['device']), iv_distances) 
-        masks = self.ut_mask(iv_distances.shape[1]).to(self.trainfmt_cfg['device'])
-        mask_iv_distances = iv_distances.masked_fill(masks, value=torch.tensor(-1e32).to(self.trainfmt_cfg['device'])) 
-        idx_matrix = torch.arange(0,seqlen * seqlen,1).reshape(seqlen,-1).repeat(self.bs,1,1).to(self.trainfmt_cfg['device'])
+        iv_distances = torch.where(iv_distances>0.0, torch.tensor(-1e32).to(self.traintpl_cfg['device']), iv_distances) 
+        masks = self.ut_mask(iv_distances.shape[1]).to(self.traintpl_cfg['device'])
+        mask_iv_distances = iv_distances.masked_fill(masks, value=torch.tensor(-1e32).to(self.traintpl_cfg['device'])) 
+        idx_matrix = torch.arange(0,seqlen * seqlen,1).reshape(seqlen,-1).repeat(self.bs,1,1).to(self.traintpl_cfg['device'])
         final_iv_distance = mask_iv_distances + idx_matrix 
         values, indices = torch.topk(final_iv_distance, 1, dim=2, largest=True) 
 
         _values = values.permute(1,0,2)
         _indices = indices.permute(1,0,2)
         batch_identity_indices = (_values >= 0).nonzero() 
         identity_idx = []
         for identity_indices in batch_identity_indices:
             pre_idx = _indices[identity_indices[0],identity_indices[1]] 
             idx = torch.cat([identity_indices[:-1],pre_idx], dim=-1)
             identity_idx.append(idx)
         if len(identity_idx) > 0:
             identity_idx = torch.stack(identity_idx, dim=0)
         else:
-            identity_idx = torch.tensor([]).to(self.trainfmt_cfg['device'])
+            identity_idx = torch.tensor([]).to(self.traintpl_cfg['device'])
 
         return identity_idx 
 
     def forward(self, exer_seq, label_seq, **kwargs):
         k = self.k_emb_layer(exer_seq)  # Embedding Layer: about question
         self.bs = exer_seq.shape[0]
         x = (exer_seq + self.n_item * label_seq).long()
 
         value_read_content_l = []  # seqlen * bs * dim | read_content
         input_embed_l = []  # seqlen * bs * dim| q
         correlation_weight_list = []  # seqlen * bs * mem_size | correlation_weight
         ft = []
         # After atten about new question, Update Memory-value
-        mem_value = self.Mv.unsqueeze(0).repeat(self.bs, 1, 1).to(self.trainfmt_cfg['device'])  # bs * mem_size * dim
-        for i in range(self.datafmt_cfg['window_size']):
+        mem_value = self.Mv.unsqueeze(0).repeat(self.bs, 1, 1).to(self.traintpl_cfg['device'])  # bs * mem_size * dim
+        for i in range(self.window_size):
             # k: bs * seqlen * dim
             q = k.permute(1, 0, 2)[i]  # q: bs * dim
             # attention Process
-            correlation_weight = self.mem.attention(q).to(self.trainfmt_cfg['device'])  # bs * memory_size
+            correlation_weight = self.mem.attention(q).to(self.traintpl_cfg['device'])  # bs * memory_size
             
             # Read Process
             read_content = self.mem.read(correlation_weight, mem_value)  # read_count: bs * dim
             # modify
             batch_predict_input = torch.cat([read_content, q], 1)  #  bs * 2dim
             f = torch.tanh(self.read_embed_linear(batch_predict_input))
 
@@ -259,24 +260,24 @@
             value_read_content_l.append(read_content)
             input_embed_l.append(q)
             ft.append(f)
 
             # Write Process  |  student response + f-vector 
             y = self.x_emb_layer(x[:,i])
             write_embed = torch.cat([f, y], 1) # bz * (f_dim + y_dim)
-            write_embed = self.a_embed(write_embed).to(self.trainfmt_cfg['device']) # bs * dim
+            write_embed = self.a_embed(write_embed).to(self.traintpl_cfg['device']) # bs * dim
             mem_value = self.mem.write(correlation_weight, write_embed, mem_value)
         # w: bs * seqlen * mem_size
-        w = torch.cat([correlation_weight_list[i].unsqueeze(1) for i in range(self.datafmt_cfg['window_size'])], 1)
-        idx_values = self.triangular_layer(w, self.datafmt_cfg['window_size'])
+        w = torch.cat([correlation_weight_list[i].unsqueeze(1) for i in range(self.window_size)], 1)
+        idx_values = self.triangular_layer(w, self.window_size)
         ft = torch.stack(ft, dim=0)
 
         hidden_state, cell_state = [], []
         hx, cx = self.hx.repeat(self.bs, 1), self.cx.repeat(self.bs, 1)
-        for i in range(self.datafmt_cfg['window_size']):
+        for i in range(self.window_size):
             for j in range(self.bs):
                 if idx_values.shape[0] != 0 and i == idx_values[0][0] and j == idx_values[0][1]:
                     hx[j,:] = hidden_state[idx_values[0][2]][j]
                     cx = cx.clone()
                     cx[j,:] = cell_state[idx_values[0][2]][j]
                     idx_values = idx_values[1:]
             hx, cx = self.lstm_cell(ft[i], (hx, cx))
```

## edustudio/model/KT/GKT/gkt.py

```diff
@@ -1,7 +1,19 @@
+r"""
+GKT
+##########################################
+
+Reference:
+    Hiromi Nakagawa et al. "Graph-based Knowledge Tracing: Modeling Student Proficiency Using Graph Neural Network" in WI 2019.
+
+Reference Code:
+    https://github.com/jhljx/GKT
+
+"""
+
 from ...gd_basemodel import GDBaseModel
 import torch.nn as nn
 import torch
 import torch.nn.functional as F
 import numpy as np
 from .building_blocks import MLP, MLPDecoder, MLPEncoder, EraseAddGate, ScaledDotProductAttention
 import scipy.sparse as sp
@@ -28,40 +40,40 @@
         self.graph = build_dense_graph(self.n_exer)
         self.graph_model = None
         # self.graph = kwargs['graph']
         # self.graph_model = kwargs['graph_model']
         pass
 
     def build_cfg(self):
-        self.graph_type = self.model_cfg['graph_type']
-        self.n_stu = self.datafmt_cfg['dt_info']['stu_count']
-        self.n_exer = self.datafmt_cfg['dt_info']['exer_count']
-        self.edge_type_num = self.model_cfg['edge_type_num']
+        self.graph_type = self.modeltpl_cfg['graph_type']
+        self.n_stu = self.datatpl_cfg['dt_info']['stu_count']
+        self.n_exer = self.datatpl_cfg['dt_info']['exer_count']
+        self.edge_type_num = self.modeltpl_cfg['edge_type_num']
 
-        self.hidden_dim = self.model_cfg['hidden_dim']
-        self.emb_dim = self.model_cfg['emb_dim']
+        self.hidden_dim = self.modeltpl_cfg['hidden_dim']
+        self.emb_dim = self.modeltpl_cfg['emb_dim']
 
         assert self.graph_type in ['Dense', 'Transition', 'DKT', 'PAM', 'MHA', 'VAE']
 
     def build_model(self):
-        self.exer_emb = nn.Embedding(self.n_exer * 2, self.model_cfg['emb_dim'])
-        self.cpt_emb = nn.Embedding(self.n_exer, self.model_cfg['emb_dim'])
+        self.exer_emb = nn.Embedding(self.n_exer * 2, self.modeltpl_cfg['emb_dim'])
+        self.cpt_emb = nn.Embedding(self.n_exer, self.modeltpl_cfg['emb_dim'])
 
         if self.graph_type in ['Dense', 'Transition', 'DKT']:
             assert  self.edge_type_num == 2
             assert self.graph is not None
             self.graph = nn.Parameter(self.graph)  # [concept_num, concept_num]
             self.graph.requires_grad = False  # fix parameter
         else:  # ['PAM', 'MHA', 'VAE']
             if self.graph_type == 'PAM':
                 self.graph = nn.Parameter(torch.rand(self.n_exer, self.n_exer))
             else:
                 assert self.graph_model is not None
 
-        dropout = self.model_cfg['dropout']
+        dropout = self.modeltpl_cfg['dropout']
         mlp_input_dim =  self.hidden_dim + self.emb_dim
 
         self.f_self = MLP(mlp_input_dim, self.hidden_dim, self.hidden_dim, dropout=dropout)
         self.f_neighbor_list = nn.ModuleList()
         if self.graph_type in ['Dense', 'Transition', 'DKT', 'PAM']:
             # f_in and f_out functions
             self.f_neighbor_list.append(MLP(2 * mlp_input_dim, self.hidden_dim, self.hidden_dim, dropout=dropout))
```

## edustudio/quickstart/init_all.py

```diff
@@ -5,24 +5,24 @@
 from edustudio.utils.common import UnifyConfig, PathUtil, Logger
 import os
 
 
 def init_all(cfg: UnifyConfig):
     frame_cfg = cfg.frame_cfg
     dataset = cfg.dataset
-    trainfmt_cls =cfg.trainfmt_cfg.cls if isinstance(cfg.trainfmt_cfg.cls, str) else cfg.trainfmt_cfg.cls.__name__
+    traintpl_cls =cfg.traintpl_cfg.cls if isinstance(cfg.traintpl_cfg.cls, str) else cfg.traintpl_cfg.cls.__name__
 
     frame_cfg.data_folder_path = f"{frame_cfg.DATA_FOLDER_PATH}/{dataset}"
     # PathUtil.check_path_exist(frame_cfg.data_folder_path)
 
     frame_cfg.TEMP_FOLDER_PATH = os.path.realpath(frame_cfg.TEMP_FOLDER_PATH)
     frame_cfg.ARCHIVE_FOLDER_PATH = os.path.realpath(frame_cfg.ARCHIVE_FOLDER_PATH)
 
-    frame_cfg.temp_folder_path = f"{frame_cfg.TEMP_FOLDER_PATH}/{dataset}/{trainfmt_cls}/{cfg.model_cfg.cls}/{frame_cfg.ID}"
-    frame_cfg.archive_folder_path = f"{frame_cfg.ARCHIVE_FOLDER_PATH}/{dataset}/{trainfmt_cls}/{cfg.model_cfg.cls}"
+    frame_cfg.temp_folder_path = f"{frame_cfg.TEMP_FOLDER_PATH}/{dataset}/{traintpl_cls}/{cfg.modeltpl_cfg.cls}/{frame_cfg.ID}"
+    frame_cfg.archive_folder_path = f"{frame_cfg.ARCHIVE_FOLDER_PATH}/{dataset}/{traintpl_cls}/{cfg.modeltpl_cfg.cls}"
     PathUtil.auto_create_folder_path(
         frame_cfg.temp_folder_path, frame_cfg.archive_folder_path
     )
     log_filepath = f"{frame_cfg.temp_folder_path}/{frame_cfg.ID}.log"
     if frame_cfg['LOG_WITHOUT_DATE']:
         cfg.logger = Logger(filepath=log_filepath, fmt='[%(levelname)s]: %(message)s', date_fmt=None).get_std_logger()
     else:
```

## edustudio/quickstart/parse_cfg.py

```diff
@@ -5,196 +5,225 @@
 from ast import literal_eval
 from collections import defaultdict
 import importlib
 
 def get_global_cfg(
     dataset:str,
     cfg_file_name:str,
-    trainfmt_cfg_dict: Dict[str, Any],
-    datafmt_cfg_dict:  Dict[str, Any],
-    evalfmt_cfg_dict:  Dict[str, Any],
-    model_cfg_dict: Dict[str, Any],
+    traintpl_cfg_dict: Dict[str, Any],
+    datatpl_cfg_dict:  Dict[str, Any],
+    evaltpl_cfg_dict:  Dict[str, Any],
+    modeltpl_cfg_dict: Dict[str, Any],
     frame_cfg_dict:  Dict[str, Any],
 ):
     parser = argparse.ArgumentParser()
     parser.add_argument('--dataset', '-dt', type=str,
                         help='dataset name', dest='dataset', default=dataset)
     parser.add_argument('--cfg_file_name', '-f', type=str,
                         help='config filename', dest='cfg_file_name', default=cfg_file_name)
-    parser.add_argument('--trainfmt_cfg.cls', '-trainfmt_cls', type=str,
-                        dest='trainfmt_cls', default=trainfmt_cfg_dict.get('cls', None))
-    parser.add_argument('--datafmt_cfg.cls', '-datafmt_cls', type=str,
-                        dest='datafmt_cls', default=datafmt_cfg_dict.get('cls', None))
-    parser.add_argument('--model_cfg.cls', '-model_cls', type=str,
-                        dest='model_cls', default=model_cfg_dict.get('cls', None))
-    parser.add_argument('--evalfmt_cfg.clses', '-evalfmt_clses', nargs='+',
-                        dest='evalfmt_clses', default=evalfmt_cfg_dict.get('clses', None))
-    parser.add_argument('--datafmt_cfg.backbone_datafmt_cls', '-datafmt_backbone_cls', type=str,
-                        dest='backbone_datafmt_cls', default=datafmt_cfg_dict.get('backbone_datafmt_cls', None))
-    parser.add_argument('--model_cfg.backbone_model_cls', '-model_backbone_cls', type=str,
-                        dest='backbone_model_cls', default=model_cfg_dict.get('backbone_model_cls', None))
+    parser.add_argument('--traintpl_cfg.cls', '-traintpl_cls', type=str,
+                        dest='traintpl_cls', default=traintpl_cfg_dict.get('cls', None))
+    parser.add_argument('--datatpl_cfg.cls', '-datatpl_cls', type=str,
+                        dest='datatpl_cls', default=datatpl_cfg_dict.get('cls', None))
+    parser.add_argument('--modeltpl_cfg.cls', '-modeltpl_cls', type=str,
+                        dest='modeltpl_cls', default=modeltpl_cfg_dict.get('cls', None))
+    parser.add_argument('--evaltpl_cfg.clses', '-evaltpl_clses', nargs='+',
+                        dest='evaltpl_clses', default=evaltpl_cfg_dict.get('clses', None))
+    parser.add_argument('--datatpl_cfg.backbone_datatpl_cls', '-datatpl_backbone_cls', type=str,
+                        dest='backbone_datatpl_cls', default=datatpl_cfg_dict.get('backbone_datatpl_cls', None))
+    parser.add_argument('--modeltpl_cfg.backbone_modeltpl_cls', '-modeltpl_backbone_cls', type=str,
+                        dest='backbone_modeltpl_cls', default=modeltpl_cfg_dict.get('backbone_modeltpl_cls', None))
+    parser.add_argument('--datatpl_cfg.mid2cache_op_seq', '-mid2cache_op_seq', type=str,
+                        dest='mid2cache_op_seq', default=datatpl_cfg_dict.get('mid2cache_op_seq', None))   
     args, unknown_args = parser.parse_known_args()
     assert args.dataset is not None
     
     unknown_arg_dict = defaultdict(dict)
     if len(unknown_args) > 0:
         assert len(unknown_args) % 2 == 0, \
             "number of extra parameters[except dt and cfg_file_name] from command line should be even"
         for i in range(int(len(unknown_args) / 2)):
             assert unknown_args[2 * i].startswith("--"), \
                 "the first term in extra parameter[except dt and cfg_file_name] pair should start with '--'"
             key, value = unknown_args[2 * i][2:], unknown_args[2 * i + 1]
-            if key.startswith('trainfmt_cfg.'):
-                unknown_arg_dict['trainfmt_cfg'][key] = value
-            elif key.startswith('datafmt_cfg.'):
-                unknown_arg_dict['datafmt_cfg'][key] = value
-            elif key.startswith('model_cfg.'):
-                unknown_arg_dict['model_cfg'][key] = value
-            elif key.startswith('evalfmt_cfg.'):
-               unknown_arg_dict['evalfmt_cfg'][key] = value
+            if key.startswith('traintpl_cfg.'):
+                unknown_arg_dict['traintpl_cfg'][key] = value
+            elif key.startswith('datatpl_cfg.'):
+                unknown_arg_dict['datatpl_cfg'][key] = value
+            elif key.startswith('modeltpl_cfg.'):
+                unknown_arg_dict['modeltpl_cfg'][key] = value
+            elif key.startswith('evaltpl_cfg.'):
+               unknown_arg_dict['evaltpl_cfg'][key] = value
             elif key.startswith('frame_cfg.'):
                 unknown_arg_dict['frame_cfg'][key] = value
             else:
                 raise ValueError(f"unsupported key: {key}")
 
 
     cfg = UnifyConfig({
-        'trainfmt_cfg': UnifyConfig(), 'datafmt_cfg': UnifyConfig(),
-        'model_cfg': UnifyConfig(), 'evalfmt_cfg': UnifyConfig(), 
+        'traintpl_cfg': UnifyConfig(), 'datatpl_cfg': UnifyConfig(),
+        'modeltpl_cfg': UnifyConfig(), 'evaltpl_cfg': UnifyConfig(), 
         'frame_cfg': UnifyConfig()
     })
     cfg.dataset = args.dataset
         
     # process frame cfg
     cfg.frame_cfg = UnifyConfig.from_py_module(settings)
     for k,v in frame_cfg_dict.items():
         assert k in cfg.frame_cfg
-        assert type(cfg.frame_cfg[k]) is type(v)
+        assert type(v) is None or type(cfg.frame_cfg[k]) is type(v)
         cfg.frame_cfg[k] = v
     for k,v in unknown_arg_dict['frame_cfg'].items():
         assert k in cfg.frame_cfg
         if type(cfg.frame_cfg[k]) is not str:
             v = type(cfg.frame_cfg)(literal_eval(v))
         cfg.dot_set(k, v)
 
-    trainfmt_cls = args.trainfmt_cls
-    datafmt_cls = args.datafmt_cls
-    model_cls = args.model_cls
-    evalfmt_clses = args.evalfmt_clses
+    traintpl_cls = args.traintpl_cls
+    datatpl_cls = args.datatpl_cls
+    modeltpl_cls = args.modeltpl_cls
+    evaltpl_clses = args.evaltpl_clses
     if args.cfg_file_name is not None:
         yaml_cfg = UnifyConfig.from_yml_file(
             f"{cfg.frame_cfg['CFG_FOLDER_PATH']}/{cfg.dataset}/{args.cfg_file_name}"
         )
         assert 'frame_cfg' not in yaml_cfg
         assert 'dataset' not in yaml_cfg
         assert 'logger' not in yaml_cfg
-        trainfmt_cls = trainfmt_cls or yaml_cfg.get('trainfmt_cfg', {'cls': None}).get("cls")
-        datafmt_cls = datafmt_cls or yaml_cfg.get('datafmt_cfg', {'cls': None}).get("cls")
-        model_cls = model_cls or yaml_cfg.get('model_cfg', {'cls': None}).get("cls")
-        evalfmt_clses = evalfmt_clses or yaml_cfg.get('evalfmt_cfg', {'clses': None}).get("clses")
-
-    assert trainfmt_cls is not None
-    assert datafmt_cls is not None
-    assert model_cls is not None
-    assert evalfmt_clses is not None
-    assert len(set(evalfmt_clses)) == len(evalfmt_clses)
-
-
-    cfg.dot_set('trainfmt_cfg.cls', trainfmt_cls)
-    cfg.dot_set('datafmt_cfg.cls', datafmt_cls)
-    cfg.dot_set('model_cfg.cls', model_cls)
-    cfg.dot_set('evalfmt_cfg.clses', evalfmt_clses)
-    
-    if isinstance(trainfmt_cls, str):
-        cfg.trainfmt_cfg.update(
-            importlib.import_module("edustudio.trainfmt").
-            __getattribute__(trainfmt_cls).get_default_cfg()
+        traintpl_cls = traintpl_cls or yaml_cfg.get('traintpl_cfg', {'cls': None}).get("cls")
+        datatpl_cls = datatpl_cls or yaml_cfg.get('datatpl_cfg', {'cls': None}).get("cls")
+        modeltpl_cls = modeltpl_cls or yaml_cfg.get('modeltpl_cfg', {'cls': None}).get("cls")
+        evaltpl_clses = evaltpl_clses or yaml_cfg.get('evaltpl_cfg', {'clses': None}).get("clses")
+
+        args.backbone_modeltpl_cls = args.backbone_modeltpl_cls or yaml_cfg.get('modeltpl_cfg', {'backbone_modeltpl_cls': None}).get("backbone_modeltpl_cls")
+        args.backbone_datatpl_cls = args.backbone_datatpl_cls or yaml_cfg.get('datatpl_cfg', {'backbone_datatpl_cls': None}).get("backbone_datatpl_cls")
+        args.mid2cache_op_seq = args.mid2cache_op_seq or yaml_cfg.get('datatpl_cfg', {'mid2cache_op_seq': None}).get("mid2cache_op_seq")
+
+    assert traintpl_cls is not None
+    assert datatpl_cls is not None
+    assert modeltpl_cls is not None
+    assert evaltpl_clses is not None
+    assert len(set(evaltpl_clses)) == len(evaltpl_clses)
+
+
+    cfg.dot_set('traintpl_cfg.cls', traintpl_cls)
+    cfg.dot_set('datatpl_cfg.cls', datatpl_cls)
+    cfg.dot_set('modeltpl_cfg.cls', modeltpl_cls)
+    cfg.dot_set('evaltpl_cfg.clses', evaltpl_clses)
+    
+    if isinstance(traintpl_cls, str):
+        cfg.traintpl_cfg.update(
+            importlib.import_module("edustudio.traintpl").
+            __getattribute__(traintpl_cls).get_default_cfg()
         )
     else:
-        cfg.trainfmt_cfg.update(trainfmt_cls.get_default_cfg())
+        cfg.traintpl_cfg.update(traintpl_cls.get_default_cfg())
     
-    if isinstance(model_cls, str):
-        cfg.model_cfg.update(
+    if isinstance(modeltpl_cls, str):
+        cfg.modeltpl_cfg.update(
             importlib.import_module("edustudio.model").
-            __getattribute__(model_cls).get_default_cfg(backbone_model_cls=args.backbone_model_cls)
+            __getattribute__(modeltpl_cls).get_default_cfg(backbone_modeltpl_cls=args.backbone_modeltpl_cls)
         )
     else:
-        cfg.model_cfg.update(model_cls.get_default_cfg(backbone_model_cls=args.backbone_model_cls))
+        cfg.modeltpl_cfg.update(modeltpl_cls.get_default_cfg(backbone_modeltpl_cls=args.backbone_modeltpl_cls))
     
-    if isinstance(datafmt_cls, str):
-        cfg.datafmt_cfg.update(
-            importlib.import_module("edustudio.datafmt").
-            __getattribute__(datafmt_cls).get_default_cfg(backbone_datafmt_cls=args.backbone_datafmt_cls)
+    if isinstance(datatpl_cls, str):
+        cfg.datatpl_cfg.update(
+            importlib.import_module("edustudio.datatpl").
+            __getattribute__(datatpl_cls).get_default_cfg(backbone_datatpl_cls=args.backbone_datatpl_cls, mid2cache_op_seq=args.mid2cache_op_seq)
         )
     else:
-        cfg.datafmt_cfg.update(datafmt_cls.get_default_cfg(backbone_datafmt_cls=args.backbone_datafmt_cls))
+        cfg.datatpl_cfg.update(datatpl_cls.get_default_cfg(backbone_datatpl_cls=args.backbone_datatpl_cls, mid2cache_op_seq=args.mid2cache_op_seq))
     
-    for evalfmt_cls in evalfmt_clses:
-        if isinstance(evalfmt_cls, str):
-            cfg.evalfmt_cfg[evalfmt_cls] = importlib.import_module("edustudio.evalfmt").\
-                __getattribute__(evalfmt_cls).get_default_cfg()
+    for evaltpl_cls in evaltpl_clses:
+        if isinstance(evaltpl_cls, str):
+            cfg.evaltpl_cfg[evaltpl_cls] = importlib.import_module("edustudio.evaltpl").\
+                __getattribute__(evaltpl_cls).get_default_cfg()
         else:
-            cfg.evalfmt_cfg[evalfmt_cls.__name__] = evalfmt_cls.get_default_cfg()
+            cfg.evaltpl_cfg[evaltpl_cls.__name__] = evaltpl_cls.get_default_cfg()
+
+
+    if args.mid2cache_op_seq is not None:
+        atom_data_op_set = {(op if type(op) is str else op.__name__) for op in args.mid2cache_op_seq}
+    else:
+        atom_data_op_set = {(op if type(op) is str else op.__name__) for op in cfg['datatpl_cfg'].get('mid2cache_op_seq', [])}
 
     # config file
     if args.cfg_file_name is not None:
-        for config_name in ['trainfmt_cfg', 'datafmt_cfg', 'model_cfg']:
+        if config_name == 'datatpl_cfg':
             for k,v in yaml_cfg[config_name].items():
                 assert k in cfg[config_name], f"invalid key: {k}"
                 if k == 'cls': continue
-                assert type(cfg[config_name][k]) is type(v)
+                # assert type(v) is None or type(cfg[config_name][k]) is type(v)
+                if k in atom_data_op_set:
+                    for kk,vv in datatpl_cfg_dict[k].items():
+                        assert kk in cfg['datatpl_cfg'][k], f"invalid key: {kk}"
+                        cfg['datatpl_cfg'][k][kk] = vv
+                else:
+                    cfg[config_name][k] = v 
+        for config_name in ['traintpl_cfg', 'modeltpl_cfg']:
+            for k,v in yaml_cfg[config_name].items():
+                assert k in cfg[config_name], f"invalid key: {k}"
+                if k == 'cls': continue
+                # assert type(v) is None or type(cfg[config_name][k]) is type(v)
                 cfg[config_name][k] = v
-        for k,v in yaml_cfg['evalfmt_cfg'].items():
+        for k,v in yaml_cfg['evaltpl_cfg'].items():
             if k == 'clses': continue
-            assert k in cfg.evalfmt_cfg['clses'], f"invalid key: {k}"
+            assert k in cfg.evaltpl_cfg['clses'], f"invalid key: {k}"
             assert type(v) is dict
             for kk, vv in v.items():
-                assert kk in cfg.evalfmt_cfg[k], f"invalid key: {kk}"
-                assert type(cfg.evalfmt_cfg[k][kk]) is type(vv)
-                cfg.evalfmt_cfg[k][kk] = vv
+                assert kk in cfg.evaltpl_cfg[k], f"invalid key: {kk}"
+                assert type(cfg.evaltpl_cfg[k][kk]) is type(vv)
+                cfg.evaltpl_cfg[k][kk] = vv
 
     # parameter dict
-    for k,v in trainfmt_cfg_dict.items():
+    for k,v in traintpl_cfg_dict.items():
         if k == 'cls': continue
-        assert k in cfg['trainfmt_cfg'], f"invalid key: {k}"
-        assert type(cfg['trainfmt_cfg'][k]) is type(v)
-        cfg['trainfmt_cfg'][k] = v
-    for k,v in datafmt_cfg_dict.items():
-        if k == 'cls' or k == 'backbone_datafmt_cls': continue
-        assert k in cfg['datafmt_cfg'], f"invalid key: {k}"
-        assert type(cfg['datafmt_cfg'][k]) is type(v)
-        cfg['datafmt_cfg'][k] = v
-    for k,v in model_cfg_dict.items():
-        if k == 'cls' or k == 'backbone_model_cls': continue
-        assert k in cfg['model_cfg'], f"invalid key: {k}"
-        assert type(cfg['model_cfg'][k]) is type(v)
-        cfg['model_cfg'][k] = v
+        assert k in cfg['traintpl_cfg'], f"invalid key: {k}"
+        # assert type(v) is None or type(cfg['traintpl_cfg'][k]) is type(v)
+        cfg['traintpl_cfg'][k] = v
+    
+    for k,v in datatpl_cfg_dict.items():
+        if k == 'cls' or k == 'backbone_datatpl_cls': continue
+        assert k in cfg['datatpl_cfg'], f"invalid key: {k}"
+        # assert type(v) is None or type(cfg['datatpl_cfg'][k]) is type(v)
+        if k in atom_data_op_set:
+            for kk,vv in datatpl_cfg_dict[k].items():
+                assert kk in cfg['datatpl_cfg'][k], f"invalid key: {kk}"
+                cfg['datatpl_cfg'][k][kk] = vv
+        else:
+            cfg['datatpl_cfg'][k] = v
+    for k,v in modeltpl_cfg_dict.items():
+        if k == 'cls' or k == 'backbone_modeltpl_cls': continue
+        assert k in cfg['modeltpl_cfg'], f"invalid key: {k}"
+        # assert type(v) is None or type(cfg['modeltpl_cfg'][k]) is type(v)
+        cfg['modeltpl_cfg'][k] = v
 
-    evalfmt_clses_name = [cls_ if isinstance(cls_, str) else cls_.__name__ for cls_ in cfg.evalfmt_cfg['clses']]
-    for k,v in evalfmt_cfg_dict.items():
+    evaltpl_clses_name = [cls_ if isinstance(cls_, str) else cls_.__name__ for cls_ in cfg.evaltpl_cfg['clses']]
+    for k,v in evaltpl_cfg_dict.items():
         if k == 'clses': continue
-        assert k in evalfmt_clses_name, f"invalid key: {k}"
+        assert k in evaltpl_clses_name, f"invalid key: {k}"
         assert type(v) is dict
         for kk, vv in v.items():
-            assert kk in cfg.evalfmt_cfg[k], f"invalid key: {kk}"
-            assert type(cfg.evalfmt_cfg[k][kk]) is type(vv)
-            cfg.evalfmt_cfg[k][kk] = vv
+            assert kk in cfg.evaltpl_cfg[k], f"invalid key: {kk}"
+            # assert type(cfg.evaltpl_cfg[k][kk]) is type(vv)
+            cfg.evaltpl_cfg[k][kk] = vv
     
 
     # command line
-    for config_name in ['trainfmt_cfg', 'datafmt_cfg', 'model_cfg']:
+    for config_name in ['traintpl_cfg', 'datatpl_cfg', 'modeltpl_cfg']:
         for k,v in unknown_arg_dict[config_name].items():
             if k == 'cls': continue
             kk = k.split('.')[-1]
             assert kk in cfg[config_name], f"invalid key: {kk}"
             if type(cfg[config_name][kk]) is not str:
                 v = type(cfg[config_name][kk])(literal_eval(v))
             cfg.dot_set(k, v)
-    for k,v in unknown_arg_dict["evalfmt_cfg"].items():
+    for k,v in unknown_arg_dict["evaltpl_cfg"].items():
         kk = k.split('.')[-1]
-        assert kk in cfg['evalfmt_cfg'], f"invalid key: {kk}"
+        assert kk in cfg['evaltpl_cfg'], f"invalid key: {kk}"
         if kk == 'clses': continue
         if type(cfg.dot_get(k)) is not str:
             v = type(cfg.dot_get(k))(literal_eval(v))
         cfg.dot_set(k, v)
     
     return cfg
```

## edustudio/quickstart/quickstart.py

```diff
@@ -10,41 +10,41 @@
 
 from edustudio.utils.common import UnifyConfig
 
 
 def run_edustudio(
     dataset: str = None,
     cfg_file_name: str = None,  # config file
-    trainfmt_cfg_dict: Dict[str, Any] = {},  # parameters dictionary
-    datafmt_cfg_dict:  Dict[str, Any] = {},  # parameters dictionary
-    evalfmt_cfg_dict:  Dict[str, Any] = {},  # parameters dictionary
-    model_cfg_dict: Dict[str, Any] = {},  # parameters dictionary
+    traintpl_cfg_dict: Dict[str, Any] = {},  # parameters dictionary
+    datatpl_cfg_dict:  Dict[str, Any] = {},  # parameters dictionary
+    evaltpl_cfg_dict:  Dict[str, Any] = {},  # parameters dictionary
+    modeltpl_cfg_dict: Dict[str, Any] = {},  # parameters dictionary
     frame_cfg_dict:  Dict[str, Any] = {},  # parameters dictionary
     return_cfg_and_result: bool = False,
 ):
     cfg: UnifyConfig = get_global_cfg(
-        dataset, cfg_file_name, trainfmt_cfg_dict,
-        datafmt_cfg_dict, evalfmt_cfg_dict, model_cfg_dict, frame_cfg_dict
+        dataset, cfg_file_name, traintpl_cfg_dict,
+        datatpl_cfg_dict, evaltpl_cfg_dict, modeltpl_cfg_dict, frame_cfg_dict
     )
     init_all(cfg)
     try:
         cfg.logger.info("====" * 15)
         cfg.logger.info(f"[ID]: {cfg.frame_cfg.ID}")
         cfg.logger.info(f"[DATASET]: {cfg.dataset}")
         cfg.logger.info(f"[ARGV]: {sys.argv}")
         cfg.logger.info(f"[ALL_CFG]: \n{cfg.dump_fmt()}")
         cfg.dump_file(f"{cfg.frame_cfg.temp_folder_path}/cfg.json")
         cfg.logger.info("====" * 15)
-        if isinstance(cfg.trainfmt_cfg['cls'], str):
-            cls = importlib.import_module('edustudio.trainfmt').\
-                __getattribute__(cfg.trainfmt_cfg['cls'])
+        if isinstance(cfg.traintpl_cfg['cls'], str):
+            cls = importlib.import_module('edustudio.traintpl').\
+                __getattribute__(cfg.traintpl_cfg['cls'])
         else:
-            cls = cfg.trainfmt_cfg['cls']
-        trainfmt = cls(cfg)
-        trainfmt.start()
+            cls = cfg.traintpl_cfg['cls']
+        traintpl = cls(cfg)
+        traintpl.start()
         cfg.logger.info(f"Task: {cfg.frame_cfg.ID} Completed!")
         logging.shutdown()
         shutil.move(cfg.frame_cfg.temp_folder_path, cfg.frame_cfg.archive_folder_path)
     except Exception as e:
         cfg.logger.error(traceback.format_exc())
         raise e
```

## edustudio/utils/callback/callbacks/history.py

```diff
@@ -60,9 +60,11 @@
             plt.ylabel("value")
             plt.plot(x_arr, value_arr)
             plt.autoscale()
             plt.savefig(f"{self.folder_path}/plots/{name}.png", dpi=500, bbox_inches='tight', pad_inches=0.1)
         
     @staticmethod
     def dump_json(data, filepath):
+        if not os.path.exists(os.path.dirname(filepath)):
+            os.makedirs(os.path.dirname(filepath))
         with open(filepath, 'w', encoding='utf8') as f:
             json.dump(data, fp=f, indent=2, ensure_ascii=False, cls=NumpyEncoder)
```

## Comparing `edustudio-0.0.1a1.dist-info/LICENSE` & `edustudio-1.0.0a2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `edustudio-0.0.1a1.dist-info/METADATA` & `edustudio-1.0.0a2.dist-info/METADATA`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: edustudio
-Version: 0.0.1a1
+Version: 1.0.0a2
 Summary: a Unified and Templatized Framework for Student Assessment Models
 Home-page: https://github.com/HFUT-LEC/EduStudio
 Author: HFUT-LEC
 Author-email: lmcRS.hfut@gmail.com
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: License :: OSI Approved :: MIT License
@@ -19,9 +19,9 @@
 Requires-Dist: scikit-learn (>=0.23.2)
 Requires-Dist: pyyaml (>=5.1.0)
 Requires-Dist: tensorboard (>=2.5.0)
 Requires-Dist: requests (>=2.27.1)
 Requires-Dist: pytz (>=2022.1)
 Requires-Dist: matplotlib (>=3.5.1)
 
-EduStudio is a Unified and Templatized Frameworkfor Student Assessment Models includingCognitive Diagnosis(CD) and Knowledge Tracing(KT) based on Pytorch.
+EduStudio is a Unified and Templatized Framework for Student Assessment Models including Cognitive Diagnosis(CD) and Knowledge Tracing(KT) based on Pytorch.
```

