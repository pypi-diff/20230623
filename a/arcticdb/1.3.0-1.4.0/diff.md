# Comparing `tmp/arcticdb-1.3.0-cp39-cp39-win_amd64.whl.zip` & `tmp/arcticdb-1.4.0-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,73 +1,73 @@
-Zip file size: 6197531 bytes, number of entries: 71
--rw-rw-rw-  2.0 fat 22063616 b- defN 23-Jun-09 17:26 arcticdb_ext.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat       66 b- defN 23-Jun-09 17:05 arcticc/__init__.py
--rw-rw-rw-  2.0 fat      583 b- defN 23-Jun-09 17:05 arcticc/pb2/__init__.py
--rw-rw-rw-  2.0 fat      424 b- defN 23-Jun-09 17:05 arcticdb/__init__.py
--rw-rw-rw-  2.0 fat      447 b- defN 23-Jun-09 17:05 arcticdb/_msgpack_compat.py
--rw-rw-rw-  2.0 fat    10784 b- defN 23-Jun-09 17:05 arcticdb/arctic.py
--rw-rw-rw-  2.0 fat     7524 b- defN 23-Jun-09 17:05 arcticdb/config.py
--rw-rw-rw-  2.0 fat      765 b- defN 23-Jun-09 17:05 arcticdb/exceptions.py
--rw-rw-rw-  2.0 fat     9361 b- defN 23-Jun-09 17:05 arcticdb/flattener.py
--rw-rw-rw-  2.0 fat     1809 b- defN 23-Jun-09 17:05 arcticdb/log.py
--rw-rw-rw-  2.0 fat     6476 b- defN 23-Jun-09 17:05 arcticdb/options.py
--rw-rw-rw-  2.0 fat      519 b- defN 23-Jun-09 17:05 arcticdb/preconditions.py
--rw-rw-rw-  2.0 fat     1612 b- defN 23-Jun-09 17:05 arcticdb/supported_types.py
--rw-rw-rw-  2.0 fat     3142 b- defN 23-Jun-09 17:05 arcticdb/tools.py
--rw-rw-rw-  2.0 fat      138 b- defN 23-Jun-09 17:05 arcticdb/adapters/__init__.py
--rw-rw-rw-  2.0 fat     2211 b- defN 23-Jun-09 17:05 arcticdb/adapters/arctic_library_adapter.py
--rw-rw-rw-  2.0 fat     2394 b- defN 23-Jun-09 17:05 arcticdb/adapters/lmdb_library_adapter.py
--rw-rw-rw-  2.0 fat     6433 b- defN 23-Jun-09 17:05 arcticdb/adapters/s3_library_adapter.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-09 17:05 arcticdb/authorization/__init__.py
--rw-rw-rw-  2.0 fat      969 b- defN 23-Jun-09 17:05 arcticdb/authorization/permissions.py
--rw-rw-rw-  2.0 fat     8935 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/config_pb2.py
--rw-rw-rw-  2.0 fat    96954 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/descriptors_pb2.py
--rw-rw-rw-  2.0 fat    28646 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/encoding_pb2.py
--rw-rw-rw-  2.0 fat    13225 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/generation_pb2.py
--rw-rw-rw-  2.0 fat     1990 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/in_memory_storage_pb2.py
--rw-rw-rw-  2.0 fat     4634 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/lmdb_storage_pb2.py
--rw-rw-rw-  2.0 fat    24224 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/logger_pb2.py
--rw-rw-rw-  2.0 fat     2931 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/mongo_storage_pb2.py
--rw-rw-rw-  2.0 fat     6878 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/nfs_backed_storage_pb2.py
--rw-rw-rw-  2.0 fat     3821 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/processors_pb2.py
--rw-rw-rw-  2.0 fat    49227 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/request_pb2.py
--rw-rw-rw-  2.0 fat     6729 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/s3_storage_pb2.py
--rw-rw-rw-  2.0 fat    67292 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/storage_pb2.py
--rw-rw-rw-  2.0 fat    12621 b- defN 23-Jun-09 17:17 arcticdb/proto/3/arcticc/pb2/utils_pb2.py
--rw-rw-rw-  2.0 fat     2298 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/config_pb2.py
--rw-rw-rw-  2.0 fat    14870 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py
--rw-rw-rw-  2.0 fat     4895 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/encoding_pb2.py
--rw-rw-rw-  2.0 fat     2998 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/generation_pb2.py
--rw-rw-rw-  2.0 fat     1038 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py
--rw-rw-rw-  2.0 fat     1367 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py
--rw-rw-rw-  2.0 fat     4114 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/logger_pb2.py
--rw-rw-rw-  2.0 fat     1195 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py
--rw-rw-rw-  2.0 fat     1517 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py
--rw-rw-rw-  2.0 fat     1259 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/processors_pb2.py
--rw-rw-rw-  2.0 fat     6801 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/request_pb2.py
--rw-rw-rw-  2.0 fat     1496 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py
--rw-rw-rw-  2.0 fat     9907 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/storage_pb2.py
--rw-rw-rw-  2.0 fat     2310 b- defN 23-Jun-09 17:17 arcticdb/proto/4/arcticc/pb2/utils_pb2.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-09 17:05 arcticdb/toolbox/__init__.py
--rw-rw-rw-  2.0 fat     6102 b- defN 23-Jun-09 17:05 arcticdb/toolbox/library_tool.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-09 17:05 arcticdb/util/__init__.py
--rw-rw-rw-  2.0 fat     2705 b- defN 23-Jun-09 17:05 arcticdb/util/errors.py
--rw-rw-rw-  2.0 fat     8775 b- defN 23-Jun-09 17:05 arcticdb/util/hypothesis.py
--rw-rw-rw-  2.0 fat      719 b- defN 23-Jun-09 17:05 arcticdb/util/memory.py
--rw-rw-rw-  2.0 fat     6013 b- defN 23-Jun-09 17:05 arcticdb/util/tasks.py
--rw-rw-rw-  2.0 fat    18251 b- defN 23-Jun-09 17:05 arcticdb/util/test.py
--rw-rw-rw-  2.0 fat      131 b- defN 23-Jun-09 17:05 arcticdb/version_store/__init__.py
--rw-rw-rw-  2.0 fat     7189 b- defN 23-Jun-09 17:05 arcticdb/version_store/_common.py
--rw-rw-rw-  2.0 fat     4193 b- defN 23-Jun-09 17:05 arcticdb/version_store/_custom_normalizers.py
--rw-rw-rw-  2.0 fat    52659 b- defN 23-Jun-09 17:05 arcticdb/version_store/_normalization.py
--rw-rw-rw-  2.0 fat   113749 b- defN 23-Jun-09 17:05 arcticdb/version_store/_store.py
--rw-rw-rw-  2.0 fat    11040 b- defN 23-Jun-09 17:05 arcticdb/version_store/helper.py
--rw-rw-rw-  2.0 fat    59441 b- defN 23-Jun-09 17:05 arcticdb/version_store/library.py
--rw-rw-rw-  2.0 fat    24581 b- defN 23-Jun-09 17:05 arcticdb/version_store/processing.py
--rw-rw-rw-  2.0 fat      603 b- defN 23-Jun-09 17:05 arcticdb/version_store/read_result.py
--rw-rw-rw-  2.0 fat     4851 b- defN 23-Jun-09 17:26 arcticdb-1.3.0.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     8449 b- defN 23-Jun-09 17:26 arcticdb-1.3.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat    18186 b- defN 23-Jun-09 17:26 arcticdb-1.3.0.dist-info/NOTICE.txt
--rw-rw-rw-  2.0 fat      100 b- defN 23-Jun-09 17:26 arcticdb-1.3.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       30 b- defN 23-Jun-09 17:26 arcticdb-1.3.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     6529 b- defN 23-Jun-09 17:26 arcticdb-1.3.0.dist-info/RECORD
-71 files, 22857741 bytes uncompressed, 6187035 bytes compressed:  72.9%
+Zip file size: 6204545 bytes, number of entries: 71
+-rw-rw-rw-  2.0 fat 22064128 b- defN 23-Jun-23 11:08 arcticdb_ext.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat       66 b- defN 23-Jun-23 10:35 arcticc/__init__.py
+-rw-rw-rw-  2.0 fat      583 b- defN 23-Jun-23 10:35 arcticc/pb2/__init__.py
+-rw-rw-rw-  2.0 fat      424 b- defN 23-Jun-23 10:35 arcticdb/__init__.py
+-rw-rw-rw-  2.0 fat      447 b- defN 23-Jun-23 10:35 arcticdb/_msgpack_compat.py
+-rw-rw-rw-  2.0 fat    11446 b- defN 23-Jun-23 10:35 arcticdb/arctic.py
+-rw-rw-rw-  2.0 fat     7524 b- defN 23-Jun-23 10:35 arcticdb/config.py
+-rw-rw-rw-  2.0 fat      765 b- defN 23-Jun-23 10:35 arcticdb/exceptions.py
+-rw-rw-rw-  2.0 fat     9361 b- defN 23-Jun-23 10:35 arcticdb/flattener.py
+-rw-rw-rw-  2.0 fat     1810 b- defN 23-Jun-23 10:35 arcticdb/log.py
+-rw-rw-rw-  2.0 fat     6476 b- defN 23-Jun-23 10:35 arcticdb/options.py
+-rw-rw-rw-  2.0 fat      519 b- defN 23-Jun-23 10:35 arcticdb/preconditions.py
+-rw-rw-rw-  2.0 fat     1612 b- defN 23-Jun-23 10:35 arcticdb/supported_types.py
+-rw-rw-rw-  2.0 fat     3150 b- defN 23-Jun-23 10:35 arcticdb/tools.py
+-rw-rw-rw-  2.0 fat      138 b- defN 23-Jun-23 10:35 arcticdb/adapters/__init__.py
+-rw-rw-rw-  2.0 fat     2349 b- defN 23-Jun-23 10:35 arcticdb/adapters/arctic_library_adapter.py
+-rw-rw-rw-  2.0 fat     2534 b- defN 23-Jun-23 10:35 arcticdb/adapters/lmdb_library_adapter.py
+-rw-rw-rw-  2.0 fat     7550 b- defN 23-Jun-23 10:35 arcticdb/adapters/s3_library_adapter.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-23 10:35 arcticdb/authorization/__init__.py
+-rw-rw-rw-  2.0 fat      969 b- defN 23-Jun-23 10:35 arcticdb/authorization/permissions.py
+-rw-rw-rw-  2.0 fat     8935 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/config_pb2.py
+-rw-rw-rw-  2.0 fat    96954 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/descriptors_pb2.py
+-rw-rw-rw-  2.0 fat    28646 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/encoding_pb2.py
+-rw-rw-rw-  2.0 fat    13225 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/generation_pb2.py
+-rw-rw-rw-  2.0 fat     1990 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/in_memory_storage_pb2.py
+-rw-rw-rw-  2.0 fat     4634 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/lmdb_storage_pb2.py
+-rw-rw-rw-  2.0 fat    24224 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/logger_pb2.py
+-rw-rw-rw-  2.0 fat     2931 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/mongo_storage_pb2.py
+-rw-rw-rw-  2.0 fat     6878 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/nfs_backed_storage_pb2.py
+-rw-rw-rw-  2.0 fat     3821 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/processors_pb2.py
+-rw-rw-rw-  2.0 fat    49227 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/request_pb2.py
+-rw-rw-rw-  2.0 fat     6729 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/s3_storage_pb2.py
+-rw-rw-rw-  2.0 fat    67292 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/storage_pb2.py
+-rw-rw-rw-  2.0 fat    12621 b- defN 23-Jun-23 10:45 arcticdb/proto/3/arcticc/pb2/utils_pb2.py
+-rw-rw-rw-  2.0 fat     2413 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/config_pb2.py
+-rw-rw-rw-  2.0 fat    15753 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py
+-rw-rw-rw-  2.0 fat     5202 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/encoding_pb2.py
+-rw-rw-rw-  2.0 fat     3113 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/generation_pb2.py
+-rw-rw-rw-  2.0 fat     1081 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py
+-rw-rw-rw-  2.0 fat     1434 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py
+-rw-rw-rw-  2.0 fat     4397 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/logger_pb2.py
+-rw-rw-rw-  2.0 fat     1262 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py
+-rw-rw-rw-  2.0 fat     1560 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py
+-rw-rw-rw-  2.0 fat     1326 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/processors_pb2.py
+-rw-rw-rw-  2.0 fat     7300 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/request_pb2.py
+-rw-rw-rw-  2.0 fat     1539 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py
+-rw-rw-rw-  2.0 fat    10526 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/storage_pb2.py
+-rw-rw-rw-  2.0 fat     2449 b- defN 23-Jun-23 10:45 arcticdb/proto/4/arcticc/pb2/utils_pb2.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-23 10:35 arcticdb/toolbox/__init__.py
+-rw-rw-rw-  2.0 fat     6102 b- defN 23-Jun-23 10:35 arcticdb/toolbox/library_tool.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-23 10:35 arcticdb/util/__init__.py
+-rw-rw-rw-  2.0 fat     2705 b- defN 23-Jun-23 10:35 arcticdb/util/errors.py
+-rw-rw-rw-  2.0 fat     8775 b- defN 23-Jun-23 10:35 arcticdb/util/hypothesis.py
+-rw-rw-rw-  2.0 fat      719 b- defN 23-Jun-23 10:35 arcticdb/util/memory.py
+-rw-rw-rw-  2.0 fat     6013 b- defN 23-Jun-23 10:35 arcticdb/util/tasks.py
+-rw-rw-rw-  2.0 fat    18249 b- defN 23-Jun-23 10:35 arcticdb/util/test.py
+-rw-rw-rw-  2.0 fat      131 b- defN 23-Jun-23 10:35 arcticdb/version_store/__init__.py
+-rw-rw-rw-  2.0 fat     7189 b- defN 23-Jun-23 10:35 arcticdb/version_store/_common.py
+-rw-rw-rw-  2.0 fat     4193 b- defN 23-Jun-23 10:35 arcticdb/version_store/_custom_normalizers.py
+-rw-rw-rw-  2.0 fat    52659 b- defN 23-Jun-23 10:35 arcticdb/version_store/_normalization.py
+-rw-rw-rw-  2.0 fat   113724 b- defN 23-Jun-23 10:35 arcticdb/version_store/_store.py
+-rw-rw-rw-  2.0 fat    11129 b- defN 23-Jun-23 10:35 arcticdb/version_store/helper.py
+-rw-rw-rw-  2.0 fat    59545 b- defN 23-Jun-23 10:35 arcticdb/version_store/library.py
+-rw-rw-rw-  2.0 fat    24370 b- defN 23-Jun-23 10:35 arcticdb/version_store/processing.py
+-rw-rw-rw-  2.0 fat      603 b- defN 23-Jun-23 10:35 arcticdb/version_store/read_result.py
+-rw-rw-rw-  2.0 fat     4851 b- defN 23-Jun-23 11:08 arcticdb-1.4.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     8557 b- defN 23-Jun-23 11:08 arcticdb-1.4.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat    18186 b- defN 23-Jun-23 11:08 arcticdb-1.4.0.dist-info/NOTICE.txt
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Jun-23 11:08 arcticdb-1.4.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       30 b- defN 23-Jun-23 11:08 arcticdb-1.4.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     6530 b- defN 23-Jun-23 11:08 arcticdb-1.4.0.dist-info/RECORD
+71 files, 22863673 bytes uncompressed, 6194049 bytes compressed:  72.9%
```

## zipnote {}

```diff
@@ -189,26 +189,26 @@
 
 Filename: arcticdb/version_store/processing.py
 Comment: 
 
 Filename: arcticdb/version_store/read_result.py
 Comment: 
 
-Filename: arcticdb-1.3.0.dist-info/LICENSE.txt
+Filename: arcticdb-1.4.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: arcticdb-1.3.0.dist-info/METADATA
+Filename: arcticdb-1.4.0.dist-info/METADATA
 Comment: 
 
-Filename: arcticdb-1.3.0.dist-info/NOTICE.txt
+Filename: arcticdb-1.4.0.dist-info/NOTICE.txt
 Comment: 
 
-Filename: arcticdb-1.3.0.dist-info/WHEEL
+Filename: arcticdb-1.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: arcticdb-1.3.0.dist-info/top_level.txt
+Filename: arcticdb-1.4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: arcticdb-1.3.0.dist-info/RECORD
+Filename: arcticdb-1.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## arcticdb/__init__.py

```diff
@@ -7,8 +7,8 @@
 from arcticdb.version_store.processing import QueryBuilder
 import arcticdb.version_store.library as library
 from arcticdb.options import LibraryOptions
 from arcticdb.tools import set_config_from_env_vars
 
 set_config_from_env_vars(_os.environ)
 
-__version__ = "1.3.0"
+__version__ = "1.4.0"
```

## arcticdb/arctic.py

```diff
@@ -4,15 +4,15 @@
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
 from typing import List, Optional
 
 from arcticdb.options import LibraryOptions
-from arcticdb_ext.storage import LibraryManager
+from arcticdb_ext.storage import LibraryManager, StorageOverride
 from arcticdb.version_store.library import Library
 from arcticdb.version_store._store import NativeVersionStore
 from arcticdb.adapters.s3_library_adapter import S3LibraryAdapter
 from arcticdb.adapters.lmdb_library_adapter import LMDBLibraryAdapter
 
 
 class Arctic:
@@ -38,15 +38,15 @@
             The S3 URI connection scheme has the form ``s3(s)://<s3 end point>:<s3 bucket>[?options]``.
 
             Use s3s as the protocol if communicating with a secure endpoint.
 
             Options is a query string that specifies connection specific options as ``<name>=<value>`` pairs joined with
             ``&``.
 
-            Available options:
+            Available options for S3:
 
             +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
             | Option                    | Description                                                                                                                                                   |
             +===========================+===============================================================================================================================================================+
             | port                      | port to use for S3 connection                                                                                                                                 |
             +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
             | region                    | S3 region                                                                                                                                                     |
@@ -57,19 +57,22 @@
             +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
             | secret                    | S3 secret access key                                                                                                                                          |
             +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
             | path_prefix               | Path within S3 bucket to use for data storage                                                                                                                 |
             +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
             | aws_auth                  | If true, authentication to endpoint will be computed via AWS environment vars/config files. If no options are provided `aws_auth` will be assumed to be true. |
             +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
+            | force_uri_lib_config      | Override the credentials and endpoint of an S3 storage with the URI of the Arctic object. Use if accessing a replicated (to different region/bucket) library. |
+            +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
 
             Note: When connecting to AWS, `region` can be automatically deduced from the endpoint if the given endpoint
             specifies the region and `region` is not set.
 
-            The LMDB URI connection scheme has the form ``lmdb:///<path to store LMDB files>``.
+            The LMDB URI connection scheme has the form ``lmdb:///<path to store LMDB files>``. There are no options
+            available for the LMDB URI connection scheme.
 
         Examples
         --------
 
         >>> ac = Arctic('s3://MY_ENDPOINT:MY_BUCKET')  # Leave AWS to derive credential information
         >>> ac = Arctic('s3://MY_ENDPOINT:MY_BUCKET?region=YOUR_REGION&access=ABCD&secret=DCBA') # Manually specify creds
         >>> ac.create_library('travel_data')
@@ -89,18 +92,19 @@
             )
 
         self._library_adapter = _cls(uri)
         self._library_manager = LibraryManager(self._library_adapter.config_library)
         self._uri = uri
 
     def __getitem__(self, name: str) -> Library:
+        storage_override = self._library_adapter.get_storage_override()
         lib = NativeVersionStore(
-            self._library_manager.get_library(name),
+            self._library_manager.get_library(name, storage_override),
             repr(self._library_adapter),
-            lib_cfg=self._library_manager.get_library_config(name),
+            lib_cfg=self._library_manager.get_library_config(name, storage_override),
         )
         return Library(repr(self), lib)
 
     def __repr__(self):
         return "Arctic(config=%r)" % self._library_adapter
 
     def get_library(self, library: str) -> Library:
@@ -169,15 +173,17 @@
         Parameters
         ----------
         name: `str`
             Name of the library to delete.
         """
         if not self._library_manager.has_library(name):
             return
-        self._library_adapter.delete_library(self[name], self._library_manager.get_library_config(name))
+        self._library_adapter.delete_library(
+            self[name], self._library_manager.get_library_config(name, StorageOverride())
+        )
         self._library_manager.remove_library_config(name)
 
     def list_libraries(self) -> List[str]:
         """
         Lists all libraries available.
 
         Examples
```

## arcticdb/log.py

```diff
@@ -35,21 +35,21 @@
         self.log(_Lvl.ERROR, msg, *args, **kwargs)
 
     def exception(self, msg, *args, **kwargs):
         exc = traceback.format_exc()
         _log(self._id, _Lvl.ERROR, msg.format(*args, **kwargs) + "\n" + exc)
 
 
-codec = _Logger(_LoggerId.CODEC)
-inmem = _Logger(_LoggerId.IN_MEM)
-root = _Logger(_LoggerId.ROOT)
-storage = _Logger(_LoggerId.STORAGE)
-version = _Logger(_LoggerId.VERSION)
-memory = _Logger(_LoggerId.MEMORY)
-timings = _Logger(_LoggerId.TIMINGS)
-lock = _Logger(_LoggerId.LOCK)
-schedule = _Logger(_LoggerId.SCHEDULE)
+logger_by_name = {
+    "codec": _Logger(_LoggerId.CODEC),
+    "inmem": _Logger(_LoggerId.IN_MEM),
+    "root": _Logger(_LoggerId.ROOT),
+    "storage": _Logger(_LoggerId.STORAGE),
+    "version": _Logger(_LoggerId.VERSION),
+    "memory": _Logger(_LoggerId.MEMORY),
+    "timings": _Logger(_LoggerId.TIMINGS),
+    "lock": _Logger(_LoggerId.LOCK),
+    "schedule": _Logger(_LoggerId.SCHEDULE),
+}
 
-
-logger_by_name = dict(
-    codec=codec, inmem=inmem, root=root, storage=storage, version=version, memory=memory, timings=timings, lock=lock
-)
+for key, value in logger_by_name.items():
+    globals()[key] = value
```

## arcticdb/tools.py

```diff
@@ -53,15 +53,15 @@
                     set_config_int(config_name, int(v))
                 elif var_type == _TYPE_FLOAT:
                     set_config_double(config_name, float(v))
                 elif var_type == _TYPE_LOGLEVEL:
                     if config_name.upper() == "ALL":
                         default_log_level = v.upper()
                     else:
-                        log_level_changes[config_name] = v.upper()
+                        log_level_changes[config_name.lower()] = v.upper()
                 else:
                     logging.error("Invalid type for env var %s (value %s), type used %s", k, v, var_type)
             except Exception as e:
                 logging.error(
                     f"Error setting env var {k} to value {v} using type {var_type} and config name {config_name}"
                     f" Exception: {e}"
                 )
```

## arcticdb/adapters/arctic_library_adapter.py

```diff
@@ -3,16 +3,17 @@
 
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
 from arcticdb.options import LibraryOptions
 from arcticc.pb2.storage_pb2 import LibraryConfig
-from arcticdb_ext.storage import Library
+from arcticdb_ext.storage import Library, StorageOverride
 from abc import ABC, abstractmethod
+from typing import Optional
 
 
 def set_library_options(lib_desc: "LibraryConfig", options: LibraryOptions):
     write_options = lib_desc.version.write_options
 
     write_options.dynamic_strings = True
     write_options.recursive_normalizers = True
@@ -58,7 +59,10 @@
 
     @abstractmethod
     def initialize_library(self, name: str, config: LibraryConfig):
         raise NotImplementedError
 
     def delete_library(self, library: Library, library_config: LibraryConfig):
         return library._nvs.version_store.clear()
+
+    def get_storage_override(self) -> StorageOverride:
+        return StorageOverride()
```

## arcticdb/adapters/lmdb_library_adapter.py

```diff
@@ -4,21 +4,23 @@
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
 import re
 import os
 
+from typing import Optional
+
 from arcticdb.options import LibraryOptions
 from arcticc.pb2.storage_pb2 import EnvironmentConfigsMap, LibraryConfig
 from arcticdb.version_store.helper import add_lmdb_library_to_env
 from arcticdb.config import _DEFAULT_ENV
 from arcticdb.version_store._store import NativeVersionStore
 from arcticdb.adapters.arctic_library_adapter import ArcticLibraryAdapter, set_library_options
-from arcticdb_ext.storage import Library
+from arcticdb_ext.storage import Library, StorageOverride
 
 
 class LMDBLibraryAdapter(ArcticLibraryAdapter):
     """
     Use local LMDB library for storage.
 
     Supports any URI that begins with `lmdb://` - for example, `lmdb:///tmp/lmdb_db`.
@@ -48,14 +50,17 @@
 
         add_lmdb_library_to_env(env_cfg, lib_name=self.CONFIG_LIBRARY_NAME, env_name=_DEFAULT_ENV, db_dir=self._path)
 
         lib = NativeVersionStore.create_store_from_config(env_cfg, _DEFAULT_ENV, self.CONFIG_LIBRARY_NAME)._library
 
         return lib
 
+    def get_storage_override(self) -> StorageOverride:
+        return StorageOverride()
+
     def create_library_config(self, name, library_options: LibraryOptions) -> LibraryConfig:
         env_cfg = EnvironmentConfigsMap()
 
         add_lmdb_library_to_env(env_cfg, lib_name=name, env_name=_DEFAULT_ENV, db_dir=self._path)
 
         set_library_options(env_cfg.env_by_id[_DEFAULT_ENV].lib_by_path[name], library_options)
```

## arcticdb/adapters/s3_library_adapter.py

```diff
@@ -11,15 +11,15 @@
 
 from arcticdb.options import LibraryOptions
 from arcticc.pb2.storage_pb2 import EnvironmentConfigsMap, LibraryConfig
 from arcticdb.version_store.helper import add_s3_library_to_env
 from arcticdb.config import _DEFAULT_ENV
 from arcticdb.version_store._store import NativeVersionStore
 from arcticdb.adapters.arctic_library_adapter import ArcticLibraryAdapter, set_library_options
-from arcticdb_ext.storage import Library
+from arcticdb_ext.storage import Library, StorageOverride, S3CredentialsOverride
 from collections import namedtuple
 from dataclasses import dataclass, fields
 from distutils.util import strtobool
 
 PARSED_QUERY = namedtuple("PARSED_QUERY", ["region"])
 USE_AWS_CRED_PROVIDERS_TOKEN = "_RBAC_"
 
@@ -33,14 +33,16 @@
 
     access: Optional[str] = None
     secret: Optional[str] = None
     aws_auth: Optional[bool] = False
 
     path_prefix: Optional[str] = None
 
+    force_uri_lib_config: Optional[bool] = False
+
 
 class S3LibraryAdapter(ArcticLibraryAdapter):
     REGEX = r"s3(s)?://(?P<endpoint>.*):(?P<bucket>[-_a-zA-Z0-9.]+)(?P<query>\?.*)?"
 
     @staticmethod
     def supports_uri(uri: str) -> bool:
         return uri.startswith("s3://") or uri.startswith("s3s://")
@@ -112,20 +114,42 @@
                     "Value query parameters: "
                     f"{list(field_dict.keys())}"
                 )
 
             if field_dict[key].type == bool:
                 parsed_query[key] = bool(strtobool(parsed_query[key][0]))
 
+            if field_dict[key].type == Optional[bool] and field_dict[key] is not None:
+                parsed_query[key] = bool(strtobool(parsed_query[key][0]))
+
         if parsed_query.get("path_prefix"):
             parsed_query["path_prefix"] = parsed_query["path_prefix"].strip("/")
 
         _kwargs = {k: v for k, v in parsed_query.items()}
         return ParsedQuery(**_kwargs)
 
+    def get_storage_override(self) -> StorageOverride:
+        storage_override = StorageOverride()
+        if self._query_params.force_uri_lib_config:
+            s3_override = S3CredentialsOverride()
+            if self._query_params.access:
+                s3_override.credential_name = self._query_params.access
+            if self._query_params.secret:
+                s3_override.credential_key = self._query_params.secret
+            if self._query_params.region:
+                s3_override.region = self._query_params.region
+            if self._endpoint:
+                s3_override.endpoint = self._endpoint
+            if self._bucket:
+                s3_override.bucket_name = self._bucket
+            storage_override = StorageOverride()
+            storage_override.set_override(s3_override)
+
+        return storage_override
+
     def create_library_config(self, name, library_options: LibraryOptions) -> LibraryConfig:
         env_cfg = EnvironmentConfigsMap()
 
         _name = self._query_params.access if not self._query_params.aws_auth else USE_AWS_CRED_PROVIDERS_TOKEN
         _key = self._query_params.secret if not self._query_params.aws_auth else USE_AWS_CRED_PROVIDERS_TOKEN
 
         if self._query_params.path_prefix:
```

## arcticdb/proto/4/arcticc/pb2/config_pb2.py

```diff
@@ -1,37 +1,38 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/config.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x18\x61rcticc/pb2/config.proto\x12\x16\x61rcticc.pb2.config_pb2\"\x95\x03\n\rRuntimeConfig\x12N\n\rstring_values\x18\x01 \x03(\x0b\x32\x37.arcticc.pb2.config_pb2.RuntimeConfig.StringValuesEntry\x12H\n\nint_values\x18\x02 \x03(\x0b\x32\x34.arcticc.pb2.config_pb2.RuntimeConfig.IntValuesEntry\x12N\n\rdouble_values\x18\x03 \x03(\x0b\x32\x37.arcticc.pb2.config_pb2.RuntimeConfig.DoubleValuesEntry\x1a\x33\n\x11StringValuesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x30\n\x0eIntValuesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x03:\x02\x38\x01\x1a\x33\n\x11\x44oubleValuesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x01:\x02\x38\x01\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.config_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.config_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _RUNTIMECONFIG_STRINGVALUESENTRY._options = None
   _RUNTIMECONFIG_STRINGVALUESENTRY._serialized_options = b'8\001'
   _RUNTIMECONFIG_INTVALUESENTRY._options = None
   _RUNTIMECONFIG_INTVALUESENTRY._serialized_options = b'8\001'
   _RUNTIMECONFIG_DOUBLEVALUESENTRY._options = None
   _RUNTIMECONFIG_DOUBLEVALUESENTRY._serialized_options = b'8\001'
-  _RUNTIMECONFIG._serialized_start=53
-  _RUNTIMECONFIG._serialized_end=458
-  _RUNTIMECONFIG_STRINGVALUESENTRY._serialized_start=304
-  _RUNTIMECONFIG_STRINGVALUESENTRY._serialized_end=355
-  _RUNTIMECONFIG_INTVALUESENTRY._serialized_start=357
-  _RUNTIMECONFIG_INTVALUESENTRY._serialized_end=405
-  _RUNTIMECONFIG_DOUBLEVALUESENTRY._serialized_start=407
-  _RUNTIMECONFIG_DOUBLEVALUESENTRY._serialized_end=458
+  _globals['_RUNTIMECONFIG']._serialized_start=53
+  _globals['_RUNTIMECONFIG']._serialized_end=458
+  _globals['_RUNTIMECONFIG_STRINGVALUESENTRY']._serialized_start=304
+  _globals['_RUNTIMECONFIG_STRINGVALUESENTRY']._serialized_end=355
+  _globals['_RUNTIMECONFIG_INTVALUESENTRY']._serialized_start=357
+  _globals['_RUNTIMECONFIG_INTVALUESENTRY']._serialized_end=405
+  _globals['_RUNTIMECONFIG_DOUBLEVALUESENTRY']._serialized_start=407
+  _globals['_RUNTIMECONFIG_DOUBLEVALUESENTRY']._serialized_end=458
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py

```diff
@@ -1,106 +1,107 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/descriptors.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1d\x61rcticc/pb2/descriptors.proto\x12\x1b\x61rcticc.pb2.descriptors_pb2\"\xc7\x03\n\x0eTypeDescriptor\x12I\n\nvalue_type\x18\x01 \x01(\x0e\x32\x35.arcticc.pb2.descriptors_pb2.TypeDescriptor.ValueType\x12G\n\tsize_bits\x18\x02 \x01(\x0e\x32\x34.arcticc.pb2.descriptors_pb2.TypeDescriptor.SizeBits\x12\x11\n\tdimension\x18\x03 \x01(\r\"\xc7\x01\n\tValueType\x12\x16\n\x12UNKNOWN_VALUE_TYPE\x10\x00\x12\x08\n\x04UINT\x10\x01\x12\x07\n\x03INT\x10\x02\x12\t\n\x05\x46LOAT\x10\x03\x12\x08\n\x04\x42OOL\x10\x04\x12\x0e\n\nMICROS_UTC\x10\x05\x12\n\n\x06SYMBOL\x10\x06\x12\x10\n\x0c\x41SCII_STRING\x10\x07\x12\x0f\n\x0bUTF8_STRING\x10\x08\x12\t\n\x05\x42YTES\x10\t\x12\n\n\x06PICKLE\x10\n\x12\x12\n\x0e\x44YNAMIC_STRING\x10\x0b\x12\x10\n\x0c\x44YNAMIC_UTF8\x10\x0c\"D\n\x08SizeBits\x12\x15\n\x11UNKNOWN_SIZE_BITS\x10\x00\x12\x06\n\x02S8\x10\x01\x12\x07\n\x03S16\x10\x02\x12\x07\n\x03S32\x10\x03\x12\x07\n\x03S64\x10\x04\"\xa5\x01\n\x0fIndexDescriptor\x12\x13\n\x0b\x66ield_count\x18\x01 \x01(\r\x12?\n\x04kind\x18\x02 \x01(\x0e\x32\x31.arcticc.pb2.descriptors_pb2.IndexDescriptor.Type\"<\n\x04Type\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0c\n\x08ROWCOUNT\x10R\x12\n\n\x06STRING\x10S\x12\r\n\tTIMESTAMP\x10T\"\xad\x03\n\x10StreamDescriptor\x12\x10\n\x06num_id\x18\x01 \x01(\x04H\x00\x12\x10\n\x06str_id\x18\x02 \x01(\tH\x00\x12;\n\x05index\x18\x03 \x01(\x0b\x32,.arcticc.pb2.descriptors_pb2.IndexDescriptor\x12M\n\x06\x66ields\x18\x04 \x03(\x0b\x32=.arcticc.pb2.descriptors_pb2.StreamDescriptor.FieldDescriptor\x12\x11\n\ttype_hash\x18\x05 \x01(\x04\x12\x10\n\x08timezone\x18\x06 \x01(\t\x12\x38\n\x06sorted\x18\x07 \x01(\x0e\x32(.arcticc.pb2.descriptors_pb2.SortedValue\x12\x10\n\x08in_bytes\x18\x08 \x01(\x04\x12\x11\n\tout_bytes\x18\t \x01(\x04\x1a_\n\x0f\x46ieldDescriptor\x12>\n\ttype_desc\x18\x01 \x01(\x0b\x32+.arcticc.pb2.descriptors_pb2.TypeDescriptor\x12\x0c\n\x04name\x18\x02 \x01(\tB\x04\n\x02id\"\x89\x01\n\x14MsgPackSerialization\"q\n\x07\x45xtType\x12\x0f\n\x0bUNSUPPORTED\x10\x00\x12\x10\n\x0cPD_TIMESTAMP\x10 \x12\x0f\n\x0bPY_DATETIME\x10!\x12\x10\n\x0cPY_TIMEDELTA\x10\"\x12\x0f\n\x0bPY_PICKLE_2\x10\x66\x12\x0f\n\x0bPY_PICKLE_3\x10g\"\xbe\x17\n\x15NormalizationMetadata\x12P\n\x02\x64\x66\x18\x01 \x01(\x0b\x32\x42.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasDataFrameH\x00\x12T\n\x06series\x18\x02 \x01(\x0b\x32\x42.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasDataFrameH\x00\x12U\n\x02ts\x18\x03 \x01(\x0b\x32G.arcticc.pb2.descriptors_pb2.NormalizationMetadata.NormalisedTimeSeriesH\x00\x12Y\n\x0emsg_pack_frame\x18\x04 \x01(\x0b\x32?.arcticc.pb2.descriptors_pb2.NormalizationMetadata.MsgPackFrameH\x00\x12H\n\x02np\x18\x05 \x01(\x0b\x32:.arcticc.pb2.descriptors_pb2.NormalizationMetadata.NdArrayH\x00\x12W\n\x06\x63ustom\x18@ \x01(\x0b\x32G.arcticc.pb2.descriptors_pb2.NormalizationMetadata.CustomNormalizerMeta\x1as\n\x0bPandasIndex\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\n\n\x02tz\x18\x02 \x01(\t\x12\x11\n\tfake_name\x18\x03 \x01(\x08\x12\x1a\n\x12is_not_range_index\x18\x04 \x01(\x08\x12\r\n\x05start\x18\x05 \x01(\x03\x12\x0c\n\x04step\x18\x06 \x01(\x03\x1a\x80\x02\n\x10PandasMultiIndex\x12\x0f\n\x07version\x18\x01 \x01(\r\x12\x63\n\x08timezone\x18\x02 \x03(\x0b\x32Q.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasMultiIndex.TimezoneEntry\x12\x13\n\x0b\x66ield_count\x18\x03 \x01(\r\x12\x0c\n\x04name\x18\x04 \x01(\t\x12\n\n\x02tz\x18\x05 \x01(\t\x12\x16\n\x0e\x66\x61ke_field_pos\x18\x06 \x03(\r\x1a/\n\rTimezoneEntry\x12\x0b\n\x03key\x18\x01 \x01(\r\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\xae\x02\n\x11PandasMultiColumn\x12\x0e\n\x06levels\x18\x01 \x03(\t\x12[\n\x06labels\x18\x02 \x03(\x0b\x32K.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasMultiColumn.Labels\x12\x64\n\x08timezone\x18\x03 \x03(\x0b\x32R.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasMultiColumn.TimezoneEntry\x1a\x15\n\x06Labels\x12\x0b\n\x03val\x18\x01 \x03(\x04\x1a/\n\rTimezoneEntry\x12\x0b\n\x03key\x18\x01 \x01(\r\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\xdb\x08\n\x06Pandas\x12\x0c\n\x04name\x18\x01 \x01(\t\x12O\n\x05index\x18\x02 \x01(\x0b\x32>.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasIndexH\x00\x12Z\n\x0bmulti_index\x18\x03 \x01(\x0b\x32\x43.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasMultiIndexH\x00\x12\x0c\n\x04mark\x18\x04 \x01(\x08\x12]\n\ncategories\x18\x05 \x03(\x0b\x32I.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas.CategoriesEntry\x12\x64\n\x0eint_categories\x18\x06 \x03(\x0b\x32L.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas.IntCategoriesEntry\x12Z\n\tcol_names\x18\x07 \x03(\x0b\x32G.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas.ColNamesEntry\x12O\n\x07\x63olumns\x18\x08 \x01(\x0b\x32>.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasIndex\x1a\x1e\n\nCategories\x12\x10\n\x08\x63\x61tegory\x18\x01 \x03(\t\x1a!\n\rIntCategories\x12\x10\n\x08\x63\x61tegory\x18\x01 \x03(\x04\x1aw\n\x0f\x43\x61tegoriesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12S\n\x05value\x18\x02 \x01(\x0b\x32\x44.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas.Categories:\x02\x38\x01\x1a}\n\x12IntCategoriesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12V\n\x05value\x18\x02 \x01(\x0b\x32G.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas.IntCategories:\x02\x38\x01\x1aV\n\nColumnName\x12\x0f\n\x07is_none\x18\x01 \x01(\x08\x12\x10\n\x08is_empty\x18\x02 \x01(\x08\x12\x15\n\roriginal_name\x18\x03 \x01(\t\x12\x0e\n\x06is_int\x18\x04 \x01(\x08\x1au\n\rColNamesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12S\n\x05value\x18\x02 \x01(\x0b\x32\x44.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas.ColumnName:\x02\x38\x01\x42\x0c\n\nindex_type\x1a\xd8\x01\n\x0fPandasDataFrame\x12I\n\x06\x63ommon\x18\x01 \x01(\x0b\x32\x39.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas\x12[\n\rmulti_columns\x18\x02 \x01(\x0b\x32\x44.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasMultiColumn\x12\x1d\n\x15has_synthetic_columns\x18\x03 \x01(\x08\x1a\xeb\x01\n\x14NormalisedTimeSeries\x12\x0c\n\x04mark\x18\x01 \x01(\x08\x12I\n\x06\x63ommon\x18\x02 \x01(\x0b\x32\x39.arcticc.pb2.descriptors_pb2.NormalizationMetadata.Pandas\x12[\n\rmulti_columns\x18\x03 \x01(\x0b\x32\x44.arcticc.pb2.descriptors_pb2.NormalizationMetadata.PandasMultiColumn\x12\x1d\n\x15has_synthetic_columns\x18\x04 \x01(\x08\x1a\x33\n\x0cMsgPackFrame\x12\x0f\n\x07version\x18\x01 \x01(\r\x12\x12\n\nsize_bytes\x18\x02 \x01(\x04\x1a{\n\x14\x43ustomNormalizerMeta\x12\x12\n\nclass_name\x18\x01 \x01(\t\x12\x0c\n\x04meta\x18\x02 \x01(\x0c\x12\x1a\n\x12py_datetime_marker\x18\x03 \x01(\x08\x12%\n\x1d\x64\x61terange_has_datetime_marker\x18\x04 \x01(\x08\x1a\x18\n\x07NdArray\x12\r\n\x05shape\x18\x01 \x03(\x04\x42\x0c\n\ninput_type\"H\n\x0c\x43olumnGroups\x12\x12\n\ngroup_ends\x18\x01 \x03(\r\x12\x13\n\x0bnum_buckets\x18\x02 \x01(\r\x12\x0f\n\x07\x65nabled\x18\x03 \x01(\x08\"\xc5\x01\n\x13UserDefinedMetadata\x12P\n\x04type\x18\x01 \x01(\x0e\x32\x42.arcticc.pb2.descriptors_pb2.UserDefinedMetadata.SerializationType\x12\x0f\n\x07version\x18\x02 \x01(\r\x12\x18\n\x0einline_payload\x18\x03 \x01(\x0cH\x00\"!\n\x11SerializationType\x12\x0c\n\x08MSG_PACK\x10\x00\x42\x0e\n\x0cstorage_type\"\xab\x02\n\x07\x41tomKey\x12\x13\n\tstring_id\x18\x01 \x01(\tH\x00\x12\x14\n\nnumeric_id\x18\x02 \x01(\x03H\x00\x12\x12\n\nversion_id\x18\x03 \x01(\x04\x12\x13\n\x0b\x63reation_ts\x18\x04 \x01(\x04\x12\x14\n\x0c\x63ontent_hash\x18\x05 \x01(\x04\x12\x16\n\x0cstring_start\x18\x06 \x01(\tH\x01\x12\x17\n\rnumeric_start\x18\x07 \x01(\x03H\x01\x12\x14\n\nstring_end\x18\x08 \x01(\tH\x02\x12\x15\n\x0bnumeric_end\x18\t \x01(\x03H\x02\x12\x36\n\x08key_type\x18\n \x01(\x0e\x32$.arcticc.pb2.descriptors_pb2.KeyTypeB\x04\n\x02idB\r\n\x0bindex_startB\x0b\n\tindex_end\"\xc8\x03\n\x14TimeSeriesDescriptor\x12\x12\n\ntotal_rows\x18\x01 \x01(\x04\x12H\n\x11stream_descriptor\x18\x02 \x01(\x0b\x32-.arcticc.pb2.descriptors_pb2.StreamDescriptor\x12I\n\rnormalization\x18\x03 \x01(\x0b\x32\x32.arcticc.pb2.descriptors_pb2.NormalizationMetadata\x12@\n\rcolumn_groups\x18\x04 \x01(\x0b\x32).arcticc.pb2.descriptors_pb2.ColumnGroups\x12\x43\n\tuser_meta\x18\x05 \x01(\x0b\x32\x30.arcticc.pb2.descriptors_pb2.UserDefinedMetadata\x12\x36\n\x08next_key\x18\x06 \x01(\x0b\x32$.arcticc.pb2.descriptors_pb2.AtomKey\x12H\n\x0emulti_key_meta\x18\x07 \x01(\x0b\x32\x30.arcticc.pb2.descriptors_pb2.UserDefinedMetadata\"\'\n\x14SymbolListDescriptor\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08*G\n\x0bSortedValue\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0c\n\x08UNSORTED\x10\x01\x12\r\n\tASCENDING\x10\x02\x12\x0e\n\nDESCENDING\x10\x03*\xbf\x02\n\x07KeyType\x12\x10\n\x0cSTREAM_GROUP\x10\x00\x12\x0e\n\nGENERATION\x10\x01\x12\x0e\n\nTABLE_DATA\x10\x02\x12\x0f\n\x0bTABLE_INDEX\x10\x03\x12\x0b\n\x07VERSION\x10\x04\x12\x13\n\x0fVERSION_JOURNAL\x10\x05\x12\x0b\n\x07METRICS\x10\x06\x12\x0c\n\x08SNAPSHOT\x10\x07\x12\x0f\n\x0bSYMBOL_LIST\x10\x08\x12\x0f\n\x0bVERSION_REF\x10\t\x12\x10\n\x0cSTORAGE_INFO\x10\n\x12\x0e\n\nAPPEND_REF\x10\x0b\x12\r\n\tMULTI_KEY\x10\x0c\x12\x08\n\x04LOCK\x10\r\x12\x10\n\x0cSNAPSHOT_REF\x10\x0e\x12\r\n\tTOMBSTONE\x10\x0f\x12\x0f\n\x0b\x41PPEND_DATA\x10\x10\x12\x07\n\x03LOG\x10\x11\x12\r\n\tPARTITION\x10\x12\x12\r\n\tUNDEFINED\x10\x13\x42\x03\xf8\x01\x01\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.descriptors_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.descriptors_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   DESCRIPTOR._serialized_options = b'\370\001\001'
   _NORMALIZATIONMETADATA_PANDASMULTIINDEX_TIMEZONEENTRY._options = None
   _NORMALIZATIONMETADATA_PANDASMULTIINDEX_TIMEZONEENTRY._serialized_options = b'8\001'
   _NORMALIZATIONMETADATA_PANDASMULTICOLUMN_TIMEZONEENTRY._options = None
   _NORMALIZATIONMETADATA_PANDASMULTICOLUMN_TIMEZONEENTRY._serialized_options = b'8\001'
   _NORMALIZATIONMETADATA_PANDAS_CATEGORIESENTRY._options = None
   _NORMALIZATIONMETADATA_PANDAS_CATEGORIESENTRY._serialized_options = b'8\001'
   _NORMALIZATIONMETADATA_PANDAS_INTCATEGORIESENTRY._options = None
   _NORMALIZATIONMETADATA_PANDAS_INTCATEGORIESENTRY._serialized_options = b'8\001'
   _NORMALIZATIONMETADATA_PANDAS_COLNAMESENTRY._options = None
   _NORMALIZATIONMETADATA_PANDAS_COLNAMESENTRY._serialized_options = b'8\001'
-  _SORTEDVALUE._serialized_start=5345
-  _SORTEDVALUE._serialized_end=5416
-  _KEYTYPE._serialized_start=5419
-  _KEYTYPE._serialized_end=5738
-  _TYPEDESCRIPTOR._serialized_start=63
-  _TYPEDESCRIPTOR._serialized_end=518
-  _TYPEDESCRIPTOR_VALUETYPE._serialized_start=249
-  _TYPEDESCRIPTOR_VALUETYPE._serialized_end=448
-  _TYPEDESCRIPTOR_SIZEBITS._serialized_start=450
-  _TYPEDESCRIPTOR_SIZEBITS._serialized_end=518
-  _INDEXDESCRIPTOR._serialized_start=521
-  _INDEXDESCRIPTOR._serialized_end=686
-  _INDEXDESCRIPTOR_TYPE._serialized_start=626
-  _INDEXDESCRIPTOR_TYPE._serialized_end=686
-  _STREAMDESCRIPTOR._serialized_start=689
-  _STREAMDESCRIPTOR._serialized_end=1118
-  _STREAMDESCRIPTOR_FIELDDESCRIPTOR._serialized_start=1017
-  _STREAMDESCRIPTOR_FIELDDESCRIPTOR._serialized_end=1112
-  _MSGPACKSERIALIZATION._serialized_start=1121
-  _MSGPACKSERIALIZATION._serialized_end=1258
-  _MSGPACKSERIALIZATION_EXTTYPE._serialized_start=1145
-  _MSGPACKSERIALIZATION_EXTTYPE._serialized_end=1258
-  _NORMALIZATIONMETADATA._serialized_start=1261
-  _NORMALIZATIONMETADATA._serialized_end=4267
-  _NORMALIZATIONMETADATA_PANDASINDEX._serialized_start=1795
-  _NORMALIZATIONMETADATA_PANDASINDEX._serialized_end=1910
-  _NORMALIZATIONMETADATA_PANDASMULTIINDEX._serialized_start=1913
-  _NORMALIZATIONMETADATA_PANDASMULTIINDEX._serialized_end=2169
-  _NORMALIZATIONMETADATA_PANDASMULTIINDEX_TIMEZONEENTRY._serialized_start=2122
-  _NORMALIZATIONMETADATA_PANDASMULTIINDEX_TIMEZONEENTRY._serialized_end=2169
-  _NORMALIZATIONMETADATA_PANDASMULTICOLUMN._serialized_start=2172
-  _NORMALIZATIONMETADATA_PANDASMULTICOLUMN._serialized_end=2474
-  _NORMALIZATIONMETADATA_PANDASMULTICOLUMN_LABELS._serialized_start=2404
-  _NORMALIZATIONMETADATA_PANDASMULTICOLUMN_LABELS._serialized_end=2425
-  _NORMALIZATIONMETADATA_PANDASMULTICOLUMN_TIMEZONEENTRY._serialized_start=2122
-  _NORMALIZATIONMETADATA_PANDASMULTICOLUMN_TIMEZONEENTRY._serialized_end=2169
-  _NORMALIZATIONMETADATA_PANDAS._serialized_start=2477
-  _NORMALIZATIONMETADATA_PANDAS._serialized_end=3592
-  _NORMALIZATIONMETADATA_PANDAS_CATEGORIES._serialized_start=3058
-  _NORMALIZATIONMETADATA_PANDAS_CATEGORIES._serialized_end=3088
-  _NORMALIZATIONMETADATA_PANDAS_INTCATEGORIES._serialized_start=3090
-  _NORMALIZATIONMETADATA_PANDAS_INTCATEGORIES._serialized_end=3123
-  _NORMALIZATIONMETADATA_PANDAS_CATEGORIESENTRY._serialized_start=3125
-  _NORMALIZATIONMETADATA_PANDAS_CATEGORIESENTRY._serialized_end=3244
-  _NORMALIZATIONMETADATA_PANDAS_INTCATEGORIESENTRY._serialized_start=3246
-  _NORMALIZATIONMETADATA_PANDAS_INTCATEGORIESENTRY._serialized_end=3371
-  _NORMALIZATIONMETADATA_PANDAS_COLUMNNAME._serialized_start=3373
-  _NORMALIZATIONMETADATA_PANDAS_COLUMNNAME._serialized_end=3459
-  _NORMALIZATIONMETADATA_PANDAS_COLNAMESENTRY._serialized_start=3461
-  _NORMALIZATIONMETADATA_PANDAS_COLNAMESENTRY._serialized_end=3578
-  _NORMALIZATIONMETADATA_PANDASDATAFRAME._serialized_start=3595
-  _NORMALIZATIONMETADATA_PANDASDATAFRAME._serialized_end=3811
-  _NORMALIZATIONMETADATA_NORMALISEDTIMESERIES._serialized_start=3814
-  _NORMALIZATIONMETADATA_NORMALISEDTIMESERIES._serialized_end=4049
-  _NORMALIZATIONMETADATA_MSGPACKFRAME._serialized_start=4051
-  _NORMALIZATIONMETADATA_MSGPACKFRAME._serialized_end=4102
-  _NORMALIZATIONMETADATA_CUSTOMNORMALIZERMETA._serialized_start=4104
-  _NORMALIZATIONMETADATA_CUSTOMNORMALIZERMETA._serialized_end=4227
-  _NORMALIZATIONMETADATA_NDARRAY._serialized_start=4229
-  _NORMALIZATIONMETADATA_NDARRAY._serialized_end=4253
-  _COLUMNGROUPS._serialized_start=4269
-  _COLUMNGROUPS._serialized_end=4341
-  _USERDEFINEDMETADATA._serialized_start=4344
-  _USERDEFINEDMETADATA._serialized_end=4541
-  _USERDEFINEDMETADATA_SERIALIZATIONTYPE._serialized_start=4492
-  _USERDEFINEDMETADATA_SERIALIZATIONTYPE._serialized_end=4525
-  _ATOMKEY._serialized_start=4544
-  _ATOMKEY._serialized_end=4843
-  _TIMESERIESDESCRIPTOR._serialized_start=4846
-  _TIMESERIESDESCRIPTOR._serialized_end=5302
-  _SYMBOLLISTDESCRIPTOR._serialized_start=5304
-  _SYMBOLLISTDESCRIPTOR._serialized_end=5343
+  _globals['_SORTEDVALUE']._serialized_start=5345
+  _globals['_SORTEDVALUE']._serialized_end=5416
+  _globals['_KEYTYPE']._serialized_start=5419
+  _globals['_KEYTYPE']._serialized_end=5738
+  _globals['_TYPEDESCRIPTOR']._serialized_start=63
+  _globals['_TYPEDESCRIPTOR']._serialized_end=518
+  _globals['_TYPEDESCRIPTOR_VALUETYPE']._serialized_start=249
+  _globals['_TYPEDESCRIPTOR_VALUETYPE']._serialized_end=448
+  _globals['_TYPEDESCRIPTOR_SIZEBITS']._serialized_start=450
+  _globals['_TYPEDESCRIPTOR_SIZEBITS']._serialized_end=518
+  _globals['_INDEXDESCRIPTOR']._serialized_start=521
+  _globals['_INDEXDESCRIPTOR']._serialized_end=686
+  _globals['_INDEXDESCRIPTOR_TYPE']._serialized_start=626
+  _globals['_INDEXDESCRIPTOR_TYPE']._serialized_end=686
+  _globals['_STREAMDESCRIPTOR']._serialized_start=689
+  _globals['_STREAMDESCRIPTOR']._serialized_end=1118
+  _globals['_STREAMDESCRIPTOR_FIELDDESCRIPTOR']._serialized_start=1017
+  _globals['_STREAMDESCRIPTOR_FIELDDESCRIPTOR']._serialized_end=1112
+  _globals['_MSGPACKSERIALIZATION']._serialized_start=1121
+  _globals['_MSGPACKSERIALIZATION']._serialized_end=1258
+  _globals['_MSGPACKSERIALIZATION_EXTTYPE']._serialized_start=1145
+  _globals['_MSGPACKSERIALIZATION_EXTTYPE']._serialized_end=1258
+  _globals['_NORMALIZATIONMETADATA']._serialized_start=1261
+  _globals['_NORMALIZATIONMETADATA']._serialized_end=4267
+  _globals['_NORMALIZATIONMETADATA_PANDASINDEX']._serialized_start=1795
+  _globals['_NORMALIZATIONMETADATA_PANDASINDEX']._serialized_end=1910
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTIINDEX']._serialized_start=1913
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTIINDEX']._serialized_end=2169
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTIINDEX_TIMEZONEENTRY']._serialized_start=2122
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTIINDEX_TIMEZONEENTRY']._serialized_end=2169
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTICOLUMN']._serialized_start=2172
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTICOLUMN']._serialized_end=2474
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTICOLUMN_LABELS']._serialized_start=2404
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTICOLUMN_LABELS']._serialized_end=2425
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTICOLUMN_TIMEZONEENTRY']._serialized_start=2122
+  _globals['_NORMALIZATIONMETADATA_PANDASMULTICOLUMN_TIMEZONEENTRY']._serialized_end=2169
+  _globals['_NORMALIZATIONMETADATA_PANDAS']._serialized_start=2477
+  _globals['_NORMALIZATIONMETADATA_PANDAS']._serialized_end=3592
+  _globals['_NORMALIZATIONMETADATA_PANDAS_CATEGORIES']._serialized_start=3058
+  _globals['_NORMALIZATIONMETADATA_PANDAS_CATEGORIES']._serialized_end=3088
+  _globals['_NORMALIZATIONMETADATA_PANDAS_INTCATEGORIES']._serialized_start=3090
+  _globals['_NORMALIZATIONMETADATA_PANDAS_INTCATEGORIES']._serialized_end=3123
+  _globals['_NORMALIZATIONMETADATA_PANDAS_CATEGORIESENTRY']._serialized_start=3125
+  _globals['_NORMALIZATIONMETADATA_PANDAS_CATEGORIESENTRY']._serialized_end=3244
+  _globals['_NORMALIZATIONMETADATA_PANDAS_INTCATEGORIESENTRY']._serialized_start=3246
+  _globals['_NORMALIZATIONMETADATA_PANDAS_INTCATEGORIESENTRY']._serialized_end=3371
+  _globals['_NORMALIZATIONMETADATA_PANDAS_COLUMNNAME']._serialized_start=3373
+  _globals['_NORMALIZATIONMETADATA_PANDAS_COLUMNNAME']._serialized_end=3459
+  _globals['_NORMALIZATIONMETADATA_PANDAS_COLNAMESENTRY']._serialized_start=3461
+  _globals['_NORMALIZATIONMETADATA_PANDAS_COLNAMESENTRY']._serialized_end=3578
+  _globals['_NORMALIZATIONMETADATA_PANDASDATAFRAME']._serialized_start=3595
+  _globals['_NORMALIZATIONMETADATA_PANDASDATAFRAME']._serialized_end=3811
+  _globals['_NORMALIZATIONMETADATA_NORMALISEDTIMESERIES']._serialized_start=3814
+  _globals['_NORMALIZATIONMETADATA_NORMALISEDTIMESERIES']._serialized_end=4049
+  _globals['_NORMALIZATIONMETADATA_MSGPACKFRAME']._serialized_start=4051
+  _globals['_NORMALIZATIONMETADATA_MSGPACKFRAME']._serialized_end=4102
+  _globals['_NORMALIZATIONMETADATA_CUSTOMNORMALIZERMETA']._serialized_start=4104
+  _globals['_NORMALIZATIONMETADATA_CUSTOMNORMALIZERMETA']._serialized_end=4227
+  _globals['_NORMALIZATIONMETADATA_NDARRAY']._serialized_start=4229
+  _globals['_NORMALIZATIONMETADATA_NDARRAY']._serialized_end=4253
+  _globals['_COLUMNGROUPS']._serialized_start=4269
+  _globals['_COLUMNGROUPS']._serialized_end=4341
+  _globals['_USERDEFINEDMETADATA']._serialized_start=4344
+  _globals['_USERDEFINEDMETADATA']._serialized_end=4541
+  _globals['_USERDEFINEDMETADATA_SERIALIZATIONTYPE']._serialized_start=4492
+  _globals['_USERDEFINEDMETADATA_SERIALIZATIONTYPE']._serialized_end=4525
+  _globals['_ATOMKEY']._serialized_start=4544
+  _globals['_ATOMKEY']._serialized_end=4843
+  _globals['_TIMESERIESDESCRIPTOR']._serialized_start=4846
+  _globals['_TIMESERIESDESCRIPTOR']._serialized_end=5302
+  _globals['_SYMBOLLISTDESCRIPTOR']._serialized_start=5304
+  _globals['_SYMBOLLISTDESCRIPTOR']._serialized_end=5343
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/encoding_pb2.py

```diff
@@ -1,49 +1,50 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/encoding.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 from arcticc.pb2 import descriptors_pb2 as arcticc_dot_pb2_dot_descriptors__pb2
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1a\x61rcticc/pb2/encoding.proto\x12\x18\x61rcticc.pb2.encoding_pb2\x1a\x1d\x61rcticc/pb2/descriptors.proto\"\xb8\x03\n\rSegmentHeader\x12\x10\n\x08start_ts\x18\x01 \x01(\x04\x12\x0e\n\x06\x65nd_ts\x18\x02 \x01(\x04\x12H\n\x11stream_descriptor\x18\x03 \x01(\x0b\x32-.arcticc.pb2.descriptors_pb2.StreamDescriptor\x12\x36\n\x06\x66ields\x18\x05 \x03(\x0b\x32&.arcticc.pb2.encoding_pb2.EncodedField\x12\x46\n\x0chashing_algo\x18\x06 \x01(\x0e\x32\x30.arcticc.pb2.encoding_pb2.SegmentHeader.HashType\x12>\n\x0emetadata_field\x18\x07 \x01(\x0b\x32&.arcticc.pb2.encoding_pb2.EncodedField\x12\x41\n\x11string_pool_field\x18\x08 \x01(\x0b\x32&.arcticc.pb2.encoding_pb2.EncodedField\x12\x11\n\tcompacted\x18\t \x01(\x08\"%\n\x08HashType\x12\x0c\n\x08ROWCOUNT\x10\x00\x12\x0b\n\x07XX_HASH\x10\x01\"\xa4\x01\n\x0c\x45ncodedField\x12@\n\x07ndarray\x18\x02 \x01(\x0b\x32-.arcticc.pb2.encoding_pb2.NDArrayEncodedFieldH\x00\x12\x46\n\ndictionary\x18\x03 \x01(\x0b\x32\x30.arcticc.pb2.encoding_pb2.DictionaryEncodedFieldH\x00\x42\n\n\x08\x65ncoding\"\xfd\x04\n\x0cVariantCodec\x12;\n\x04zstd\x18\x10 \x01(\x0b\x32+.arcticc.pb2.encoding_pb2.VariantCodec.ZstdH\x00\x12?\n\x03tp4\x18\x11 \x01(\x0b\x32\x30.arcticc.pb2.encoding_pb2.VariantCodec.TurboPforH\x00\x12\x39\n\x03lz4\x18\x12 \x01(\x0b\x32*.arcticc.pb2.encoding_pb2.VariantCodec.Lz4H\x00\x12I\n\x0bpassthrough\x18\x13 \x01(\x0b\x32\x32.arcticc.pb2.encoding_pb2.VariantCodec.PassthroughH\x00\x1a+\n\x04Zstd\x12\r\n\x05level\x18\x01 \x01(\x05\x12\x14\n\x0cis_streaming\x18\x02 \x01(\x08\x1a\xf8\x01\n\tTurboPfor\x12M\n\tsub_codec\x18\x01 \x01(\x0e\x32:.arcticc.pb2.encoding_pb2.VariantCodec.TurboPfor.SubCodecs\"\x9b\x01\n\tSubCodecs\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x06\n\x02P4\x10\x10\x12\x0c\n\x08P4_DELTA\x10\x11\x12\x10\n\x0cP4_DELTA_RLE\x10\x12\x12\t\n\x05P4_ZZ\x10\x14\x12\x0c\n\x08\x46P_DELTA\x10 \x12\x10\n\x0c\x46P_DELTA2_ZZ\x10!\x12\x12\n\x0e\x46P_GORILLA_RLE\x10\"\x12\t\n\x05\x46P_ZZ\x10$\x12\x0f\n\x0b\x46P_ZZ_DELTA\x10(\x1a\x1b\n\x03Lz4\x12\x14\n\x0c\x61\x63\x63\x65leration\x18\x01 \x01(\x05\x1a\x1b\n\x0bPassthrough\x12\x0c\n\x04mark\x18\x01 \x01(\x08\x42\x07\n\x05\x63odec\"\x8a\x01\n\x05\x42lock\x12\x10\n\x08in_bytes\x18\x01 \x01(\r\x12\x11\n\tout_bytes\x18\x02 \x01(\r\x12\x0c\n\x04hash\x18\x03 \x01(\x04\x12\x17\n\x0f\x65ncoder_version\x18\x04 \x01(\r\x12\x35\n\x05\x63odec\x18\x05 \x01(\x0b\x32&.arcticc.pb2.encoding_pb2.VariantCodec\"\xa6\x01\n\x13NDArrayEncodedField\x12\x13\n\x0bitems_count\x18\x01 \x01(\r\x12/\n\x06shapes\x18\x02 \x03(\x0b\x32\x1f.arcticc.pb2.encoding_pb2.Block\x12/\n\x06values\x18\x03 \x03(\x0b\x32\x1f.arcticc.pb2.encoding_pb2.Block\x12\x18\n\x10sparse_map_bytes\x18\x04 \x01(\r\"\x99\x01\n\x16\x44ictionaryEncodedField\x12=\n\x06values\x18\x01 \x01(\x0b\x32-.arcticc.pb2.encoding_pb2.NDArrayEncodedField\x12@\n\tpositions\x18\x02 \x01(\x0b\x32-.arcticc.pb2.encoding_pb2.NDArrayEncodedFieldB\x03\xf8\x01\x01\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.encoding_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.encoding_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   DESCRIPTOR._serialized_options = b'\370\001\001'
-  _SEGMENTHEADER._serialized_start=88
-  _SEGMENTHEADER._serialized_end=528
-  _SEGMENTHEADER_HASHTYPE._serialized_start=491
-  _SEGMENTHEADER_HASHTYPE._serialized_end=528
-  _ENCODEDFIELD._serialized_start=531
-  _ENCODEDFIELD._serialized_end=695
-  _VARIANTCODEC._serialized_start=698
-  _VARIANTCODEC._serialized_end=1335
-  _VARIANTCODEC_ZSTD._serialized_start=974
-  _VARIANTCODEC_ZSTD._serialized_end=1017
-  _VARIANTCODEC_TURBOPFOR._serialized_start=1020
-  _VARIANTCODEC_TURBOPFOR._serialized_end=1268
-  _VARIANTCODEC_TURBOPFOR_SUBCODECS._serialized_start=1113
-  _VARIANTCODEC_TURBOPFOR_SUBCODECS._serialized_end=1268
-  _VARIANTCODEC_LZ4._serialized_start=1270
-  _VARIANTCODEC_LZ4._serialized_end=1297
-  _VARIANTCODEC_PASSTHROUGH._serialized_start=1299
-  _VARIANTCODEC_PASSTHROUGH._serialized_end=1326
-  _BLOCK._serialized_start=1338
-  _BLOCK._serialized_end=1476
-  _NDARRAYENCODEDFIELD._serialized_start=1479
-  _NDARRAYENCODEDFIELD._serialized_end=1645
-  _DICTIONARYENCODEDFIELD._serialized_start=1648
-  _DICTIONARYENCODEDFIELD._serialized_end=1801
+  _globals['_SEGMENTHEADER']._serialized_start=88
+  _globals['_SEGMENTHEADER']._serialized_end=528
+  _globals['_SEGMENTHEADER_HASHTYPE']._serialized_start=491
+  _globals['_SEGMENTHEADER_HASHTYPE']._serialized_end=528
+  _globals['_ENCODEDFIELD']._serialized_start=531
+  _globals['_ENCODEDFIELD']._serialized_end=695
+  _globals['_VARIANTCODEC']._serialized_start=698
+  _globals['_VARIANTCODEC']._serialized_end=1335
+  _globals['_VARIANTCODEC_ZSTD']._serialized_start=974
+  _globals['_VARIANTCODEC_ZSTD']._serialized_end=1017
+  _globals['_VARIANTCODEC_TURBOPFOR']._serialized_start=1020
+  _globals['_VARIANTCODEC_TURBOPFOR']._serialized_end=1268
+  _globals['_VARIANTCODEC_TURBOPFOR_SUBCODECS']._serialized_start=1113
+  _globals['_VARIANTCODEC_TURBOPFOR_SUBCODECS']._serialized_end=1268
+  _globals['_VARIANTCODEC_LZ4']._serialized_start=1270
+  _globals['_VARIANTCODEC_LZ4']._serialized_end=1297
+  _globals['_VARIANTCODEC_PASSTHROUGH']._serialized_start=1299
+  _globals['_VARIANTCODEC_PASSTHROUGH']._serialized_end=1326
+  _globals['_BLOCK']._serialized_start=1338
+  _globals['_BLOCK']._serialized_end=1476
+  _globals['_NDARRAYENCODEDFIELD']._serialized_start=1479
+  _globals['_NDARRAYENCODEDFIELD']._serialized_end=1645
+  _globals['_DICTIONARYENCODEDFIELD']._serialized_start=1648
+  _globals['_DICTIONARYENCODEDFIELD']._serialized_end=1801
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/generation_pb2.py

```diff
@@ -1,37 +1,38 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/generation.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import any_pb2 as google_dot_protobuf_dot_any__pb2
 from arcticc.pb2 import descriptors_pb2 as arcticc_dot_pb2_dot_descriptors__pb2
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1c\x61rcticc/pb2/generation.proto\x12\x1a\x61rcticc.pb2.generation_pb2\x1a\x19google/protobuf/any.proto\x1a\x1d\x61rcticc/pb2/descriptors.proto\"+\n\x12GenerationMetadata\x12\x15\n\rgroup_seq_num\x18\x01 \x01(\x04\"\x82\x05\n\x15TickStreamsGeneration\x12\n\n\x02id\x18\x01 \x01(\x04\x12\x16\n\x0eversion_number\x18\x02 \x01(\x04\x12\x17\n\x0f\x63reation_us_utc\x18\x03 \x01(\x04\x12\x19\n\x11virt_start_us_utc\x18\x04 \x01(\x04\x12\x10\n\x08timezone\x18\x05 \x01(\t\x12\x1e\n\x16previous_generation_id\x18\x06 \x01(\x04\x12\x18\n\x10\x65ncoding_version\x18\x07 \x01(\r\x12\'\n\tmeta_data\x18\x1f \x01(\x0b\x32\x14.google.protobuf.Any\x12\x63\n\x12\x64\x65scriptor_by_hash\x18  \x03(\x0b\x32G.arcticc.pb2.generation_pb2.TickStreamsGeneration.DescriptorByHashEntry\x12u\n\x1c\x64\x65scriptor_hash_by_stream_id\x18! \x03(\x0b\x32O.arcticc.pb2.generation_pb2.TickStreamsGeneration.DescriptorHashByStreamIdEntry\x12\x17\n\x0fvirt_end_us_utc\x18@ \x01(\x04\x1a\x66\n\x15\x44\x65scriptorByHashEntry\x12\x0b\n\x03key\x18\x01 \x01(\x04\x12<\n\x05value\x18\x02 \x01(\x0b\x32-.arcticc.pb2.descriptors_pb2.StreamDescriptor:\x02\x38\x01\x1a?\n\x1d\x44\x65scriptorHashByStreamIdEntry\x12\x0b\n\x03key\x18\x01 \x01(\x04\x12\r\n\x05value\x18\x02 \x01(\x04:\x02\x38\x01\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.generation_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.generation_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _TICKSTREAMSGENERATION_DESCRIPTORBYHASHENTRY._options = None
   _TICKSTREAMSGENERATION_DESCRIPTORBYHASHENTRY._serialized_options = b'8\001'
   _TICKSTREAMSGENERATION_DESCRIPTORHASHBYSTREAMIDENTRY._options = None
   _TICKSTREAMSGENERATION_DESCRIPTORHASHBYSTREAMIDENTRY._serialized_options = b'8\001'
-  _GENERATIONMETADATA._serialized_start=118
-  _GENERATIONMETADATA._serialized_end=161
-  _TICKSTREAMSGENERATION._serialized_start=164
-  _TICKSTREAMSGENERATION._serialized_end=806
-  _TICKSTREAMSGENERATION_DESCRIPTORBYHASHENTRY._serialized_start=639
-  _TICKSTREAMSGENERATION_DESCRIPTORBYHASHENTRY._serialized_end=741
-  _TICKSTREAMSGENERATION_DESCRIPTORHASHBYSTREAMIDENTRY._serialized_start=743
-  _TICKSTREAMSGENERATION_DESCRIPTORHASHBYSTREAMIDENTRY._serialized_end=806
+  _globals['_GENERATIONMETADATA']._serialized_start=118
+  _globals['_GENERATIONMETADATA']._serialized_end=161
+  _globals['_TICKSTREAMSGENERATION']._serialized_start=164
+  _globals['_TICKSTREAMSGENERATION']._serialized_end=806
+  _globals['_TICKSTREAMSGENERATION_DESCRIPTORBYHASHENTRY']._serialized_start=639
+  _globals['_TICKSTREAMSGENERATION_DESCRIPTORBYHASHENTRY']._serialized_end=741
+  _globals['_TICKSTREAMSGENERATION_DESCRIPTORHASHBYSTREAMIDENTRY']._serialized_start=743
+  _globals['_TICKSTREAMSGENERATION_DESCRIPTORHASHBYSTREAMIDENTRY']._serialized_end=806
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py

```diff
@@ -1,25 +1,26 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/in_memory_storage.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n#arcticc/pb2/in_memory_storage.proto\x12!arcticc.pb2.in_memory_storage_pb2\"\x1c\n\x06\x43onfig\x12\x12\n\ncache_size\x18\x01 \x01(\x04\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.in_memory_storage_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.in_memory_storage_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _CONFIG._serialized_start=74
-  _CONFIG._serialized_end=102
+  _globals['_CONFIG']._serialized_start=74
+  _globals['_CONFIG']._serialized_end=102
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py

```diff
@@ -1,27 +1,28 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/lmdb_storage.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1e\x61rcticc/pb2/lmdb_storage.proto\x12\x1c\x61rcticc.pb2.lmdb_storage_pb2\"\x8f\x01\n\x06\x43onfig\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\r\n\x05\x66lags\x18\x02 \x01(\r\x12\x10\n\x08map_size\x18\x03 \x01(\x04\x12\x0f\n\x07max_dbs\x18\x04 \x01(\r\x12\x13\n\x0bmax_readers\x18\x05 \x01(\r\x12\x1a\n\x12recreate_if_exists\x18\x64 \x01(\x08\"\x14\n\x05\x46lags\x12\x0b\n\x07\x44\x45\x46\x41ULT\x10\x00\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.lmdb_storage_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.lmdb_storage_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _CONFIG._serialized_start=65
-  _CONFIG._serialized_end=208
-  _CONFIG_FLAGS._serialized_start=188
-  _CONFIG_FLAGS._serialized_end=208
+  _globals['_CONFIG']._serialized_start=65
+  _globals['_CONFIG']._serialized_end=208
+  _globals['_CONFIG_FLAGS']._serialized_start=188
+  _globals['_CONFIG_FLAGS']._serialized_end=208
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/logger_pb2.py

```diff
@@ -1,49 +1,50 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/logger.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x18\x61rcticc/pb2/logger.proto\x12\x16\x61rcticc.pb2.logger_pb2\"\xa7\x03\n\rLoggersConfig\x12G\n\nsink_by_id\x18\x01 \x03(\x0b\x32\x33.arcticc.pb2.logger_pb2.LoggersConfig.SinkByIdEntry\x12K\n\x0clogger_by_id\x18\x02 \x03(\x0b\x32\x35.arcticc.pb2.logger_pb2.LoggersConfig.LoggerByIdEntry\x12\x32\n\x05\x61sync\x18\x05 \x01(\x0b\x32#.arcticc.pb2.logger_pb2.AsyncConfig\x12\x1e\n\x16\x66lush_interval_seconds\x18\x03 \x01(\r\x1aS\n\rSinkByIdEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x31\n\x05value\x18\x02 \x01(\x0b\x32\".arcticc.pb2.logger_pb2.SinkConfig:\x02\x38\x01\x1aW\n\x0fLoggerByIdEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.arcticc.pb2.logger_pb2.LoggerConfig:\x02\x38\x01\";\n\x0b\x41syncConfig\x12\x12\n\nqueue_size\x18\x01 \x01(\r\x12\x18\n\x10thread_pool_size\x18\x02 \x01(\r\"\xce\x01\n\x0cLoggerConfig\x12\x0f\n\x07pattern\x18\x01 \x01(\t\x12\x39\n\x05level\x18\x02 \x01(\x0e\x32*.arcticc.pb2.logger_pb2.LoggerConfig.Level\x12\x10\n\x08sink_ids\x18\x03 \x03(\t\"`\n\x05Level\x12\x0b\n\x07UNKNOWN\x10\x00\x12\t\n\x05TRACE\x10\x01\x12\t\n\x05\x44\x45\x42UG\x10\x02\x12\x08\n\x04INFO\x10\x03\x12\x08\n\x04WARN\x10\x04\x12\t\n\x05\x45RROR\x10\x05\x12\x0c\n\x08\x43RITICAL\x10\x06\x12\x07\n\x03OFF\x10\x07\"\x85\x04\n\nSinkConfig\x12=\n\x07\x63onsole\x18\x01 \x01(\x0b\x32*.arcticc.pb2.logger_pb2.SinkConfig.ConsoleH\x00\x12<\n\x04\x66ile\x18\x02 \x01(\x0b\x32,.arcticc.pb2.logger_pb2.SinkConfig.BasicFileH\x00\x12\x43\n\x08rot_file\x18\x03 \x01(\x0b\x32/.arcticc.pb2.logger_pb2.SinkConfig.RotatingFileH\x00\x12\x42\n\ndaily_file\x18\x04 \x01(\x0b\x32,.arcticc.pb2.logger_pb2.SinkConfig.DailyFileH\x00\x1a-\n\x07\x43onsole\x12\x11\n\thas_color\x18\x01 \x01(\x08\x12\x0f\n\x07std_err\x18\x02 \x01(\x08\x1a\x19\n\tBasicFile\x12\x0c\n\x04path\x18\x01 \x01(\t\x1aL\n\x0cRotatingFile\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x16\n\x0emax_size_bytes\x18\x02 \x01(\x04\x12\x16\n\x0emax_file_count\x18\x03 \x01(\x04\x1aQ\n\tDailyFile\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x19\n\x11utc_rotation_hour\x18\x02 \x01(\r\x12\x1b\n\x13utc_rotation_minute\x18\x03 \x01(\rB\x06\n\x04sinkb\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.logger_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.logger_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _LOGGERSCONFIG_SINKBYIDENTRY._options = None
   _LOGGERSCONFIG_SINKBYIDENTRY._serialized_options = b'8\001'
   _LOGGERSCONFIG_LOGGERBYIDENTRY._options = None
   _LOGGERSCONFIG_LOGGERBYIDENTRY._serialized_options = b'8\001'
-  _LOGGERSCONFIG._serialized_start=53
-  _LOGGERSCONFIG._serialized_end=476
-  _LOGGERSCONFIG_SINKBYIDENTRY._serialized_start=304
-  _LOGGERSCONFIG_SINKBYIDENTRY._serialized_end=387
-  _LOGGERSCONFIG_LOGGERBYIDENTRY._serialized_start=389
-  _LOGGERSCONFIG_LOGGERBYIDENTRY._serialized_end=476
-  _ASYNCCONFIG._serialized_start=478
-  _ASYNCCONFIG._serialized_end=537
-  _LOGGERCONFIG._serialized_start=540
-  _LOGGERCONFIG._serialized_end=746
-  _LOGGERCONFIG_LEVEL._serialized_start=650
-  _LOGGERCONFIG_LEVEL._serialized_end=746
-  _SINKCONFIG._serialized_start=749
-  _SINKCONFIG._serialized_end=1266
-  _SINKCONFIG_CONSOLE._serialized_start=1025
-  _SINKCONFIG_CONSOLE._serialized_end=1070
-  _SINKCONFIG_BASICFILE._serialized_start=1072
-  _SINKCONFIG_BASICFILE._serialized_end=1097
-  _SINKCONFIG_ROTATINGFILE._serialized_start=1099
-  _SINKCONFIG_ROTATINGFILE._serialized_end=1175
-  _SINKCONFIG_DAILYFILE._serialized_start=1177
-  _SINKCONFIG_DAILYFILE._serialized_end=1258
+  _globals['_LOGGERSCONFIG']._serialized_start=53
+  _globals['_LOGGERSCONFIG']._serialized_end=476
+  _globals['_LOGGERSCONFIG_SINKBYIDENTRY']._serialized_start=304
+  _globals['_LOGGERSCONFIG_SINKBYIDENTRY']._serialized_end=387
+  _globals['_LOGGERSCONFIG_LOGGERBYIDENTRY']._serialized_start=389
+  _globals['_LOGGERSCONFIG_LOGGERBYIDENTRY']._serialized_end=476
+  _globals['_ASYNCCONFIG']._serialized_start=478
+  _globals['_ASYNCCONFIG']._serialized_end=537
+  _globals['_LOGGERCONFIG']._serialized_start=540
+  _globals['_LOGGERCONFIG']._serialized_end=746
+  _globals['_LOGGERCONFIG_LEVEL']._serialized_start=650
+  _globals['_LOGGERCONFIG_LEVEL']._serialized_end=746
+  _globals['_SINKCONFIG']._serialized_start=749
+  _globals['_SINKCONFIG']._serialized_end=1266
+  _globals['_SINKCONFIG_CONSOLE']._serialized_start=1025
+  _globals['_SINKCONFIG_CONSOLE']._serialized_end=1070
+  _globals['_SINKCONFIG_BASICFILE']._serialized_start=1072
+  _globals['_SINKCONFIG_BASICFILE']._serialized_end=1097
+  _globals['_SINKCONFIG_ROTATINGFILE']._serialized_start=1099
+  _globals['_SINKCONFIG_ROTATINGFILE']._serialized_end=1175
+  _globals['_SINKCONFIG_DAILYFILE']._serialized_start=1177
+  _globals['_SINKCONFIG_DAILYFILE']._serialized_end=1258
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py

```diff
@@ -1,27 +1,28 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/mongo_storage.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1f\x61rcticc/pb2/mongo_storage.proto\x12\x1d\x61rcticc.pb2.mongo_storage_pb2\":\n\x06\x43onfig\x12\x0b\n\x03uri\x18\x01 \x01(\t\x12\r\n\x05\x66lags\x18\x02 \x01(\r\"\x14\n\x05\x46lags\x12\x0b\n\x07\x44\x45\x46\x41ULT\x10\x00\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.mongo_storage_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.mongo_storage_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _CONFIG._serialized_start=66
-  _CONFIG._serialized_end=124
-  _CONFIG_FLAGS._serialized_start=104
-  _CONFIG_FLAGS._serialized_end=124
+  _globals['_CONFIG']._serialized_start=66
+  _globals['_CONFIG']._serialized_end=124
+  _globals['_CONFIG_FLAGS']._serialized_start=104
+  _globals['_CONFIG_FLAGS']._serialized_end=124
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py

```diff
@@ -1,25 +1,26 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/nfs_backed_storage.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n$arcticc/pb2/nfs_backed_storage.proto\x12\"arcticc.pb2.nfs_backed_storage_pb2\"\x87\x02\n\x06\x43onfig\x12\x13\n\x0b\x62ucket_name\x18\x01 \x01(\t\x12\x17\n\x0f\x63redential_name\x18\x02 \x01(\t\x12\x16\n\x0e\x63redential_key\x18\x03 \x01(\t\x12\x10\n\x08\x65ndpoint\x18\x04 \x01(\t\x12\x17\n\x0fmax_connections\x18\x05 \x01(\r\x12\x17\n\x0f\x63onnect_timeout\x18\x06 \x01(\r\x12\x17\n\x0frequest_timeout\x18\x07 \x01(\r\x12\x0b\n\x03ssl\x18\x08 \x01(\x08\x12\x0e\n\x06prefix\x18\t \x01(\t\x12\r\n\x05https\x18\n \x01(\x08\x12\x0e\n\x06region\x18\x0b \x01(\t\x12\x1e\n\x16use_virtual_addressing\x18\x0c \x01(\x08\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.nfs_backed_storage_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.nfs_backed_storage_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _CONFIG._serialized_start=77
-  _CONFIG._serialized_end=340
+  _globals['_CONFIG']._serialized_start=77
+  _globals['_CONFIG']._serialized_end=340
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/processors_pb2.py

```diff
@@ -1,27 +1,28 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/processors.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1c\x61rcticc/pb2/processors.proto\x12\x1a\x61rcticc.pb2.processors_pb2\"&\n\x0f\x46ilterProcessor\x12\x13\n\x0b\x63olumn_name\x18\x01 \x01(\t\"]\n\rProcessorArgs\x12=\n\x06\x66ilter\x18\x01 \x01(\x0b\x32+.arcticc.pb2.processors_pb2.FilterProcessorH\x00\x42\r\n\x0b\x66ilter_typeb\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.processors_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.processors_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _FILTERPROCESSOR._serialized_start=60
-  _FILTERPROCESSOR._serialized_end=98
-  _PROCESSORARGS._serialized_start=100
-  _PROCESSORARGS._serialized_end=193
+  _globals['_FILTERPROCESSOR']._serialized_start=60
+  _globals['_FILTERPROCESSOR']._serialized_end=98
+  _globals['_PROCESSORARGS']._serialized_start=100
+  _globals['_PROCESSORARGS']._serialized_end=193
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/request_pb2.py

```diff
@@ -1,66 +1,67 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/request.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 from arcticc.pb2 import descriptors_pb2 as arcticc_dot_pb2_dot_descriptors__pb2
 from arcticc.pb2 import storage_pb2 as arcticc_dot_pb2_dot_storage__pb2
 from arcticc.pb2 import encoding_pb2 as arcticc_dot_pb2_dot_encoding__pb2
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x19\x61rcticc/pb2/request.proto\x12\x17\x61rcticc.pb2.request_pb2\x1a\x1d\x61rcticc/pb2/descriptors.proto\x1a\x19\x61rcticc/pb2/storage.proto\x1a\x1a\x61rcticc/pb2/encoding.proto\"\\\n\x0bReadOptions\x12\x1f\n\x17\x66orce_strings_to_object\x18\x01 \x01(\x08\x12\x16\n\x0e\x64ynamic_schema\x18\x02 \x01(\x08\x12\x14\n\x0c\x61llow_sparse\x18\x03 \x01(\x08\"\x19\n\tMonostate\x12\x0c\n\x04mark\x18\x01 \x01(\x08\"(\n\nIndexRange\x12\r\n\x05start\x18\x01 \x01(\x04\x12\x0b\n\x03\x65nd\x18\x02 \x01(\x04\"&\n\x08RowRange\x12\r\n\x05start\x18\x01 \x01(\x04\x12\x0b\n\x03\x65nd\x18\x02 \x01(\x04\"\xd8\x01\n\tReadQuery\x12\x0f\n\x07\x63olumns\x18\x01 \x03(\t\x12\x37\n\tmonostate\x18\x02 \x01(\x0b\x32\".arcticc.pb2.request_pb2.MonostateH\x00\x12:\n\x0bindex_range\x18\x03 \x01(\x0b\x32#.arcticc.pb2.request_pb2.IndexRangeH\x00\x12\x36\n\trow_range\x18\x04 \x01(\x0b\x32!.arcticc.pb2.request_pb2.RowRangeH\x00\x42\r\n\x0b\x46ilterRange\")\n\x14SnapshotVersionQuery\x12\x11\n\tsnap_name\x18\x01 \x01(\t\"*\n\x15TimestampVersionQuery\x12\x11\n\ttimestamp\x18\x01 \x01(\x03\"\'\n\x14SpecificVersionQuery\x12\x0f\n\x07version\x18\x01 \x01(\x04\"\xcc\x02\n\x0cVersionQuery\x12\x37\n\tmonostate\x18\x01 \x01(\x0b\x32\".arcticc.pb2.request_pb2.MonostateH\x00\x12\x41\n\x08snapshot\x18\x02 \x01(\x0b\x32-.arcticc.pb2.request_pb2.SnapshotVersionQueryH\x00\x12\x43\n\ttimestamp\x18\x03 \x01(\x0b\x32..arcticc.pb2.request_pb2.TimestampVersionQueryH\x00\x12\x41\n\x08specific\x18\x04 \x01(\x0b\x32-.arcticc.pb2.request_pb2.SpecificVersionQueryH\x00\x12\x13\n\x0bskip_compat\x18\x05 \x01(\x08\x12\x1a\n\x12iterate_on_failure\x18\x06 \x01(\x08\x42\x07\n\x05query\"\xf2\x01\n\x14ReadDataFrameRequest\x12\x10\n\x06num_id\x18\x01 \x01(\x04H\x00\x12\x10\n\x06str_id\x18\x02 \x01(\tH\x00\x12<\n\rversion_query\x18\x03 \x01(\x0b\x32%.arcticc.pb2.request_pb2.VersionQuery\x12\x36\n\nread_query\x18\x04 \x01(\x0b\x32\".arcticc.pb2.request_pb2.ReadQuery\x12:\n\x0cread_options\x18\x05 \x01(\x0b\x32$.arcticc.pb2.request_pb2.ReadOptionsB\x04\n\x02id\"_\n\x15ReadDataFrameResponse\x12\x46\n\x0btime_series\x18\x03 \x01(\x0b\x32\x31.arcticc.pb2.descriptors_pb2.TimeSeriesDescriptor\"l\n\x12ListSymbolsRequest\x12\x0c\n\x04mark\x18\x01 \x01(\x08\x12\r\n\x05regex\x18\x02 \x01(\t\x12\x0e\n\x06prefix\x18\x03 \x01(\t\x12\x10\n\x08snapshot\x18\x04 \x01(\t\x12\x17\n\x0fuse_symbol_list\x18\x05 \x01(\x08\"4\n\x13ListSymbolsResponse\x12\x0c\n\x04mark\x18\x01 \x01(\x08\x12\x0f\n\x07symbols\x18\x02 \x03(\t\"%\n\x15ServerShutdownRequest\x12\x0c\n\x04mark\x18\x01 \x01(\x08\"&\n\x16ServerShutdownResponse\x12\x0c\n\x04mark\x18\x01 \x01(\x08\"1\n\x14NoDataFoundException\x12\x0c\n\x04what\x18\x01 \x01(\t\x12\x0b\n\x03key\x18\x02 \x01(\t\"\x1f\n\x0fServerException\x12\x0c\n\x04what\x18\x01 \x01(\t\"\x90\x01\n\tException\x12@\n\x07no_data\x18\x01 \x01(\x0b\x32-.arcticc.pb2.request_pb2.NoDataFoundExceptionH\x00\x12\x39\n\x05\x65rror\x18\x02 \x01(\x0b\x32(.arcticc.pb2.request_pb2.ServerExceptionH\x00\x42\x06\n\x04type\"\xca\x02\n\nRpcRequest\x12:\n\x0clibrary_path\x18\x01 \x01(\x0b\x32$.arcticc.pb2.storage_pb2.LibraryPath\x12\x13\n\x0b\x65nvironment\x18\x02 \x01(\t\x12\x0e\n\x06seqnum\x18\x03 \x01(\x04\x12\x42\n\x08shutdown\x18\x04 \x01(\x0b\x32..arcticc.pb2.request_pb2.ServerShutdownRequestH\x00\x12G\n\x0eread_dataframe\x18\x05 \x01(\x0b\x32-.arcticc.pb2.request_pb2.ReadDataFrameRequestH\x00\x12\x43\n\x0clist_symbols\x18\x06 \x01(\x0b\x32+.arcticc.pb2.request_pb2.ListSymbolsRequestH\x00\x42\t\n\x07request\"\x99\x03\n\x0bRpcResponse\x12\x10\n\x06num_id\x18\x01 \x01(\x04H\x00\x12\x10\n\x06str_id\x18\x02 \x01(\tH\x00\x12\x0e\n\x06seqnum\x18\x03 \x01(\x04\x12\x36\n\x06\x66ields\x18\x04 \x03(\x0b\x32&.arcticc.pb2.encoding_pb2.EncodedField\x12\x43\n\x08shutdown\x18\x05 \x01(\x0b\x32/.arcticc.pb2.request_pb2.ServerShutdownResponseH\x01\x12\x37\n\texception\x18\x06 \x01(\x0b\x32\".arcticc.pb2.request_pb2.ExceptionH\x01\x12H\n\x0eread_dataframe\x18\x07 \x01(\x0b\x32..arcticc.pb2.request_pb2.ReadDataFrameResponseH\x01\x12\x44\n\x0clist_symbols\x18\x08 \x01(\x0b\x32,.arcticc.pb2.request_pb2.ListSymbolsResponseH\x01\x42\x04\n\x02idB\n\n\x08responseb\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.request_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.request_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _READOPTIONS._serialized_start=140
-  _READOPTIONS._serialized_end=232
-  _MONOSTATE._serialized_start=234
-  _MONOSTATE._serialized_end=259
-  _INDEXRANGE._serialized_start=261
-  _INDEXRANGE._serialized_end=301
-  _ROWRANGE._serialized_start=303
-  _ROWRANGE._serialized_end=341
-  _READQUERY._serialized_start=344
-  _READQUERY._serialized_end=560
-  _SNAPSHOTVERSIONQUERY._serialized_start=562
-  _SNAPSHOTVERSIONQUERY._serialized_end=603
-  _TIMESTAMPVERSIONQUERY._serialized_start=605
-  _TIMESTAMPVERSIONQUERY._serialized_end=647
-  _SPECIFICVERSIONQUERY._serialized_start=649
-  _SPECIFICVERSIONQUERY._serialized_end=688
-  _VERSIONQUERY._serialized_start=691
-  _VERSIONQUERY._serialized_end=1023
-  _READDATAFRAMEREQUEST._serialized_start=1026
-  _READDATAFRAMEREQUEST._serialized_end=1268
-  _READDATAFRAMERESPONSE._serialized_start=1270
-  _READDATAFRAMERESPONSE._serialized_end=1365
-  _LISTSYMBOLSREQUEST._serialized_start=1367
-  _LISTSYMBOLSREQUEST._serialized_end=1475
-  _LISTSYMBOLSRESPONSE._serialized_start=1477
-  _LISTSYMBOLSRESPONSE._serialized_end=1529
-  _SERVERSHUTDOWNREQUEST._serialized_start=1531
-  _SERVERSHUTDOWNREQUEST._serialized_end=1568
-  _SERVERSHUTDOWNRESPONSE._serialized_start=1570
-  _SERVERSHUTDOWNRESPONSE._serialized_end=1608
-  _NODATAFOUNDEXCEPTION._serialized_start=1610
-  _NODATAFOUNDEXCEPTION._serialized_end=1659
-  _SERVEREXCEPTION._serialized_start=1661
-  _SERVEREXCEPTION._serialized_end=1692
-  _EXCEPTION._serialized_start=1695
-  _EXCEPTION._serialized_end=1839
-  _RPCREQUEST._serialized_start=1842
-  _RPCREQUEST._serialized_end=2172
-  _RPCRESPONSE._serialized_start=2175
-  _RPCRESPONSE._serialized_end=2584
+  _globals['_READOPTIONS']._serialized_start=140
+  _globals['_READOPTIONS']._serialized_end=232
+  _globals['_MONOSTATE']._serialized_start=234
+  _globals['_MONOSTATE']._serialized_end=259
+  _globals['_INDEXRANGE']._serialized_start=261
+  _globals['_INDEXRANGE']._serialized_end=301
+  _globals['_ROWRANGE']._serialized_start=303
+  _globals['_ROWRANGE']._serialized_end=341
+  _globals['_READQUERY']._serialized_start=344
+  _globals['_READQUERY']._serialized_end=560
+  _globals['_SNAPSHOTVERSIONQUERY']._serialized_start=562
+  _globals['_SNAPSHOTVERSIONQUERY']._serialized_end=603
+  _globals['_TIMESTAMPVERSIONQUERY']._serialized_start=605
+  _globals['_TIMESTAMPVERSIONQUERY']._serialized_end=647
+  _globals['_SPECIFICVERSIONQUERY']._serialized_start=649
+  _globals['_SPECIFICVERSIONQUERY']._serialized_end=688
+  _globals['_VERSIONQUERY']._serialized_start=691
+  _globals['_VERSIONQUERY']._serialized_end=1023
+  _globals['_READDATAFRAMEREQUEST']._serialized_start=1026
+  _globals['_READDATAFRAMEREQUEST']._serialized_end=1268
+  _globals['_READDATAFRAMERESPONSE']._serialized_start=1270
+  _globals['_READDATAFRAMERESPONSE']._serialized_end=1365
+  _globals['_LISTSYMBOLSREQUEST']._serialized_start=1367
+  _globals['_LISTSYMBOLSREQUEST']._serialized_end=1475
+  _globals['_LISTSYMBOLSRESPONSE']._serialized_start=1477
+  _globals['_LISTSYMBOLSRESPONSE']._serialized_end=1529
+  _globals['_SERVERSHUTDOWNREQUEST']._serialized_start=1531
+  _globals['_SERVERSHUTDOWNREQUEST']._serialized_end=1568
+  _globals['_SERVERSHUTDOWNRESPONSE']._serialized_start=1570
+  _globals['_SERVERSHUTDOWNRESPONSE']._serialized_end=1608
+  _globals['_NODATAFOUNDEXCEPTION']._serialized_start=1610
+  _globals['_NODATAFOUNDEXCEPTION']._serialized_end=1659
+  _globals['_SERVEREXCEPTION']._serialized_start=1661
+  _globals['_SERVEREXCEPTION']._serialized_end=1692
+  _globals['_EXCEPTION']._serialized_start=1695
+  _globals['_EXCEPTION']._serialized_end=1839
+  _globals['_RPCREQUEST']._serialized_start=1842
+  _globals['_RPCREQUEST']._serialized_end=2172
+  _globals['_RPCRESPONSE']._serialized_start=2175
+  _globals['_RPCRESPONSE']._serialized_end=2584
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py

```diff
@@ -1,25 +1,26 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/s3_storage.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x1c\x61rcticc/pb2/s3_storage.proto\x12\x1a\x61rcticc.pb2.s3_storage_pb2\"\x87\x02\n\x06\x43onfig\x12\x13\n\x0b\x62ucket_name\x18\x01 \x01(\t\x12\x17\n\x0f\x63redential_name\x18\x02 \x01(\t\x12\x16\n\x0e\x63redential_key\x18\x03 \x01(\t\x12\x10\n\x08\x65ndpoint\x18\x04 \x01(\t\x12\x17\n\x0fmax_connections\x18\x05 \x01(\r\x12\x17\n\x0f\x63onnect_timeout\x18\x06 \x01(\r\x12\x17\n\x0frequest_timeout\x18\x07 \x01(\r\x12\x0b\n\x03ssl\x18\x08 \x01(\x08\x12\x0e\n\x06prefix\x18\t \x01(\t\x12\r\n\x05https\x18\n \x01(\x08\x12\x0e\n\x06region\x18\x0b \x01(\t\x12\x1e\n\x16use_virtual_addressing\x18\x0c \x01(\x08\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.s3_storage_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.s3_storage_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _CONFIG._serialized_start=61
-  _CONFIG._serialized_end=324
+  _globals['_CONFIG']._serialized_start=61
+  _globals['_CONFIG']._serialized_end=324
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/storage_pb2.py

```diff
@@ -1,83 +1,84 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/storage.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import any_pb2 as google_dot_protobuf_dot_any__pb2
 from arcticc.pb2 import utils_pb2 as arcticc_dot_pb2_dot_utils__pb2
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x19\x61rcticc/pb2/storage.proto\x12\x17\x61rcticc.pb2.storage_pb2\x1a\x19google/protobuf/any.proto\x1a\x17\x61rcticc/pb2/utils.proto\"\xc3\x01\n\x15\x45nvironmentConfigsMap\x12N\n\tenv_by_id\x18\x01 \x03(\x0b\x32;.arcticc.pb2.storage_pb2.EnvironmentConfigsMap.EnvByIdEntry\x1aZ\n\x0c\x45nvByIdEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x39\n\x05value\x18\x02 \x01(\x0b\x32*.arcticc.pb2.storage_pb2.EnvironmentConfig:\x02\x38\x01\"\xf2\x02\n\x11\x45nvironmentConfig\x12R\n\rstorage_by_id\x18\x01 \x03(\x0b\x32;.arcticc.pb2.storage_pb2.EnvironmentConfig.StorageByIdEntry\x12N\n\x0blib_by_path\x18\x02 \x03(\x0b\x32\x39.arcticc.pb2.storage_pb2.EnvironmentConfig.LibByPathEntry\x1a[\n\x10StorageByIdEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0b\x32\'.arcticc.pb2.storage_pb2.VariantStorage:\x02\x38\x01\x1a\\\n\x0eLibByPathEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x39\n\x05value\x18\x02 \x01(\x0b\x32*.arcticc.pb2.storage_pb2.LibraryDescriptor:\x02\x38\x01\"G\n\x0eVariantStorage\x12$\n\x06\x63onfig\x18\x02 \x01(\x0b\x32\x14.google.protobuf.Any\x12\x0f\n\x07storage\x18\x03 \x01(\t\"\x1c\n\x0bLibraryPath\x12\r\n\x05parts\x18\x01 \x03(\t\"\x99\x01\n\x11\x45ventLoggerConfig\x12@\n\x0flogstash_config\x18\x32 \x01(\x0b\x32%.arcticc.pb2.utils_pb2.LogstashConfigH\x00\x12\x38\n\x0b\x66ile_logger\x18\x33 \x01(\x0b\x32!.arcticc.pb2.utils_pb2.FileLoggerH\x00\x42\x08\n\x06\x63onfig\"\xf2\x0c\n\x12VersionStoreConfig\x12O\n\rwrite_options\x18\x01 \x01(\x0b\x32\x38.arcticc.pb2.storage_pb2.VersionStoreConfig.WriteOptions\x12,\n$use_norm_failure_handler_known_types\x18\x03 \x01(\x08\x12)\n!fail_on_missing_custom_normalizer\x18\x04 \x01(\x08\x12\x13\n\x0bsymbol_list\x18\x05 \x01(\x08\x12G\n\x08msg_pack\x18  \x01(\x0b\x32\x33.arcticc.pb2.storage_pb2.VersionStoreConfig.MsgPackH\x00\x12X\n\x0b\x66\x61ilure_sim\x18\x06 \x01(\x0b\x32\x43.arcticc.pb2.storage_pb2.VersionStoreConfig.StorageFailureSimulator\x12\x0f\n\x07\x64\x65leted\x18\x07 \x01(\x08\x12\x42\n\x11prometheus_config\x18\x08 \x01(\x0b\x32\'.arcticc.pb2.utils_pb2.PrometheusConfig\x12G\n\x13\x65vent_logger_config\x18\t \x01(\x0b\x32*.arcticc.pb2.storage_pb2.EventLoggerConfig\x12\x1b\n\x13storage_fallthrough\x18\n \x01(\x08\x1a\x9d\x07\n\x0cWriteOptions\x12\x19\n\x11\x63olumn_group_size\x18\x01 \x01(\r\x12\x18\n\x10segment_row_size\x18\x02 \x01(\x04\x12\x1e\n\x16prune_previous_version\x18\x07 \x01(\x08\x12\x16\n\x0e\x64\x65_duplication\x18\x08 \x01(\x08\x12\x17\n\x0f\x64ynamic_strings\x18\t \x01(\x08\x12\x1d\n\x15recursive_normalizers\x18\n \x01(\x08\x12\x19\n\x11pickle_on_failure\x18\x0b \x01(\x08\x12\x16\n\x0euse_tombstones\x18\x0c \x01(\x08\x12\x17\n\x0f\x64\x65layed_deletes\x18\r \x01(\x08\x12\x14\n\x0c\x61llow_sparse\x18\x32 \x01(\x08\x12\x19\n\x11\x63onsistency_check\x18\x33 \x01(\x08\x12\x16\n\x0e\x64ynamic_schema\x18\x34 \x01(\x08\x12\x12\n\nincomplete\x18\x35 \x01(\x08\x12\x0e\n\x06set_tz\x18\x36 \x01(\x08\x12\x19\n\x11ignore_sort_order\x18\x37 \x01(\x08\x12\x1a\n\x12\x66\x61st_tombstone_all\x18\x38 \x01(\x08\x12\x19\n\x11\x62ucketize_dynamic\x18\x39 \x01(\x08\x12\x17\n\x0fmax_num_buckets\x18: \x01(\r\x12^\n\rsync_disabled\x18\x0e \x01(\x0b\x32\x45.arcticc.pb2.storage_pb2.VersionStoreConfig.WriteOptions.SyncDisabledH\x00\x12\\\n\x0csync_passive\x18\x0f \x01(\x0b\x32\x44.arcticc.pb2.storage_pb2.VersionStoreConfig.WriteOptions.SyncPassiveH\x00\x12Z\n\x0bsync_active\x18\x10 \x01(\x0b\x32\x43.arcticc.pb2.storage_pb2.VersionStoreConfig.WriteOptions.SyncActiveH\x00\x12\x16\n\x0esnapshot_dedup\x18\x11 \x01(\x08\x12%\n\x1d\x63ompact_incomplete_dedup_rows\x18\x12 \x01(\x08\x1a\x1f\n\x0cSyncDisabled\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08\x1a\x1e\n\x0bSyncPassive\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08\x1a\x1d\n\nSyncActive\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08\x42\x0b\n\tsync_mode\x1a\x35\n\x07MsgPack\x12\x15\n\rmax_blob_size\x18\x01 \x01(\x04\x12\x13\n\x0bstrict_mode\x18\x02 \x01(\x08\x1aP\n\x17StorageFailureSimulator\x12\x1a\n\x12write_failure_prob\x18( \x01(\x01\x12\x19\n\x11read_failure_prob\x18) \x01(\x01\x42\x16\n\x14norm_failure_handler\"\"\n\x0fReadPermissions\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08\"#\n\x10WritePermissions\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08\"\xb2\x01\n\x0bPermissions\x12\x13\n\x0bpermissions\x18\x01 \x01(\t\x12\x0f\n\x07library\x18\x02 \x01(\t\x12\x38\n\x04read\x18\x03 \x01(\x0b\x32(.arcticc.pb2.storage_pb2.ReadPermissionsH\x00\x12:\n\x05write\x18\x04 \x01(\x0b\x32).arcticc.pb2.storage_pb2.WritePermissionsH\x00\x42\x07\n\x05level\"%\n\x12NoCredentialsStore\x12\x0f\n\x07\x65nabled\x18\x01 \x01(\x08\".\n\x15VaultCredentialsStore\x12\x15\n\rbusiness_unit\x18\x01 \x01(\t\")\n\x15MongoCredentialsStore\x12\x10\n\x08\x64\x61tabase\x18\x01 \x01(\t\"\xe2\x01\n\x10\x43redentialsStore\x12>\n\x07nostore\x18\x01 \x01(\x0b\x32+.arcticc.pb2.storage_pb2.NoCredentialsStoreH\x00\x12?\n\x05vault\x18\x02 \x01(\x0b\x32..arcticc.pb2.storage_pb2.VaultCredentialsStoreH\x00\x12?\n\x05mongo\x18\x03 \x01(\x0b\x32..arcticc.pb2.storage_pb2.MongoCredentialsStoreH\x00\x42\x0c\n\nstore_type\"\xd7\x02\n\x11LibraryDescriptor\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x12\x13\n\x0bstorage_ids\x18\x03 \x03(\t\x12>\n\x07version\x18\x04 \x01(\x0b\x32+.arcticc.pb2.storage_pb2.VersionStoreConfigH\x00\x12/\n\'prefer_native_library_on_name_collision\x18\x06 \x01(\x08\x12\x44\n\x11\x63redentials_store\x18\x07 \x01(\x0b\x32).arcticc.pb2.storage_pb2.CredentialsStore\x12\x0f\n\x07library\x18\x08 \x01(\t\x12\x1a\n\x12\x62\x61\x63kup_storage_ids\x18\t \x03(\t\x12\x18\n\x10migration_target\x18\n \x01(\tB\x0c\n\nstore_type\"\xfa\x01\n\rLibraryConfig\x12<\n\x08lib_desc\x18\x01 \x01(\x0b\x32*.arcticc.pb2.storage_pb2.LibraryDescriptor\x12N\n\rstorage_by_id\x18\x02 \x03(\x0b\x32\x37.arcticc.pb2.storage_pb2.LibraryConfig.StorageByIdEntry\x1a[\n\x10StorageByIdEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0b\x32\'.arcticc.pb2.storage_pb2.VariantStorage:\x02\x38\x01\x62\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.storage_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.storage_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   _ENVIRONMENTCONFIGSMAP_ENVBYIDENTRY._options = None
   _ENVIRONMENTCONFIGSMAP_ENVBYIDENTRY._serialized_options = b'8\001'
   _ENVIRONMENTCONFIG_STORAGEBYIDENTRY._options = None
   _ENVIRONMENTCONFIG_STORAGEBYIDENTRY._serialized_options = b'8\001'
   _ENVIRONMENTCONFIG_LIBBYPATHENTRY._options = None
   _ENVIRONMENTCONFIG_LIBBYPATHENTRY._serialized_options = b'8\001'
   _LIBRARYCONFIG_STORAGEBYIDENTRY._options = None
   _LIBRARYCONFIG_STORAGEBYIDENTRY._serialized_options = b'8\001'
-  _ENVIRONMENTCONFIGSMAP._serialized_start=107
-  _ENVIRONMENTCONFIGSMAP._serialized_end=302
-  _ENVIRONMENTCONFIGSMAP_ENVBYIDENTRY._serialized_start=212
-  _ENVIRONMENTCONFIGSMAP_ENVBYIDENTRY._serialized_end=302
-  _ENVIRONMENTCONFIG._serialized_start=305
-  _ENVIRONMENTCONFIG._serialized_end=675
-  _ENVIRONMENTCONFIG_STORAGEBYIDENTRY._serialized_start=490
-  _ENVIRONMENTCONFIG_STORAGEBYIDENTRY._serialized_end=581
-  _ENVIRONMENTCONFIG_LIBBYPATHENTRY._serialized_start=583
-  _ENVIRONMENTCONFIG_LIBBYPATHENTRY._serialized_end=675
-  _VARIANTSTORAGE._serialized_start=677
-  _VARIANTSTORAGE._serialized_end=748
-  _LIBRARYPATH._serialized_start=750
-  _LIBRARYPATH._serialized_end=778
-  _EVENTLOGGERCONFIG._serialized_start=781
-  _EVENTLOGGERCONFIG._serialized_end=934
-  _VERSIONSTORECONFIG._serialized_start=937
-  _VERSIONSTORECONFIG._serialized_end=2587
-  _VERSIONSTORECONFIG_WRITEOPTIONS._serialized_start=1501
-  _VERSIONSTORECONFIG_WRITEOPTIONS._serialized_end=2426
-  _VERSIONSTORECONFIG_WRITEOPTIONS_SYNCDISABLED._serialized_start=2319
-  _VERSIONSTORECONFIG_WRITEOPTIONS_SYNCDISABLED._serialized_end=2350
-  _VERSIONSTORECONFIG_WRITEOPTIONS_SYNCPASSIVE._serialized_start=2352
-  _VERSIONSTORECONFIG_WRITEOPTIONS_SYNCPASSIVE._serialized_end=2382
-  _VERSIONSTORECONFIG_WRITEOPTIONS_SYNCACTIVE._serialized_start=2384
-  _VERSIONSTORECONFIG_WRITEOPTIONS_SYNCACTIVE._serialized_end=2413
-  _VERSIONSTORECONFIG_MSGPACK._serialized_start=2428
-  _VERSIONSTORECONFIG_MSGPACK._serialized_end=2481
-  _VERSIONSTORECONFIG_STORAGEFAILURESIMULATOR._serialized_start=2483
-  _VERSIONSTORECONFIG_STORAGEFAILURESIMULATOR._serialized_end=2563
-  _READPERMISSIONS._serialized_start=2589
-  _READPERMISSIONS._serialized_end=2623
-  _WRITEPERMISSIONS._serialized_start=2625
-  _WRITEPERMISSIONS._serialized_end=2660
-  _PERMISSIONS._serialized_start=2663
-  _PERMISSIONS._serialized_end=2841
-  _NOCREDENTIALSSTORE._serialized_start=2843
-  _NOCREDENTIALSSTORE._serialized_end=2880
-  _VAULTCREDENTIALSSTORE._serialized_start=2882
-  _VAULTCREDENTIALSSTORE._serialized_end=2928
-  _MONGOCREDENTIALSSTORE._serialized_start=2930
-  _MONGOCREDENTIALSSTORE._serialized_end=2971
-  _CREDENTIALSSTORE._serialized_start=2974
-  _CREDENTIALSSTORE._serialized_end=3200
-  _LIBRARYDESCRIPTOR._serialized_start=3203
-  _LIBRARYDESCRIPTOR._serialized_end=3546
-  _LIBRARYCONFIG._serialized_start=3549
-  _LIBRARYCONFIG._serialized_end=3799
-  _LIBRARYCONFIG_STORAGEBYIDENTRY._serialized_start=490
-  _LIBRARYCONFIG_STORAGEBYIDENTRY._serialized_end=581
+  _globals['_ENVIRONMENTCONFIGSMAP']._serialized_start=107
+  _globals['_ENVIRONMENTCONFIGSMAP']._serialized_end=302
+  _globals['_ENVIRONMENTCONFIGSMAP_ENVBYIDENTRY']._serialized_start=212
+  _globals['_ENVIRONMENTCONFIGSMAP_ENVBYIDENTRY']._serialized_end=302
+  _globals['_ENVIRONMENTCONFIG']._serialized_start=305
+  _globals['_ENVIRONMENTCONFIG']._serialized_end=675
+  _globals['_ENVIRONMENTCONFIG_STORAGEBYIDENTRY']._serialized_start=490
+  _globals['_ENVIRONMENTCONFIG_STORAGEBYIDENTRY']._serialized_end=581
+  _globals['_ENVIRONMENTCONFIG_LIBBYPATHENTRY']._serialized_start=583
+  _globals['_ENVIRONMENTCONFIG_LIBBYPATHENTRY']._serialized_end=675
+  _globals['_VARIANTSTORAGE']._serialized_start=677
+  _globals['_VARIANTSTORAGE']._serialized_end=748
+  _globals['_LIBRARYPATH']._serialized_start=750
+  _globals['_LIBRARYPATH']._serialized_end=778
+  _globals['_EVENTLOGGERCONFIG']._serialized_start=781
+  _globals['_EVENTLOGGERCONFIG']._serialized_end=934
+  _globals['_VERSIONSTORECONFIG']._serialized_start=937
+  _globals['_VERSIONSTORECONFIG']._serialized_end=2587
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS']._serialized_start=1501
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS']._serialized_end=2426
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS_SYNCDISABLED']._serialized_start=2319
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS_SYNCDISABLED']._serialized_end=2350
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS_SYNCPASSIVE']._serialized_start=2352
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS_SYNCPASSIVE']._serialized_end=2382
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS_SYNCACTIVE']._serialized_start=2384
+  _globals['_VERSIONSTORECONFIG_WRITEOPTIONS_SYNCACTIVE']._serialized_end=2413
+  _globals['_VERSIONSTORECONFIG_MSGPACK']._serialized_start=2428
+  _globals['_VERSIONSTORECONFIG_MSGPACK']._serialized_end=2481
+  _globals['_VERSIONSTORECONFIG_STORAGEFAILURESIMULATOR']._serialized_start=2483
+  _globals['_VERSIONSTORECONFIG_STORAGEFAILURESIMULATOR']._serialized_end=2563
+  _globals['_READPERMISSIONS']._serialized_start=2589
+  _globals['_READPERMISSIONS']._serialized_end=2623
+  _globals['_WRITEPERMISSIONS']._serialized_start=2625
+  _globals['_WRITEPERMISSIONS']._serialized_end=2660
+  _globals['_PERMISSIONS']._serialized_start=2663
+  _globals['_PERMISSIONS']._serialized_end=2841
+  _globals['_NOCREDENTIALSSTORE']._serialized_start=2843
+  _globals['_NOCREDENTIALSSTORE']._serialized_end=2880
+  _globals['_VAULTCREDENTIALSSTORE']._serialized_start=2882
+  _globals['_VAULTCREDENTIALSSTORE']._serialized_end=2928
+  _globals['_MONGOCREDENTIALSSTORE']._serialized_start=2930
+  _globals['_MONGOCREDENTIALSSTORE']._serialized_end=2971
+  _globals['_CREDENTIALSSTORE']._serialized_start=2974
+  _globals['_CREDENTIALSSTORE']._serialized_end=3200
+  _globals['_LIBRARYDESCRIPTOR']._serialized_start=3203
+  _globals['_LIBRARYDESCRIPTOR']._serialized_end=3546
+  _globals['_LIBRARYCONFIG']._serialized_start=3549
+  _globals['_LIBRARYCONFIG']._serialized_end=3799
+  _globals['_LIBRARYCONFIG_STORAGEBYIDENTRY']._serialized_start=490
+  _globals['_LIBRARYCONFIG_STORAGEBYIDENTRY']._serialized_end=581
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/proto/4/arcticc/pb2/utils_pb2.py

```diff
@@ -1,33 +1,34 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
 # source: arcticc/pb2/utils.proto
 """Generated protocol buffer code."""
-from google.protobuf.internal import builder as _builder
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import symbol_database as _symbol_database
+from google.protobuf.internal import builder as _builder
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x17\x61rcticc/pb2/utils.proto\x12\x15\x61rcticc.pb2.utils_pb2\"\xd4\x01\n\x0eRemoteryConfig\x12\x0c\n\x04port\x18\x01 \x01(\r\x12\x1e\n\x16\x64o_not_reuse_open_port\x18\x02 \x01(\x08\x12&\n\x1elimit_connections_to_localhost\x18\x03 \x01(\x08\x12#\n\x1bms_sleep_btw_server_updates\x18\x04 \x01(\r\x12#\n\x1bmessage_queue_size_in_bytes\x18\x05 \x01(\r\x12\"\n\x1amax_nb_messages_per_update\x18\x06 \x01(\r\"\xf0\x01\n\x10PrometheusConfig\x12\x10\n\x08instance\x18\x01 \x01(\t\x12\x0c\n\x04host\x18\x02 \x01(\t\x12\x0c\n\x04port\x18\x03 \x01(\t\x12\x10\n\x08job_name\x18\x04 \x01(\t\x12\x16\n\x0eprometheus_env\x18\x05 \x01(\t\x12Q\n\x10prometheus_model\x18\x06 \x01(\x0e\x32\x37.arcticc.pb2.utils_pb2.PrometheusConfig.PrometheusModel\"1\n\x0fPrometheusModel\x12\x0b\n\x07NO_INIT\x10\x00\x12\x08\n\x04PUSH\x10\x01\x12\x07\n\x03WEB\x10\x02\"[\n\x0eLogstashConfig\x12\x12\n\nevent_type\x18\x01 \x01(\t\x12\x0c\n\x04host\x18\x02 \x01(\t\x12\x0c\n\x04port\x18\x03 \x01(\t\x12\x19\n\x11\x61llow_name_lookup\x18\x04 \x01(\x08\"\x1f\n\nFileLogger\x12\x11\n\tfile_path\x18\x01 \x01(\tb\x06proto3')
 
-_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
-_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.utils_pb2', globals())
+_globals = globals()
+_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
+_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'arcticc.pb2.utils_pb2', _globals)
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
-  _REMOTERYCONFIG._serialized_start=51
-  _REMOTERYCONFIG._serialized_end=263
-  _PROMETHEUSCONFIG._serialized_start=266
-  _PROMETHEUSCONFIG._serialized_end=506
-  _PROMETHEUSCONFIG_PROMETHEUSMODEL._serialized_start=457
-  _PROMETHEUSCONFIG_PROMETHEUSMODEL._serialized_end=506
-  _LOGSTASHCONFIG._serialized_start=508
-  _LOGSTASHCONFIG._serialized_end=599
-  _FILELOGGER._serialized_start=601
-  _FILELOGGER._serialized_end=632
+  _globals['_REMOTERYCONFIG']._serialized_start=51
+  _globals['_REMOTERYCONFIG']._serialized_end=263
+  _globals['_PROMETHEUSCONFIG']._serialized_start=266
+  _globals['_PROMETHEUSCONFIG']._serialized_end=506
+  _globals['_PROMETHEUSCONFIG_PROMETHEUSMODEL']._serialized_start=457
+  _globals['_PROMETHEUSCONFIG_PROMETHEUSMODEL']._serialized_end=506
+  _globals['_LOGSTASHCONFIG']._serialized_start=508
+  _globals['_LOGSTASHCONFIG']._serialized_end=599
+  _globals['_FILELOGGER']._serialized_start=601
+  _globals['_FILELOGGER']._serialized_end=632
 # @@protoc_insertion_point(module_scope)
```

## arcticdb/util/test.py

```diff
@@ -20,15 +20,15 @@
 
 from arcticdb.config import Defaults
 from arcticdb.log import configure, logger_by_name
 from arcticdb.version_store._custom_normalizers import CustomNormalizer
 from arcticc.pb2.descriptors_pb2 import NormalizationMetadata
 from arcticc.pb2.logger_pb2 import LoggerConfig, LoggersConfig
 from arcticc.pb2.storage_pb2 import LibraryDescriptor, VersionStoreConfig
-from arcticdb.version_store.helper import ArcticcFileConfig
+from arcticdb.version_store.helper import ArcticFileConfig
 from arcticdb.config import _DEFAULT_ENVS_PATH
 from arcticdb_ext import set_config_int, get_config_int, unset_config_int
 
 
 PANDAS_VERSION = version.parse(pd.__version__)
 CHECK_FREQ_VERSION = version.Version("1.1")
 IS_PANDAS_ZERO = PANDAS_VERSION < version.Version("1.0")
@@ -134,15 +134,15 @@
             "bool": np.random.randn(size) > 0,
         }
     )
     return df
 
 
 def get_lib_by_name(lib_name, env, conf_path=_DEFAULT_ENVS_PATH):
-    local_conf = ArcticcFileConfig(env, conf_path)
+    local_conf = ArcticFileConfig(env, conf_path)
     lib = local_conf[lib_name]
     return lib
 
 
 @contextmanager
 def config_context(name, value):
     try:
```

## arcticdb/version_store/_store.py

```diff
@@ -1387,15 +1387,15 @@
             return [self._get_version_query(None, **kwargs) for _ in range(num_symbols)]
 
     def _get_read_query(self, date_range: Optional[DateRangeInput], row_range, columns, query_builder):
         check(date_range is None or row_range is None, "Date range and row range both specified")
         read_query = _PythonVersionStoreReadQuery()
 
         if query_builder:
-            read_query.set_clause_builder(query_builder.finalize_clause_builder())
+            read_query.add_clauses(query_builder.clauses)
 
         if date_range is not None:
             read_query.row_filter = _normalize_dt_range(date_range)
 
         if row_range is not None:
             read_query.row_range = row_range
```

## arcticdb/version_store/helper.py

```diff
@@ -1,22 +1,24 @@
 """
 Copyright 2023 Man Group Operations Limited
 
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
+import os.path as osp
 import re
 import time
 from typing import Iterable, Dict, Any, Union
 
 from arcticc.pb2.lmdb_storage_pb2 import Config as LmdbConfig
 from arcticc.pb2.s3_storage_pb2 import Config as S3Config
 from arcticc.pb2.in_memory_storage_pb2 import Config as MemoryConfig
 from arcticc.pb2.mongo_storage_pb2 import Config as MongoConfig
+from arcticc.pb2.nfs_backed_storage_pb2 import Config as NfsConfig
 from arcticc.pb2.storage_pb2 import (
     EnvironmentConfigsMap,
     EnvironmentConfig,
     LibraryConfig,
     LibraryDescriptor,
     VariantStorage,
     Permissions,
@@ -73,15 +75,15 @@
         # type: (MongoDBConnector)->None
         self.mongo_connector = connector
 
     def set_uri_builder(self, uri_builder):
         self.uri_builder = uri_builder
 
 
-class ArcticcFileConfig(ArcticConfig):
+class ArcticFileConfig(ArcticConfig):
     def __init__(self, env=Defaults.ENV, config_path=Defaults.ENV_FILE_PATH):
         # type: (EnvName, FilePath)->None
         self._conf_path = _expand_path(config_path)
         self._env = env
 
     def _check_config(self):
         if not osp.exists(self._conf_path):
@@ -330,8 +332,8 @@
 
 def get_arctic_native_lib(lib_fqn):
     # type: (AnyStr)->NativeVersionStore
     m = _LIB_PATH_REGEX.match(lib_fqn)
     if m is None:
         raise LibraryNotFound(lib_fqn)
     lib, path = m.group(1), m.group(2)
-    return ArcticcFileConfig(config_path=path)[lib]
+    return ArcticFileConfig(config_path=path)[lib]
```

## arcticdb/version_store/library.py

```diff
@@ -123,15 +123,15 @@
         ``(datetime.datetime(1970, 1, 1), datetime.datetime(1970, 1, 1))``.
     """
 
     columns: Tuple[NameWithDType]
     index: NameWithDType
     index_type: str
     row_count: int
-    last_update_time: datetime.datetime
+    last_update_time: datetime64
     date_range: Tuple[datetime.datetime, datetime.datetime]
 
 
 class WritePayload:
     """
     WritePayload is designed to enable batching of multiple operations with an API that mirrors the singular
     ``write`` API.
@@ -271,15 +271,15 @@
         return self.has_symbol(symbol)
 
     def write(
         self,
         symbol: str,
         data: NormalizableType,
         metadata: Any = None,
-        prune_previous_versions: bool = True,
+        prune_previous_versions: bool = False,
         staged=False,
         validate_index=True,
     ) -> VersionedItem:
         """
         Write ``data`` to the specified ``symbol``. If ``symbol`` already exists then a new version will be created to
         reference the newly written data. For more information on versions see the documentation for the `read`
         primitive.
@@ -310,15 +310,15 @@
         symbol : str
             Symbol name. Limited to 255 characters. The following characters are not supported in symbols:
             ``"*", "&", "<", ">"``
         data : NormalizableType
             Data to be written. To write non-normalizable data, use `write_pickle`.
         metadata : Any, default=None
             Optional metadata to persist along with the symbol.
-        prune_previous_versions : bool, default=True
+        prune_previous_versions : bool, default=False
             Removes previous (non-snapshotted) versions from the database.
         staged : bool, default=False
             Whether to write to a staging area rather than immediately to the library.
         validate_index: bool, default=False
             If True, will verify that the index of `data` supports date range searches and update operations. This in effect tests that the data is sorted in ascending order.
             ArcticDB relies on Pandas to detect if data is sorted - you can call DataFrame.index.is_monotonic_increasing on your input DataFrame to see if Pandas believes the
             data to be sorted
@@ -378,15 +378,15 @@
             prune_previous_version=prune_previous_versions,
             pickle_on_failure=False,
             parallel=staged,
             validate_index=validate_index,
         )
 
     def write_pickle(
-        self, symbol: str, data: Any, metadata: Any = None, prune_previous_versions: bool = True, staged=False
+        self, symbol: str, data: Any, metadata: Any = None, prune_previous_versions: bool = False, staged=False
     ) -> VersionedItem:
         """
         See `write`. This method differs from `write` only in that ``data`` can be of any type that is serialisable via
         the Pickle library. There are significant downsides to storing data in this way:
 
         - Retrieval can only be done in bulk. Calls to `read` will not support `date_range`, `query_builder` or `columns`.
         - The data cannot be updated or appended to via the update and append methods.
@@ -451,24 +451,24 @@
             f"write_batch_pickle instead. symbols with bad datatypes={bad_symbols[:5]}"
         )
         if len(bad_symbols) > 5:
             error_message += f" (and more)... {len(bad_symbols)} data in total have bad types."
         raise ArcticUnsupportedDataTypeException(error_message)
 
     def write_batch(
-        self, payloads: List[WritePayload], prune_previous_versions: bool = True, staged=False, validate_index=True
+        self, payloads: List[WritePayload], prune_previous_versions: bool = False, staged=False, validate_index=True
     ) -> List[VersionedItem]:
         """
         Write a batch of multiple symbols.
 
         Parameters
         ----------
         payloads : `List[WritePayload]`
             Symbols and their corresponding data. There must not be any duplicate symbols in `payload`.
-        prune_previous_versions: `bool`, default=True
+        prune_previous_versions: `bool`, default=False
             See `write`.
         staged: `bool`, default=False
             See `write`.
         validate_index: bool, default=False
             If True, will verify for each entry in the batch hat the index of `data` supports date range searches and update operations.
             This in effect tests that the data is sorted in ascending order. ArcticDB relies on Pandas to detect if data is sorted -
             you can call DataFrame.index.is_monotonic_increasing on your input DataFrame to see if Pandas believes the data to be sorted
@@ -525,24 +525,24 @@
             prune_previous_version=prune_previous_versions,
             pickle_on_failure=False,
             parallel=staged,
             validate_index=validate_index,
         )
 
     def write_batch_pickle(
-        self, payloads: List[WritePayload], prune_previous_versions: bool = True, staged=False
+        self, payloads: List[WritePayload], prune_previous_versions: bool = False, staged=False
     ) -> List[VersionedItem]:
         """
         Write a batch of multiple symbols, pickling their data if necessary.
 
         Parameters
         ----------
         payloads : `List[WritePayload]`
             Symbols and their corresponding data. There must not be any duplicate symbols in `payload`.
-        prune_previous_versions: `bool`, default=True
+        prune_previous_versions: `bool`, default=False
             See `write`.
         staged: `bool`, default=False
             See `write`.
 
         Returns
         -------
         List[VersionedItem]
@@ -1334,26 +1334,26 @@
 
         See Also
         --------
         SymbolDescription
             For documentation on each field.
         """
         info = self._nvs.get_info(symbol, as_of)
-
-        last_update_time = pd.to_datetime(info["last_update"])
+        last_update_time = pd.to_datetime(info["last_update"], utc=True)
         columns = tuple(NameWithDType(n, t) for n, t in zip(info["col_names"]["columns"], info["dtype"]))
         index = NameWithDType(info["col_names"]["index"], info["col_names"]["index_dtype"])
+        date_range = tuple(map(lambda x: x.replace(tzinfo=datetime.timezone.utc), info["date_range"]))
 
         return SymbolDescription(
             columns=columns,
             index=index,
             row_count=info["rows"],
             last_update_time=last_update_time,
             index_type=info["index_type"],
-            date_range=info["date_range"],
+            date_range=date_range,
         )
 
     def get_description_batch(self, symbols: List[Union[str, ReadInfoRequest]]) -> List[SymbolDescription]:
         """
         Returns descriptive data for a list of ``symbols``.
 
         Parameters
```

## arcticdb/version_store/processing.py

```diff
@@ -1,28 +1,33 @@
 """
 Copyright 2023 Man Group Operations Limited
 
 Use of this software is governed by the Business Source License 1.1 included in the file licenses/BSL.txt.
 
 As of the Change Date specified in that file, in accordance with the Business Source License, use of this software will be governed by the Apache License, version 2.0.
 """
-import copy
+from collections import namedtuple
 import datetime
 from math import inf
 
 import numpy as np
 import pandas as pd
 
-from abc import ABC, abstractmethod
+from typing import Dict
 
 from arcticdb.exceptions import ArcticNativeException, UserInputException
+from arcticdb.preconditions import check
 from arcticdb.supported_types import time_types as supported_time_types
 
-from arcticdb_ext.version_store import ExecutionContextOptimisation as _Optimisation
-from arcticdb_ext.version_store import ExecutionContext as _ExecutionContext
+from arcticdb_ext.version_store import PipelineOptimisation as _Optimisation
+from arcticdb_ext.version_store import ExpressionContext as _ExpressionContext
+from arcticdb_ext.version_store import FilterClause as _FilterClause
+from arcticdb_ext.version_store import ProjectClause as _ProjectClause
+from arcticdb_ext.version_store import GroupByClause as _GroupByClause
+from arcticdb_ext.version_store import AggregationClause as _AggregationClause
 from arcticdb_ext.version_store import ExpressionName as _ExpressionName
 from arcticdb_ext.version_store import ColumnName as _ColumnName
 from arcticdb_ext.version_store import ValueName as _ValueName
 from arcticdb_ext.version_store import ValueSetName as _ValueSetName
 from arcticdb_ext.version_store import Value as _Value
 from arcticdb_ext.version_store import ValueSet as _ValueSet
 from arcticdb_ext.version_store import (
@@ -37,16 +42,14 @@
     ValueInt64,
     ValueFloat32,
     ValueFloat64,
 )
 from arcticdb_ext.version_store import ExpressionNode as _ExpressionNode
 from arcticdb_ext.version_store import OperationType as _OperationType
 
-from arcticdb_ext.version_store import ClauseBuilder as _ClauseBuilder
-
 COLUMN = "COLUMN"
 
 
 class ExpressionNode:
     # Required so that comparisons like:
     # np.int(0) < <ExpressionNode object>
     # work as we want
@@ -250,120 +253,44 @@
     else:
         # Return an empty list. This will call the string ctor for ValueSet, but also set a bool flag so that numeric
         # types also behave as expected
         value_list = []
     return value_list
 
 
-class PyClauseBase(ABC):
-    @abstractmethod
-    def to_cpp(self, clause_builder) -> None:
-        pass
-
-
-class WhereClause(PyClauseBase):
-    def __init__(self, expr):
-        self.expr = expr
-
-    def __str__(self):
-        return "WhereClause: {}".format(str(self.expr))
-
-    def to_cpp(self, clause_builder):
-        clause_builder.add_FilterClause(visit_expression(self.expr))
-
-
-class ProjectClause(PyClauseBase):
-    def __init__(self, name, expr):
-        self.name = name
-        self.expr = expr
-
-    def __str__(self):
-        return "ProjectClause:{} -> {}".format(str(self.expr), self.name)
-
-    def to_cpp(self, clause_builder):
-        clause_builder.add_ProjectClause(self.name, visit_expression(self.expr))
-
-
-class Aggregation:
-    def __init__(self, source, operator):
-        self.source = source
-        self.operator = operator
-
-    def __str__(self):
-        return "{}({})".format(self.operator, self.source)
-
-    def to_cpp(self, clause_builder):
-        # TODO: Move to dictionary
-        if self.operator.lower() == "sum":
-            clause_builder.add_SumAggregationOperator(self.source, self.source)
-        elif self.operator.lower() == "mean":
-            clause_builder.add_MeanAggregationOperator(self.source, self.source)
-        elif self.operator.lower() == "max":
-            clause_builder.add_MaxAggregationOperator(self.source, self.source)
-        elif self.operator.lower() == "min":
-            clause_builder.add_MinAggregationOperator(self.source, self.source)
-        else:
-            raise ValueError("Aggregation operators are limited to 'sum', 'mean', 'max' and 'min'.")
-
-
-class GroupByClause(PyClauseBase):
-    def __init__(self, key, query_builder):
-        self.key = key
-        self.query_builder = query_builder
-        self.aggregations = {}
-
-    def __str__(self):
-        return "GroupByClause: key={}, [{}]".format(
-            str(self.key), ", ".join(["{} <- {}".format(k, v) for k, v in self.aggregations.items()])
-        )
-
-    def agg(self, aggregations):
-        for key, value in aggregations.items():
-            self.aggregations[key] = Aggregation(key, value)
-
-        return self.query_builder
-
-    def to_cpp(self, clause_builder):
-        def _expression_root_only(col_name: str):
-            _ec = _ExecutionContext()
-            _ec.root_node_name = _ExpressionName(col_name)
-
-            return _ec
-
-        clause_builder.prepare_AggregationClause(_expression_root_only(self.key))
-        for agg in self.aggregations.values():
-            agg.to_cpp(clause_builder)
-        clause_builder.finalize_AggregationClause()
+# These are just used for shallow/deep copying, pickling, and equality checks
+PythonFilterClause = namedtuple("PythonFilterClause", ["expr"])
+PythonProjectionClause = namedtuple("PythonProjectionClause", ["name", "expr"])
+PythonGroupByClause = namedtuple("PythonGroupByClause", ["name"])
+PythonAggregationClause = namedtuple("PythonAggregationClause", ["aggregations"])
 
 
 class QueryBuilder:
     """
     Build a query to process read results with. Syntax is designed to be similar to Pandas:
 
         >>> q = QueryBuilder()
         >>> q = q[q["a"] < 5] (equivalent to q = q[q.a < 5] provided the column name is also a valid Python variable name)
         >>> dataframe = lib.read(symbol, query_builder=q).data
 
-    QueryBuilder objects are stateful, and so should not be reused without reinitialising:
-
-    >>> q = QueryBuilder()
-
     For Group By and Aggregation functionality please see the documentation for the `groupby`. For projection
     functionality, see the documentation for the `apply` method.
 
-    Supported numeric operations when filtering:
-
-    * Binary comparisons: <, <=, >, >=, ==, !=
-
-    * Unary NOT: ~
+    Supported arithmetic operations when projection or filtering:
 
     * Binary arithmetic: +, -, *, /
 
     * Unary arithmetic: -, abs
 
+    Supported filtering operations:
+
+    * Binary comparisons: <, <=, >, >=, ==, !=
+
+    * Unary NOT: ~
+
     * Binary combinators: &, |, ^
 
     * List membership: isin, isnotin (also accessible with == and !=)
 
     isin/isnotin accept lists, sets, frozensets, 1D ndarrays, or *args unpacking. For example:
 
     >>> l = [1, 2, 3]
@@ -404,19 +331,20 @@
         Column involved in query is not present in symbol
         Query involves comparing strings using <, <=, >, or >= operators
         Query involves comparing a string to one or more numeric values, or vice versa
         Query involves arithmetic with a column containing strings
     """
 
     def __init__(self):
-        self.stages = []
+        self.clauses = []
+        # This is hacky, but the alternative is implementing pickle for the C++ classes of all the clauses, and the tree
+        # of classes these depend on, which is A LOT
+        self._python_clauses = []
         self._optimisation = _Optimisation.SPEED
 
-        self._clause_builder = _ClauseBuilder()
-
     def apply(self, name, expr):
         """
         Apply enables new columns to be created using supported QueryBuilder numeric operations. See the documentation for the
         QueryBuilder class for more information on supported expressions - any expression valid in a filter is valid when using
         `apply`.
 
         Parameters
@@ -454,32 +382,34 @@
         9     29   19   9.0       558
 
         Returns
         -------
         QueryBuilder
             Modified QueryBuilder object.
         """
-        self.stages.append(ProjectClause(name, expr))
+        input_columns, expression_context = visit_expression(expr)
+        self.clauses.append(_ProjectClause(input_columns, name, expression_context))
+        self._python_clauses.append(PythonProjectionClause(name, expr))
         return self
 
-    def groupby(self, expr: str):
+    def groupby(self, name: str):
         """
         Group symbol by column name. GroupBy operations must be followed by an aggregation operator. Currently the following four aggregation
         operators are supported:
             * "mean" - compute the mean of the group
             * "sum" - compute the sum of the group
             * "min" - compute the min of the group
             * "max" - compute the max of the group
 
         For usage examples, see below.
 
         Parameters
         ----------
-        expr: `str`
-            Name of the symbol to group on. Note that currently GroupBy only supports single-column groupings.
+        name: `str`
+            Name of the column to group on. Note that currently GroupBy only supports single-column groupings.
 
         Examples
         --------
         Average (mean) over two groups:
 
         >>> df = pd.DataFrame(
             {
@@ -530,87 +460,101 @@
             group_1     2.5  1.666667
 
         Returns
         -------
         QueryBuilder
             Modified QueryBuilder object.
         """
-        self.stages.append(GroupByClause(expr, self))
-        return self.stages[-1]
+        self.clauses.append(_GroupByClause(name))
+        self._python_clauses.append(PythonGroupByClause(name))
+        return self
+
+    def agg(self, aggregations: Dict[str, str]):
+        # Only makes sense if previous stage is a group-by
+        check(
+            len(self.clauses) and isinstance(self.clauses[-1], _GroupByClause),
+            f"Aggregation only makes sense after groupby",
+        )
+        for v in aggregations.values():
+            v = v.lower()
+        self.clauses.append(_AggregationClause(self.clauses[-1].grouping_column, aggregations))
+        self._python_clauses.append(PythonAggregationClause(aggregations))
+        return self
 
     def __eq__(self, right):
-        return str(self) == str(right)
+        return self._optimisation == right._optimisation and self._python_clauses == right._python_clauses
 
     def __str__(self):
-        return " | ".join(str(e) for e in self.stages)
+        return " | ".join(str(clause) for clause in self.clauses)
 
     def __getitem__(self, item):
         if isinstance(item, str):
             return ExpressionNode.column_ref(item)
         else:
             # This handles the case where the filtering is on a single boolean column
             # e.g. q = q[q["col"]]
             if isinstance(item, ExpressionNode) and item.operator == COLUMN:
                 item = ExpressionNode.compose(item, _OperationType.IDENTITY, None)
-            self.stages.append(WhereClause(item))
+            input_columns, expression_context = visit_expression(item)
+            self.clauses.append(_FilterClause(input_columns, expression_context, self._optimisation))
+            self._python_clauses.append(PythonFilterClause(item))
             return self
 
     def __getattr__(self, key):
         return self[key]
 
     def __getstate__(self):
         rv = vars(self).copy()
-        del rv["_clause_builder"]
+        del rv["clauses"]
         return rv
 
     def __setstate__(self, state):
         vars(self).update(state)
-        self._clause_builder = _ClauseBuilder()
-
-    def __copy__(self):
-        cls = self.__class__
-        result = cls.__new__(cls)
-        result.__dict__.update(self.__dict__)
-        return result
+        self.clauses = []
+        for python_clause in self._python_clauses:
+            if isinstance(python_clause, PythonFilterClause):
+                input_columns, expression_context = visit_expression(python_clause.expr)
+                self.clauses.append(_FilterClause(input_columns, expression_context, self._optimisation))
+            elif isinstance(python_clause, PythonProjectionClause):
+                input_columns, expression_context = visit_expression(python_clause.expr)
+                self.clauses.append(_ProjectClause(input_columns, python_clause.name, expression_context))
+            elif isinstance(python_clause, PythonGroupByClause):
+                self.clauses.append(_GroupByClause(python_clause.name))
+            elif isinstance(python_clause, PythonAggregationClause):
+                self.clauses.append(_AggregationClause(self.clauses[-1].grouping_column, python_clause.aggregations))
+            else:
+                raise ArcticNativeException(
+                    f"Unrecognised clause type {type(python_clause)} when unpickling QueryBuilder"
+                )
 
     def __deepcopy__(self, memo):
         cls = self.__class__
         result = cls.__new__(cls)
-        memo[id(self)] = result
-        for k, v in self.__dict__.items():
-            if k != "_clause_builder":
-                setattr(result, k, copy.deepcopy(v, memo))
-        result._clause_builder = _ClauseBuilder()
+        result.__setstate__(self.__getstate__())
         return result
 
     # Might want to apply different optimisations to different clauses once projections/group-bys are implemented
     def optimise_for_speed(self):
         """Process query as fast as possible (the default behaviour)"""
         self._optimisation = _Optimisation.SPEED
+        for clause in self.clauses:
+            if hasattr(clause, "set_pipeline_optimisation"):
+                clause.set_pipeline_optimisation(_Optimisation.SPEED)
 
     def optimise_for_memory(self):
         """Reduce peak memory usage during the query, at the expense of some performance.
 
         Optimisations applied:
 
         * Memory used by strings that are present in segments read from storage, but are not required in the final dataframe that will be presented back to the user, is reclaimed earlier in the processing pipeline.
         """
         self._optimisation = _Optimisation.MEMORY
-
-    def execution_contexts(self):
-        res = [visit_expression(stage.expr) for stage in self.stages]
-        for execution_context in res:
-            execution_context.optimisation = self._optimisation
-        return res
-
-    def finalize_clause_builder(self):
-        for py_clause in self.stages:
-            py_clause.to_cpp(self._clause_builder)
-
-        return self._clause_builder
+        for clause in self.clauses:
+            if hasattr(clause, "set_pipeline_optimisation"):
+                clause.set_pipeline_optimisation(_Optimisation.MEMORY)
 
 
 CONSTRUCTOR_MAP = {
     "u": {1: ValueUint8, 2: ValueUint16, 4: ValueUint32, 8: ValueUint64},
     "i": {1: ValueInt8, 2: ValueInt16, 4: ValueInt32, 8: ValueInt64},
     "f": {1: ValueFloat32, 2: ValueFloat32, 4: ValueFloat32, 8: ValueFloat64},
 }
@@ -666,23 +610,23 @@
                     # chars match, or if the repr is truncated like '[   0    1    2 ... 9997 9998 9999]'
                     # Append -vX to handle this case, while keeping ValueSet keys short and readable in most cases
                     if key not in valueset_keys:
                         valueset_keys[key] = 0
                     else:
                         valueset_keys[key] += 1
                     key = key + "-v" + str(valueset_keys[key])
-                    execution_context.add_value_set(key, _ValueSet(node))
+                    expression_context.add_value_set(key, _ValueSet(node))
                     return _ValueSetName(key)
                 else:
-                    execution_context.add_value(key, create_value(node))
+                    expression_context.add_value(key, create_value(node))
                     return _ValueName(key)
 
             if isinstance(node, ExpressionNode):
                 if node.operator == COLUMN:
-                    execution_context.add_column(node.left)
+                    input_columns.add(node.left)
                     return _ColumnName(node.left)
                 else:
                     _visit(node)
                     return _ExpressionName(node.get_name())
             else:
                 return _handle_leaf(node)
 
@@ -691,14 +635,15 @@
 
         left = _visit_child(node.left)
         if node.right is not None:
             right = _visit_child(node.right)
             expression_node = _ExpressionNode(left, right, node.operator)
         else:
             expression_node = _ExpressionNode(left, node.operator)
-        execution_context.add_expression_node(node.get_name(), expression_node)
+        expression_context.add_expression_node(node.get_name(), expression_node)
 
-    execution_context = _ExecutionContext()
+    expression_context = _ExpressionContext()
+    input_columns = set()
     valueset_keys = dict()
     _visit(expr)
-    execution_context.root_node_name = _ExpressionName(expr.get_name())
-    return execution_context
+    expression_context.root_node_name = _ExpressionName(expr.get_name())
+    return input_columns, expression_context
```

## Comparing `arcticdb-1.3.0.dist-info/LICENSE.txt` & `arcticdb-1.4.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `arcticdb-1.3.0.dist-info/METADATA` & `arcticdb-1.4.0.dist-info/METADATA`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: arcticdb
-Version: 1.3.0
+Version: 1.4.0
 Summary: ArcticDB DataFrame Database
 Home-page: https://github.com/man-group/arcticdb
 Author: Man Alpha Technology
 Author-email: arcticdb@man.com
 License: Business Source License 1.1 (See LICENSE.txt)
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: POSIX :: Linux
@@ -13,15 +13,14 @@
 Classifier: Topic :: Database :: Database Engines/Servers
 Description-Content-Type: text/markdown
 License-File: LICENSE.txt
 License-File: NOTICE.txt
 Requires-Dist: numpy
 Requires-Dist: pandas (<2)
 Requires-Dist: attrs
-Requires-Dist: enum-compat
 Requires-Dist: grpcio-tools
 Requires-Dist: protobuf (>=3.5.0.post1)
 Requires-Dist: xxhash
 Requires-Dist: six
 Requires-Dist: msgpack
 Requires-Dist: psutil
 Requires-Dist: pyyaml
@@ -174,14 +173,16 @@
 We welcome your contributions to help us improve and extend this project!
 
 Please refer to the [Contributing](https://github.com/man-group/ArcticDB/blob/master/docs/mkdocs/docs/technical/contributing.md)
 page and feel free to open issues on GitHub.
 
 We are also always looking for feedback from our dedicated community! If you have used ArcticDB please let us know, we would love to hear about your experience!
 
+Our release process is [documented here](https://github.com/man-group/ArcticDB/blob/master/docs/mkdocs/docs/technical/releasing.md).
+
 ## Community
 
 We would love to hear how your ArcticDB journey evolves, email us at [arcticdb@man.com](mailto:ArcticDB@man.com) or come chat to us on [Twitter](https://www.twitter.com/arcticdb)!
 
 Interested in learning more about ArcticDB? Head over to our [blog](https://medium.com/arcticdb)!
 
 Do you have any questions or issues? Chat to us and other users through our dedicated Slack Workspace - sign up for Slack access on [our website](https://arcticdb.io).
```

### html2text {}

```diff
@@ -1,28 +1,28 @@
-Metadata-Version: 2.1 Name: arcticdb Version: 1.3.0 Summary: ArcticDB DataFrame
+Metadata-Version: 2.1 Name: arcticdb Version: 1.4.0 Summary: ArcticDB DataFrame
 Database Home-page: https://github.com/man-group/arcticdb Author: Man Alpha
 Technology Author-email: arcticdb@man.com License: Business Source License 1.1
 (See LICENSE.txt) Classifier: Programming Language :: Python :: 3 Classifier:
 Operating System :: POSIX :: Linux Classifier: Operating System :: Microsoft ::
 Windows Classifier: Topic :: Database Classifier: Topic :: Database :: Database
 Engines/Servers Description-Content-Type: text/markdown License-File:
 LICENSE.txt License-File: NOTICE.txt Requires-Dist: numpy Requires-Dist: pandas
-(<2) Requires-Dist: attrs Requires-Dist: enum-compat Requires-Dist: grpcio-
-tools Requires-Dist: protobuf (>=3.5.0.post1) Requires-Dist: xxhash Requires-
-Dist: six Requires-Dist: msgpack Requires-Dist: psutil Requires-Dist: pyyaml
-Requires-Dist: decorator Requires-Dist: prometheus-client Requires-Dist:
-dataclasses ; python_version < "3.7" Provides-Extra: testing Requires-Dist:
-pytest ; extra == 'testing' Requires-Dist: pytest-cpp ; extra == 'testing'
-Requires-Dist: pytest-timeout ; extra == 'testing' Requires-Dist: packaging ;
-extra == 'testing' Requires-Dist: future ; extra == 'testing' Requires-Dist:
-pytest-server-fixtures ; extra == 'testing' Requires-Dist: mock ; extra ==
-'testing' Requires-Dist: boto3 ; extra == 'testing' Requires-Dist: moto ; extra
-== 'testing' Requires-Dist: flask ; extra == 'testing' Requires-Dist: flask-
-cors ; extra == 'testing' Requires-Dist: hypothesis (<6.73) ; extra ==
-'testing' Requires-Dist: pymongo ; extra == 'testing'
+(<2) Requires-Dist: attrs Requires-Dist: grpcio-tools Requires-Dist: protobuf
+(>=3.5.0.post1) Requires-Dist: xxhash Requires-Dist: six Requires-Dist: msgpack
+Requires-Dist: psutil Requires-Dist: pyyaml Requires-Dist: decorator Requires-
+Dist: prometheus-client Requires-Dist: dataclasses ; python_version < "3.7"
+Provides-Extra: testing Requires-Dist: pytest ; extra == 'testing' Requires-
+Dist: pytest-cpp ; extra == 'testing' Requires-Dist: pytest-timeout ; extra ==
+'testing' Requires-Dist: packaging ; extra == 'testing' Requires-Dist: future ;
+extra == 'testing' Requires-Dist: pytest-server-fixtures ; extra == 'testing'
+Requires-Dist: mock ; extra == 'testing' Requires-Dist: boto3 ; extra ==
+'testing' Requires-Dist: moto ; extra == 'testing' Requires-Dist: flask ; extra
+== 'testing' Requires-Dist: flask-cors ; extra == 'testing' Requires-Dist:
+hypothesis (<6.73) ; extra == 'testing' Requires-Dist: pymongo ; extra ==
+'testing'
  [https://github.com/man-group/ArcticDB/raw/master/static/ArcticDBCropped.png]
 ---
      [https://raw.githubusercontent.com/man-group/ArcticDB/master/static/
                              ArcticDBTerminal.gif]
 ---
  ArcticDB_Website | ArcticDB_Blog | Press_Release | Press_Release | Community
 
@@ -92,14 +92,16 @@
 Code, or behaviour that you have experienced in the project, please contact us
 at [arcticdb@man.com](mailto:ArcticDB@man.com). ## Contributing/Building From
 Source We welcome your contributions to help us improve and extend this
 project! Please refer to the [Contributing](https://github.com/man-group/
 ArcticDB/blob/master/docs/mkdocs/docs/technical/contributing.md) page and feel
 free to open issues on GitHub. We are also always looking for feedback from our
 dedicated community! If you have used ArcticDB please let us know, we would
-love to hear about your experience! ## Community We would love to hear how your
-ArcticDB journey evolves, email us at [arcticdb@man.com](mailto:
-ArcticDB@man.com) or come chat to us on [Twitter](https://www.twitter.com/
-arcticdb)! Interested in learning more about ArcticDB? Head over to our [blog]
-(https://medium.com/arcticdb)! Do you have any questions or issues? Chat to us
-and other users through our dedicated Slack Workspace - sign up for Slack
-access on [our website](https://arcticdb.io).
+love to hear about your experience! Our release process is [documented here]
+(https://github.com/man-group/ArcticDB/blob/master/docs/mkdocs/docs/technical/
+releasing.md). ## Community We would love to hear how your ArcticDB journey
+evolves, email us at [arcticdb@man.com](mailto:ArcticDB@man.com) or come chat
+to us on [Twitter](https://www.twitter.com/arcticdb)! Interested in learning
+more about ArcticDB? Head over to our [blog](https://medium.com/arcticdb)! Do
+you have any questions or issues? Chat to us and other users through our
+dedicated Slack Workspace - sign up for Slack access on [our website](https://
+arcticdb.io).
```

## Comparing `arcticdb-1.3.0.dist-info/NOTICE.txt` & `arcticdb-1.4.0.dist-info/NOTICE.txt`

 * *Files identical despite different names*

## Comparing `arcticdb-1.3.0.dist-info/RECORD` & `arcticdb-1.4.0.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-arcticdb_ext.cp39-win_amd64.pyd,sha256=fqicZdD9D7sd2q7g29_C29WFCgj5d6heqouTMCgsnGs,22063616
+arcticdb_ext.cp39-win_amd64.pyd,sha256=HgI2gbvkUS1octHTiQOtEyALwRkJi_-e1bKcZtqveVQ,22064128
 arcticc/__init__.py,sha256=5t8gAo_NnZ269q7FPcp6PwmUczF2UFmS8Zz1KAVbiL0,66
 arcticc/pb2/__init__.py,sha256=pfsson0mxPSudMCFd_HpaUTeFROIFD4yA_XQgqAYMiU,583
-arcticdb/__init__.py,sha256=t1SAKz0_D9TmtoCAYVS1jfBDTpSZdIfrJ4aysnjDGnY,424
+arcticdb/__init__.py,sha256=R5F8RKrEOz0ZSGEG83JO3Egr9gDWpuFbsdAn_A1tGbQ,424
 arcticdb/_msgpack_compat.py,sha256=i_3HluY89KVSXFnxC-UjcdK0zNsIcSBLmY3YpKFeLl8,447
-arcticdb/arctic.py,sha256=5ZGA0u0ella3mKc3lDO3YXwNWJ47bNsEb4Jsybvzjqs,10784
+arcticdb/arctic.py,sha256=bkJFxPLqc_jup_u65Tpc-tUrsyKmdTDvHGU5-gT8dxY,11446
 arcticdb/config.py,sha256=ozc4oNPIDue4JoRTpsTJeBuhEXGCbgt27qux2nsao7E,7524
 arcticdb/exceptions.py,sha256=ArcFJwbH8PKD5CfC5Aq5LEKwcjIx-ftsocuGtwZjUrU,765
 arcticdb/flattener.py,sha256=u-rdlqaavqzcMUtyMycjaa9MjUdd-6xcVedkCjW8nJ8,9361
-arcticdb/log.py,sha256=0TGHEHZ6DuUalql6NegQ--m8Q7bjxrPzxB-RniLFwfQ,1809
+arcticdb/log.py,sha256=-jhGsvGmwEyv7cvQMwEkVM9RMy2Ddm4JEGP7AcfxZOI,1810
 arcticdb/options.py,sha256=euSyeMVFtvqgGFSEPyw-3d4n0NzwCe3uJ5iwjDXktz8,6476
 arcticdb/preconditions.py,sha256=85PtbfJEUGvVeRethePECPEhwAY6ZTZ3oy8Fx-KePyY,519
 arcticdb/supported_types.py,sha256=FUr7Slxn5c1v_wQ20H3l5wlK1cwpDoQKJfwDEjtnhEI,1612
-arcticdb/tools.py,sha256=umjEygBZDw6_IWrj5gew-werTfTW-UGsqp4TdtfQt6g,3142
+arcticdb/tools.py,sha256=Ah-Dbr-7Tv-0zTg-fRpX9s0GzlHnPyYww9Ke7eaBUew,3150
 arcticdb/adapters/__init__.py,sha256=wmFWqLdci5GAilj5KQGwGPYLnDRRKDOxrc80r27lYlg,138
-arcticdb/adapters/arctic_library_adapter.py,sha256=brVvjPTkxUlWCVhpNQp2nl-V368reG_1qNa57QAoG3s,2211
-arcticdb/adapters/lmdb_library_adapter.py,sha256=YmygJR8j1JowEkxfaDO2lFXRp7GRpAuXt-zikw9OSaA,2394
-arcticdb/adapters/s3_library_adapter.py,sha256=RImsx35b7mt-zMtjn3nO_il-GNWwVwiB6VjJt6_5sDs,6433
+arcticdb/adapters/arctic_library_adapter.py,sha256=k1WynP5Ac7UpTaOssEUVsOwrGkh2OsHFccaUQMjJYoE,2349
+arcticdb/adapters/lmdb_library_adapter.py,sha256=2bVb5aJwF9GfdlP33ucaKZPUkY38Xlqyt2AWrsp-z30,2534
+arcticdb/adapters/s3_library_adapter.py,sha256=kZ0bcwBWk1a7018hZx4jRbB67-bH7mV6azMd6ENoMpg,7550
 arcticdb/authorization/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 arcticdb/authorization/permissions.py,sha256=3E91GMrL6xSEKloOWdIGdaKrHfHoqhkSEqJwjJZJ3HQ,969
 arcticdb/proto/3/arcticc/pb2/config_pb2.py,sha256=W1pb3T1ArzmExVkjgF3xWn5WMWL5l9fR7rR0unnKhxE,8935
 arcticdb/proto/3/arcticc/pb2/descriptors_pb2.py,sha256=VmnoqTZkDtHRVxsPVWqOqoQF2W7lU03KHC6x4Lmk2ys,96954
 arcticdb/proto/3/arcticc/pb2/encoding_pb2.py,sha256=Huer_Ni4ySR6J6JXmObVVDqByoxp7hp2S59EzMrD8Sw,28646
 arcticdb/proto/3/arcticc/pb2/generation_pb2.py,sha256=lnxrzzbxdZ9ooO6BvKwLcntubqOh87YHS-0nzcAJfoI,13225
 arcticdb/proto/3/arcticc/pb2/in_memory_storage_pb2.py,sha256=xZjv7HAzBZIQl72vh5SCewyz7_Q5ISSqIyjx9kn3JFs,1990
@@ -28,44 +28,44 @@
 arcticdb/proto/3/arcticc/pb2/mongo_storage_pb2.py,sha256=qvHwtcn97z5ugofmq5flxIvAQujOTCPOyD9W4Puupys,2931
 arcticdb/proto/3/arcticc/pb2/nfs_backed_storage_pb2.py,sha256=1ZnNdkR-Zbg_2GsDOPPDWObbZdFO7xOousPky27WTyU,6878
 arcticdb/proto/3/arcticc/pb2/processors_pb2.py,sha256=GPEjpYXHIcRmCd6BmuZS17mC0HhqqvqRaJhq8O6Dgy8,3821
 arcticdb/proto/3/arcticc/pb2/request_pb2.py,sha256=eVqz2Y3viNjWyMxqjDu9Ez-74ASOryngv9I-bwFUA1E,49227
 arcticdb/proto/3/arcticc/pb2/s3_storage_pb2.py,sha256=iqOScoIJckeA1lAtb2NxaUsPCxhOXgH9ZwnkuQz_ZJA,6729
 arcticdb/proto/3/arcticc/pb2/storage_pb2.py,sha256=ya6U441nW-YMeTrOaHBjhWDfPUhpmPho-GWg3JfK8iQ,67292
 arcticdb/proto/3/arcticc/pb2/utils_pb2.py,sha256=VVissg-IkyLhDcT8v2Axy2OcMp704bxqqI-oYCQKECo,12621
-arcticdb/proto/4/arcticc/pb2/config_pb2.py,sha256=YVjqv_huPZ6y0f3I9uP6roYQ2heGOAFqHHu5mr-KpCY,2298
-arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py,sha256=XGt_VXNVJ_vbw2ocTdT6_1o__kG_yRWv83ioL3TvX3s,14870
-arcticdb/proto/4/arcticc/pb2/encoding_pb2.py,sha256=VABiKnYNXbQDfjcyfKLkeG5CtFRkydw_upnM4sPhiqA,4895
-arcticdb/proto/4/arcticc/pb2/generation_pb2.py,sha256=30BjQcmyGH9vUc33PDqTtEvJeTs3H-Hz9av9j6iBsik,2998
-arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py,sha256=-W7kF-2lNnwXI035xjjRShwb6eNmSNSgiFr6WMMbBjo,1038
-arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py,sha256=PzKHbxnnjxdWbcvaboN-6uyL9HgS9lkTdtTEP_llmJk,1367
-arcticdb/proto/4/arcticc/pb2/logger_pb2.py,sha256=N1ww5JIYxI3GYYjJ1d-sh2f8pU6ScAHI_L22PS8aPRM,4114
-arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py,sha256=SUhQ_MK4n6RZIuffpw578xXq89xK8jayjH2rvVYIgvE,1195
-arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py,sha256=jZ0m6j4EuYSsUR_RwMQQpne5OBl4ES6vDridcL_DWBE,1517
-arcticdb/proto/4/arcticc/pb2/processors_pb2.py,sha256=Mbr1IpNNrtI-UcbL5pavdUoIjsmaAMEOLEV45uy6OJs,1259
-arcticdb/proto/4/arcticc/pb2/request_pb2.py,sha256=n_oXwA3vEtkUeNrzMHrC4MEFh6dkvCk6r8sfGQ-rreY,6801
-arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py,sha256=MK5ZPt9oik4TyWxLke4VC3BM3KfQVwkdcudbd1G7RK4,1496
-arcticdb/proto/4/arcticc/pb2/storage_pb2.py,sha256=liHmX8x8V6jRhFwzALwdYGsCx-npRpkbpg4pRL3mTcM,9907
-arcticdb/proto/4/arcticc/pb2/utils_pb2.py,sha256=ksfhHFjEdosK8mwT1fcaiMfVTal7C9SAviBxFYDbnHI,2310
+arcticdb/proto/4/arcticc/pb2/config_pb2.py,sha256=d7JxukfZx19GteRxOBLZeOtJXH9KpSMWrIJYC7Overw,2413
+arcticdb/proto/4/arcticc/pb2/descriptors_pb2.py,sha256=SfsU_n9hQjenj0m83MtYIihr4HScx3YcaR2i23qTmfA,15753
+arcticdb/proto/4/arcticc/pb2/encoding_pb2.py,sha256=QFWCDJL2Kkc6wuzrB2t2aH6S4ozj7LqPlrI8kVfXYms,5202
+arcticdb/proto/4/arcticc/pb2/generation_pb2.py,sha256=hHPbUdpmRyTOPINbh4El3VBXS5j8M_SpdP4QYDlVDhE,3113
+arcticdb/proto/4/arcticc/pb2/in_memory_storage_pb2.py,sha256=12N7OcCwbxDJVs5D6eh9RjI-fb6mLKCAba8afTy7ZUE,1081
+arcticdb/proto/4/arcticc/pb2/lmdb_storage_pb2.py,sha256=uv32qXLwGSEYW8_tRQF3TFqP0h6_7DutssiZM5LVmFA,1434
+arcticdb/proto/4/arcticc/pb2/logger_pb2.py,sha256=eR8lplJWX0VDT_9N34Y2nEfZzrNDWW3I7DOqODyzQCs,4397
+arcticdb/proto/4/arcticc/pb2/mongo_storage_pb2.py,sha256=50wJdbORCkRzVTRAS5ovM9n6XAV27jQfq2dQG7SQgMs,1262
+arcticdb/proto/4/arcticc/pb2/nfs_backed_storage_pb2.py,sha256=pLRdJmX7aR4WKgDpUb3mvHQONc7hI-i7knZoaHX_hnM,1560
+arcticdb/proto/4/arcticc/pb2/processors_pb2.py,sha256=x6qgspRrQVMXWzg8c6HFD1gwHfkh4y4S0PJWgBRxXRU,1326
+arcticdb/proto/4/arcticc/pb2/request_pb2.py,sha256=8UNsktxFoH0CCrwBSSTH3SgP_W6NQBQdKfWkdK1WtRY,7300
+arcticdb/proto/4/arcticc/pb2/s3_storage_pb2.py,sha256=QWjK-BQady8Jw9rTNcg7IK11VlAsaeoBo--ZbsrO76c,1539
+arcticdb/proto/4/arcticc/pb2/storage_pb2.py,sha256=WAzDk1SY9INElzGHKKKGksjqEkc5n1KF1xX1njn_ZQk,10526
+arcticdb/proto/4/arcticc/pb2/utils_pb2.py,sha256=pz9TKshU5X5zkebM53j3WnhVN02ueoKl0WkLUVc9TVg,2449
 arcticdb/toolbox/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 arcticdb/toolbox/library_tool.py,sha256=Ch8zB82NTe_GUnrDD4QxrxkP0PlV9FZMsAv7jYNCpVs,6102
 arcticdb/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 arcticdb/util/errors.py,sha256=vmVvTdFvJJP0cofApzcor6Mn6lSmoE5ih3zvEf1Flkc,2705
 arcticdb/util/hypothesis.py,sha256=0nlWCa4zESA8I-x_yy4iJ9CFytAF332q58oJgGhKLHY,8775
 arcticdb/util/memory.py,sha256=-YYUz_ATxFGPov8mAOWsvwgulxZng1hgEB4xkAvUkPg,719
 arcticdb/util/tasks.py,sha256=aXNt_CDW9F0rtXCOwQaWIuoG69OMXajmy7NDUtwgJ2w,6013
-arcticdb/util/test.py,sha256=g-KS_3Y_KnsOWbnQUxG85LoetlH5MRP1mC6ZY6_-_3A,18251
+arcticdb/util/test.py,sha256=X0Vaz0kSoj585aaNTI9aj1d-iT2fgbAuoI2-vEknttI,18249
 arcticdb/version_store/__init__.py,sha256=uGAsgCsoyGmR-F7zvOx8GuMs1QdnVHdg5l7RSm6XiBY,131
 arcticdb/version_store/_common.py,sha256=V8eruObk6XhIabaGtFibt7jmzpf0V3nByNOdfb1ftGg,7189
 arcticdb/version_store/_custom_normalizers.py,sha256=EKqxg39qV8BJPjeSCZ9BEOnZkixCXJW796F91bR8wws,4193
 arcticdb/version_store/_normalization.py,sha256=l0QU6VKuRcI7ZtH4E8-A4Pa_LBP58z3CP0Wrbzegnbw,52659
-arcticdb/version_store/_store.py,sha256=rVkBxfhEfoyWn6aLjtJ9Gic-Zy6dgn_NOiOdYUk6oEI,113749
-arcticdb/version_store/helper.py,sha256=RvlvYy02ftrY_9ovK632SWR4Ivf-nPq1hcpbl-kssHg,11040
-arcticdb/version_store/library.py,sha256=qqqkPKwkQTwD81gmiH05mMZQkbLgIi73RdaD84xJbKk,59441
-arcticdb/version_store/processing.py,sha256=2eW_r38uAm1_WxymHCu1kSwXFvx3-EuRLnTO5OTjsVc,24581
+arcticdb/version_store/_store.py,sha256=0Ar0IZDKA1Gg8Jc5SsXcd-w5VZpld1Au2PWklA28ZII,113724
+arcticdb/version_store/helper.py,sha256=RxtIpUlBKMuWDFu4jqJdtj35k3L9l6t1hfqmvTAZXlo,11129
+arcticdb/version_store/library.py,sha256=2U5nYYgy8defceN6TNo84CQpm-SED274oQiWAxkgv0k,59545
+arcticdb/version_store/processing.py,sha256=POVL_b4wwNgam5ETgyuTzlnt_wngZ29gFEUbGurXTDA,24370
 arcticdb/version_store/read_result.py,sha256=5HhAJ0Wh01f111qA5XvWqOXABO-2H0jZ78kx-iiQzOk,603
-arcticdb-1.3.0.dist-info/LICENSE.txt,sha256=ruvCXWZm0cgyb-XAEjFcfdJkJ_nGbv9gsYNeps514Ys,4851
-arcticdb-1.3.0.dist-info/METADATA,sha256=Wc-jW5KcIz90EaxZpE8K6N4CiAdetzLzQs-G81547u8,8449
-arcticdb-1.3.0.dist-info/NOTICE.txt,sha256=TsVpAVXueJjRq_zV86A3v_TqJRsXCQtYjrEvycwyaaY,18186
-arcticdb-1.3.0.dist-info/WHEEL,sha256=J_4V_gB-O6Y7Pn6lk91K27JaIhI-q07YM5J8Ufzqla4,100
-arcticdb-1.3.0.dist-info/top_level.txt,sha256=jDxz3uFaLYFuxxPf3h6-sqPQqEFbMkWGP-9vE8Dbi1w,30
-arcticdb-1.3.0.dist-info/RECORD,,
+arcticdb-1.4.0.dist-info/LICENSE.txt,sha256=ruvCXWZm0cgyb-XAEjFcfdJkJ_nGbv9gsYNeps514Ys,4851
+arcticdb-1.4.0.dist-info/METADATA,sha256=RX5Xlfe9smQ9HxtvcNTUoqwU6l57p9-220Qo6EybN1Q,8557
+arcticdb-1.4.0.dist-info/NOTICE.txt,sha256=TsVpAVXueJjRq_zV86A3v_TqJRsXCQtYjrEvycwyaaY,18186
+arcticdb-1.4.0.dist-info/WHEEL,sha256=J_4V_gB-O6Y7Pn6lk91K27JaIhI-q07YM5J8Ufzqla4,100
+arcticdb-1.4.0.dist-info/top_level.txt,sha256=jDxz3uFaLYFuxxPf3h6-sqPQqEFbMkWGP-9vE8Dbi1w,30
+arcticdb-1.4.0.dist-info/RECORD,,
```

